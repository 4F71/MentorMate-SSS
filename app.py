# ============================================================================
# APP.PY: MentorMate Chatbot - Streamlit (Runtime DB Setup)
# ============================================================================

import streamlit as st
import os
import asyncio
import json
from dotenv import load_dotenv
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain.docstore.document import Document

# Core modÃ¼llerden import
from core.rag_pipeline import RAGPipeline, validate_answer, preprocess_query

# ============================================================================
# 1. PROJE YAPILANDIRMASI
# ============================================================================

load_dotenv()
asyncio.set_event_loop(asyncio.new_event_loop())

PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
DB_PATH = os.path.join(PROJECT_ROOT, "chroma_db")
COLLECTION_NAME = "mentormate_faq"
EMBEDDING_MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

DATA_FILES = [
    os.path.join(PROJECT_ROOT, "data", "enriched_dataset.jsonl"),
    os.path.join(PROJECT_ROOT, "data", "generated_data_google.jsonl")
]

EXPERT_MODE = {
    "name": "Uzman Mod",
    "icon": "ğŸ¯",
    "color": "#1f77b4",
    "desc": "Sadece veritabanÄ±ndaki gÃ¼venilir bilgileri verir."
}

# ============================================================================
# 2. DATABASE SETUP (RUNTIME)
# ============================================================================

def load_jsonl_data(file_path: str) -> list:
    """JSONL dosyasÄ±ndan Document listesi oluÅŸtur"""
    documents = []
    
    if not os.path.exists(file_path):
        return documents
    
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                data = json.loads(line)
                question = data.get("question", "")
                answer = data.get("answer", "")
                
                if question and answer:
                    page_content = f"Soru: {question}\nCevap: {answer}"
                    doc = Document(
                        page_content=page_content,
                        metadata={"source": os.path.basename(file_path)}
                    )
                    documents.append(doc)
            except:
                continue
    
    return documents


def create_database_runtime():
    """Runtime'da veritabanÄ± oluÅŸtur"""
    
    # Veri yÃ¼kle
    all_documents = []
    for file_path in DATA_FILES:
        docs = load_jsonl_data(file_path)
        all_documents.extend(docs)
    
    if not all_documents:
        raise Exception("Veri dosyalarÄ± yÃ¼klenemedi!")
    
    # Embedding modeli
    embeddings = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL,
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'batch_size': 32}
    )
    
    # ChromaDB oluÅŸtur
    vectordb = Chroma.from_documents(
        documents=all_documents,
        embedding=embeddings,
        persist_directory=DB_PATH,
        collection_name=COLLECTION_NAME
    )
    
    return vectordb


def check_and_setup_database():
    """VeritabanÄ± yoksa runtime'da oluÅŸtur"""
    if not os.path.exists(DB_PATH):
        with st.spinner("ğŸ”§ Ä°lk kurulum yapÄ±lÄ±yor... (~2-3 dakika)"):
            try:
                st.info("ğŸ“¦ VeritabanÄ± oluÅŸturuluyor...")
                create_database_runtime()
                st.success("âœ… VeritabanÄ± baÅŸarÄ±yla oluÅŸturuldu!")
                st.balloons()
            except Exception as e:
                st.error(f"âŒ VeritabanÄ± oluÅŸturulamadÄ±: {str(e)}")
                st.stop()

# ============================================================================
# 3. BÄ°LEÅEN YÃœKLEME
# ============================================================================

@st.cache_resource
def load_rag_pipeline():
    """RAG Pipeline'Ä± yÃ¼kler"""
    if not GOOGLE_API_KEY:
        st.error("âš ï¸ Google API anahtarÄ± bulunamadÄ±! LÃ¼tfen Secrets'a ekleyin.")
        st.stop()
    
    check_and_setup_database()
    
    try:
        pipeline = RAGPipeline(
            google_api_key=GOOGLE_API_KEY,
            db_path=DB_PATH,
            collection_name=COLLECTION_NAME,
            embedding_model=EMBEDDING_MODEL,
            llm_model="gemini-2.0-flash",
            temperature=0.01
        )
        return pipeline
    except Exception as e:
        st.error(f"âŒ RAG Pipeline yÃ¼klenemedi: {str(e)}")
        st.stop()

# ============================================================================
# 4. STREAMLIT ARAYÃœZÃœ (DeÄŸiÅŸiklik yok)
# ============================================================================

def main():
    st.set_page_config(
        page_title="MentorMate Chatbot",
        page_icon="ğŸ¤–",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.markdown("""<style>.stButton > button {width: 100%;}</style>""", unsafe_allow_html=True)
    
    pipeline = load_rag_pipeline()
    
    if "messages" not in st.session_state:
        st.session_state.messages = [{
            "role": "assistant",
            "content": "Merhaba! Ben MentorMate. Bootcamp hakkÄ±nda sorularÄ±nÄ±zÄ± yanÄ±tlamak iÃ§in buradayÄ±m. ğŸš€"
        }]
    
    # SIDEBAR
    with st.sidebar:
        st.title("âš™ï¸ MentorMate")
        
        st.markdown(f"""
        <div style='padding: 15px; background-color: {EXPERT_MODE['color']}22; 
        border-radius: 8px; border-left: 4px solid {EXPERT_MODE['color']}'>
        <h3 style='margin:0; color: {EXPERT_MODE['color']}'>{EXPERT_MODE['icon']} {EXPERT_MODE['name']}</h3>
        <p style='margin:5px 0 0 0; font-size:0.9em'>{EXPERT_MODE['desc']}</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("---")
        
        st.markdown("### ğŸ“Š Sohbet Ä°statistikleri")
        user_count = len([m for m in st.session_state.messages if m["role"] == "user"])
        bot_count = len([m for m in st.session_state.messages if m["role"] == "assistant"])
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Sorular", user_count)
        with col2:
            st.metric("Cevaplar", bot_count)
        
        st.markdown("---")
        
        if st.button("ğŸ—‘ï¸ Sohbeti Temizle", use_container_width=True):
            st.session_state.messages = [{
                "role": "assistant",
                "content": "Merhaba! Ben MentorMate. Bootcamp hakkÄ±nda sorularÄ±nÄ±zÄ± yanÄ±tlamak iÃ§in buradayÄ±m. ğŸš€"
            }]
            pipeline.clear_memory()
            st.rerun()
        
        st.markdown("---")
        st.markdown("### ğŸ—„ï¸ VeritabanÄ±")
        stats = pipeline.get_stats()
        st.caption(f"ğŸ“ `{os.path.basename(stats['db_path'])}/`")
        st.caption(f"ğŸ¤– `{stats['embedding_model'].split('/')[-1][:35]}`")
        
        st.markdown("---")
        st.markdown("[ğŸ“¦ GitHub Repo](https://github.com/4F71/MentorMate-SSS)")
    
    # ANA Ä°Ã‡ERÄ°K
    st.title(f"{EXPERT_MODE['icon']} MentorMate Chatbot")
    st.caption("Bootcamp hakkÄ±nda **sadece gÃ¼venilir bilgiler** veriyorum.")
    
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
    
    if user_input := st.chat_input("Sorunuzu buraya yazÄ±n..."):
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)
        
        greetings = ["merhaba", "selam", "hey", "hi", "gÃ¼naydÄ±n"]
        if user_input.lower().strip() in greetings:
            response = f"Merhaba! Ben MentorMate. Size nasÄ±l yardÄ±mcÄ± olabilirim? ğŸ˜Š"
            with st.chat_message("assistant"):
                st.markdown(response)
            st.session_state.messages.append({"role": "assistant", "content": response})
        else:
            with st.chat_message("assistant"):
                with st.spinner(f"{EXPERT_MODE['icon']} DÃ¼ÅŸÃ¼nÃ¼yorum..."):
                    try:
                        enriched_query = preprocess_query(user_input)
                        result = pipeline.query(enriched_query)
                        raw_answer = result.get("answer", "Bir hata oluÅŸtu.").strip()
                        source_docs = result.get("source_documents", [])
                        final_answer = validate_answer(raw_answer, source_docs)
                        
                        st.markdown(final_answer)
                        st.session_state.messages.append({
                            "role": "assistant", 
                            "content": final_answer
                        })
                    except Exception as e:
                        error_msg = f"âŒ Bir hata oluÅŸtu: {str(e)}"
                        st.error(error_msg)
                        st.session_state.messages.append({
                            "role": "assistant", 
                            "content": error_msg
                        })

if __name__ == "__main__":
    main()