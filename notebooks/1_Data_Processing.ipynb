{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb67632-f52c-4ca9-a592-f38d9d0dfb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# BLOK 0: PROJE GÃœNLÃœÄÃœM - GeliÅŸtirme SerÃ¼venim, KarÅŸÄ±laÅŸtÄ±ÄŸÄ±m Zorluklar ve Ã–ÄŸrenimlerim\n",
    "# ======================================================================================\n",
    "\n",
    "\"\"\"\n",
    "########################################################################################\n",
    "# 1. BAÅLANGIÃ‡ NOKTAM: Ham Veriden AnlamlÄ± Bir Veri Seti OluÅŸturma\n",
    "########################################################################################\n",
    "# Bu projedeki ilk hedefim, `zulip_data.txt` dosyasÄ±ndaki ham metinleri alÄ±p, her bir\n",
    "# Soru-Cevap Ã§ifti iÃ§in LLM (Gemini) kullanarak anahtar kelimeler (keywords) ve ek soru\n",
    "# varyasyonlarÄ± (`all_questions`) Ã¼reterek yapÄ±landÄ±rÄ±lmÄ±ÅŸ bir JSON dosyasÄ± oluÅŸturmaktÄ±.\n",
    "# Bu not defteri, o ilk denememin ve geliÅŸtirme sÃ¼recimin adÄ±mlarÄ±nÄ± iÃ§eriyor.\n",
    "\n",
    "########################################################################################\n",
    "# 2. KARÅILAÅTIÄIM ZORLUKLAR ve PÄ°VOT (YÃ–N DEÄÄ°ÅTÄ°RME) ANLARIM\n",
    "########################################################################################\n",
    "\n",
    "# ZORLUK 1: VERÄ° KALÄ°TESÄ° (\"Dandik Veri Sendromu\")\n",
    "# --------------------------------------------------------------------------------------\n",
    "# - TESPÄ°TÄ°M: Otomatik olarak zenginleÅŸtirdiÄŸim veri setini (`enriched_dataset.jsonl`)\n",
    "#   daha sonra analiz ettiÄŸimde, birÃ§ok sorunun anlamsal olarak alakasÄ±z cevaplarla\n",
    "#   eÅŸleÅŸtiÄŸini fark ettim. Ã–rneÄŸin, \"Sertifika alacak mÄ±yÄ±m?\" sorusuna \"Grup kurmak\n",
    "#   zorunlu deÄŸil\" gibi saÃ§ma cevaplar atanmÄ±ÅŸtÄ±.\n",
    "# - Ã‡Ã–ZÃœMÃœM: Bu ÅŸekilde devam etmenin \"Ã§Ã¶p veriyi Ã§oÄŸaltmak\" olacaÄŸÄ±na karar verdim.\n",
    "#   Veri Ã¼retme sÃ¼recini durdurdum ve bir \"Veri Doktoru\" script'i yazarak hangi cevabÄ±n\n",
    "#   hangi sorulara atandÄ±ÄŸÄ±nÄ± gÃ¶steren bir rapor oluÅŸturdum. Bu rapor sayesinde,\n",
    "#   `enriched_dataset.jsonl` dosyasÄ± Ã¼zerinde manuel bir veri temizliÄŸi yaptÄ±m.\n",
    "# - Ã–ÄRENÄ°MÄ°M: Bir yapay zeka projesinin baÅŸarÄ±sÄ±nÄ±n, modelin gÃ¼cÃ¼nden Ã¶nce, beslendiÄŸi\n",
    "#   verinin kalitesine baÄŸlÄ± olduÄŸunu ilk elden tecrÃ¼be ettim. \"Garbage In, Garbage Out\"\n",
    "#   prensibinin ne kadar doÄŸru olduÄŸunu anladÄ±m.\n",
    "\n",
    "# ZORLUK 2: API LÄ°MÄ°TLERÄ° ve KÃœTÃœPHANE UYUMSUZLUKLARI\n",
    "# --------------------------------------------------------------------------------------\n",
    "# - TESPÄ°TÄ°M: TemizlenmiÅŸ veri setiyle sentetik cevap varyasyonlarÄ± Ã¼retmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ±mda,\n",
    "#   farklÄ± API saÄŸlayÄ±cÄ±larÄ±nÄ±n Ã§eÅŸitli limitleriyle ve kÃ¼tÃ¼phane sorunlarÄ±yla karÅŸÄ±laÅŸtÄ±m:\n",
    "#     a) Google Gemini: BaÅŸta \"404 Model Not Found\" hatasÄ± aldÄ±m. KÃ¼tÃ¼phane versiyonlarÄ±mÄ±n\n",
    "#        eski olduÄŸunu fark edip `pip install --upgrade` ile tÃ¼m paketleri gÃ¼ncelledim.\n",
    "#        SonrasÄ±nda ise Google'Ä±n \"GÃ¼nlÃ¼k Toplam Ä°stek Limiti\"ne takÄ±ldÄ±m.\n",
    "#     b) Hugging Face: Burada da \"Model GÃ¶rev UyumsuzluÄŸu\" ve kÃ¼tÃ¼phane kurulum hatalarÄ±\n",
    "#        yaÅŸadÄ±m. DÃ¼zeltmelerden sonra ise bu kez \"AylÄ±k Ãœcretsiz KullanÄ±m Kredisi\" bitti.\n",
    "# - KIYMETLÄ° Ã–ÄRENÄ°MÄ°M (API TEÅHÄ°S ARACI): Hangi API'Ä±n neden Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± anlamak iÃ§in\n",
    "#   tahmin yÃ¼rÃ¼tmek yerine, doÄŸrudan API'ye \"hangi modelleri kullanabilirim?\" diye soran\n",
    "#   bir teÅŸhis script'i yazdÄ±m. Bu script, kÃ¼tÃ¼phane versiyonu sorununu net bir ÅŸekilde\n",
    "#   ortaya Ã§Ä±kardÄ± ve bana kullanabileceÄŸim doÄŸru model isimlerini listeledi. Bu sayede,\n",
    "#   problem Ã§Ã¶zÃ¼mÃ¼nde varsayÄ±mlar yerine kanÄ±tlara dayalÄ± hareket etmenin Ã¶nemini Ã¶ÄŸrendim.\n",
    "# - Ã‡Ã–ZÃœMÃœM: Tek bir API'ye baÄŸÄ±mlÄ± kalmak yerine, modÃ¼ler bir yaklaÅŸÄ±m benimsedim.\n",
    "#   Her API saÄŸlayÄ±cÄ±sÄ± iÃ§in ayrÄ± bir \"Veri Ãœretici\" hÃ¼cresi oluÅŸturdum ve bu hÃ¼crelere\n",
    "#   \"kaldÄ±ÄŸÄ± yerden devam etme\" mantÄ±ÄŸÄ± ekledim. Bu, uzun soluklu veri Ã¼retme iÅŸlemini\n",
    "#   yÃ¶netilebilir kÄ±ldÄ±.\n",
    "\n",
    "########################################################################################\n",
    "# 3. NÄ°HAÄ° Ã‡Ã–ZÃœM ve PROJENÄ°N MEVCUT MÄ°MARÄ°SÄ°\n",
    "########################################################################################\n",
    "# Bu zorluklar sonucunda, projem sadece bir SSS botu olmaktan Ã§Ä±kÄ±p, dayanÄ±klÄ± bir\n",
    "# veri iÅŸleme ve RAG pipeline'Ä±na dÃ¶nÃ¼ÅŸtÃ¼.\n",
    "#\n",
    "# - VERÄ° TARAFI: ArtÄ±k manuel olarak temizlenmiÅŸ bir \"altÄ±n\" veri setim ve bu seti\n",
    "#   farklÄ± API'larla zenginleÅŸtirebilen modÃ¼ler script'lerim var.\n",
    "# - BOT TARAFI: Sadece cevap veren bir yapÄ± yerine; konuÅŸma geÃ§miÅŸini hatÄ±rlayan (HafÄ±za),\n",
    "#   bulduÄŸu bilgiyi kendi cÃ¼mleleriyle anlatan (Dinamik Cevap), hangi kaynaktan\n",
    "#   yararlandÄ±ÄŸÄ±nÄ± belirten (Kaynak GÃ¶sterme) geliÅŸmiÅŸ bir mimari geliÅŸtirdim.\n",
    "#\n",
    "# GENEL Ã–ÄRENÄ°MÄ°M: Bu proje, bir mÃ¼hendis olarak sadece kod yazmanÄ±n deÄŸil, aynÄ± zamanda\n",
    "# karÅŸÄ±laÅŸÄ±lan sorunlarÄ± sistematik bir ÅŸekilde teÅŸhis etmenin, farklÄ± Ã§Ã¶zÃ¼m yollarÄ±\n",
    "# denemenin ve hedefe ulaÅŸmak iÃ§in gerektiÄŸinde strateji deÄŸiÅŸtirmenin (pivot) ne kadar\n",
    "# Ã¶nemli olduÄŸunu bana Ã¶ÄŸretti.\n",
    "########################################################################################\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3366338-8fa7-43ce-92bd-98c71dfd168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "\n",
    "print(\"KÃ¼tÃ¼phaneler yÃ¼klendi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ef0f6d-e688-4f80-bfa2-573db17224f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    api_key = os.environ.get('GOOGLE_API_KEY')\n",
    "    if not api_key:\n",
    "        raise ValueError(\"GOOGLE_API_KEY ortam deÄŸiÅŸkeni bulunamadÄ±.\")\n",
    "    \n",
    "    genai.configure(api_key=api_key)\n",
    "    print(\"Gemini API anahtarÄ± baÅŸarÄ±yla yapÄ±landÄ±rÄ±ldÄ±.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"API yapÄ±landÄ±rma hatasÄ±: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dd4687-181d-4f2d-9994-a0ce23451923",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n----- Bu API AnahtarÄ±nÄ±n KullanabildiÄŸi Modeller -----\")\n",
    "try:\n",
    "    for m in genai.list_models():\n",
    "        if 'generateContent' in m.supported_generation_methods:\n",
    "            print(f\" {m.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Modeller listelenirken bir hata oluÅŸtu: {e}\")\n",
    "print(\"-\" * 65)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05284e2-a89d-40ae-8794-202791a59518",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = '../data/zulip_data.txt'\n",
    "output_json_path = '../data/sss_dataset_augmented.json'\n",
    "# YukarÄ±daki listeden 'gemini-2.0-flash' modelini seÃ§tim.\n",
    "MODEL_NAME = \"models/gemini-2.0-flash\" \n",
    "\n",
    "try:\n",
    "    # SeÃ§tiÄŸim model adÄ±yla bir model nesnesi oluÅŸturdum.\n",
    "    model = genai.GenerativeModel(MODEL_NAME)\n",
    "    print(f\"Model seÃ§imi yapÄ±ldÄ± ve '{MODEL_NAME}' baÅŸarÄ±yla yÃ¼klendi.\")\n",
    "except Exception as e:\n",
    "    print(f\"Model yÃ¼klenirken hata oluÅŸtu: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a82ea19-6eb9-4a90-bbc4-12eccff02122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_zulip_data(file_path):\n",
    "    \"\"\"\n",
    "    Bu fonksiyonu, 'zulip_data.txt' formatÄ±ndaki ham metin dosyasÄ±nÄ± okuyup\n",
    "    iÃ§indeki Soru-Cevap Ã§iftlerini bir liste olarak ayÄ±klamak iÃ§in yazdÄ±m.\n",
    "    \"\"\"\n",
    "    print(f\"'{file_path}' dosyasÄ±ndaki ham veri okunuyor...\")\n",
    "    qa_pairs = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        \n",
    "    # Metni \":question:\" ifadesine gÃ¶re bÃ¶lerek her bir soru bloÄŸunu ayÄ±rdÄ±m.\n",
    "    blocks = content.split(':question:')\n",
    "    for block in blocks:\n",
    "        if ':answer:' in block:\n",
    "            # Her bloÄŸu \":answer:\" ifadesine gÃ¶re soru ve cevap olarak ikiye ayÄ±rdÄ±m.\n",
    "            parts = block.split(':answer:')\n",
    "            question = parts[0].strip()\n",
    "            answer = parts[1].strip()\n",
    "            if question and answer:\n",
    "                qa_pairs.append({'question': question, 'answer': answer})\n",
    "    print(f\"-> {len(qa_pairs)} adet Soru-Cevap Ã§ifti bulundu.\")\n",
    "    return qa_pairs\n",
    "\n",
    "def generate_keywords_for_qa(question, answer):\n",
    "    \"\"\"\n",
    "    Bu fonksiyonu, verilen bir Soru-Cevap Ã§ifti iÃ§in Gemini API'sini kullanarak\n",
    "    iliÅŸkili anahtar kelimeler Ã¼retmek amacÄ±yla yazdÄ±m.\n",
    "    \"\"\"\n",
    "    # LLM'e ne yapmasÄ± gerektiÄŸini anlatan bir talimat (prompt) hazÄ±rladÄ±m.\n",
    "    prompt = f\"AÅŸaÄŸÄ±daki soru ve cevapla ilgili en Ã¶nemli 5 anahtar kelimeyi virgÃ¼lle ayÄ±rarak listele. Sadece kelimeleri yaz, baÅŸka bir ÅŸey ekleme:\\n\\nSORU: \\\"{question}\\\"\\nCEVAP: \\\"{answer}\\\"\\n\\nANAHTAR KELÄ°MELER:\"\n",
    "    # API'ye isteÄŸi gÃ¶nderip cevabÄ± aldÄ±m.\n",
    "    response = model.generate_content(prompt)\n",
    "    # Gelen cevabÄ± temizleyip kÃ¼Ã§Ã¼k harfe Ã§evirdim.\n",
    "    keywords = {kw.strip().lower() for kw in response.text.split(',')}\n",
    "    return list(keywords)\n",
    "\n",
    "def generate_alternative_questions(question, answer):\n",
    "    \"\"\"\n",
    "    Bu fonksiyonu, verilen bir Soru-Cevap Ã§iftinden yola Ã§Ä±karak, aynÄ± anlama gelen\n",
    "    4 farklÄ± alternatif soru cÃ¼mlesi Ã¼retmek iÃ§in yazdÄ±m. Bu, veri setimi\n",
    "    zenginleÅŸtirmek iÃ§in kullandÄ±ÄŸÄ±m bir yÃ¶ntemdi.\n",
    "    \"\"\"\n",
    "    prompt = f\"AÅŸaÄŸÄ±daki soruya anlamsal olarak benzeyen, aynÄ± cevabÄ± gerektiren 4 farklÄ± soru cÃ¼mlesi Ã¼ret. SorularÄ± alt alta, baÅŸÄ±nda numara olmadan yaz.\\n\\nÃ–RNEK SORU: 'Bootcamp Ã¼cretli mi?'\\nÃ–RNEK Ã‡IKTI:\\nBootcamp'e katÄ±lmak iÃ§in Ã¶deme yapmam gerekiyor mu?\\nEÄŸitimin bir maliyeti var mÄ±?\\nBu program iÃ§in Ã¼cret talep ediliyor mu?\\nBootcamp katÄ±lÄ±mÄ± paralÄ± mÄ±?\\n\\nSENÄ°N GÃ–REVÄ°N:\\nSORU: '{question}'\\nCEVAP: '{answer}'\\n\\nALTERNATÄ°F SORULAR:\"\n",
    "    response = model.generate_content(prompt)\n",
    "    # Gelen cevaptaki her bir satÄ±rÄ± ayrÄ± bir soru olarak alÄ±p listeye ekledim.\n",
    "    alt_questions = [q.strip() for q in response.text.split('\\n') if q.strip()]\n",
    "    return alt_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0335b5d-f02a-4a62-9a9a-5d894aba39d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Projemin ana veri iÅŸleme fonksiyonu.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\" VERÄ° ZENGÄ°NLEÅTÄ°RME SÃœRECÄ° BAÅLATILDI \")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # 1. Ham veriyi okudum.\n",
    "        qa_dataset = parse_zulip_data(raw_data_path)\n",
    "        \n",
    "        enriched_data = []\n",
    "        # 2. Her bir Soru-Cevap Ã§ifti iÃ§in dÃ¶ngÃ¼ baÅŸlattÄ±m.\n",
    "        for i, item in enumerate(qa_dataset):\n",
    "            question = item['question']\n",
    "            answer = item['answer']\n",
    "            print(f\"\\n[{i+1}/{len(qa_dataset)}] Ä°ÅŸleniyor: {question[:60]}...\")\n",
    "            \n",
    "            # 3. Anahtar kelimeler Ã¼rettim.\n",
    "            print(\"  - Anahtar kelimeler Ã¼retiliyor...\")\n",
    "            final_keywords = generate_keywords_for_qa(question, answer)\n",
    "            time.sleep(5) \n",
    "            \n",
    "            # 4. Alternatif sorular Ã¼rettim.\n",
    "            print(\"  - Alternatif sorular Ã¼retiliyor...\")\n",
    "            all_questions = [question] + generate_alternative_questions(question, answer)\n",
    "            time.sleep(5) \n",
    "            \n",
    "            # 5. TÃ¼m bilgileri tek bir JSON objesinde birleÅŸtirdim.\n",
    "            faq_item = {\n",
    "                \"category\": \"Genel\", \"original_question\": question,\n",
    "                \"all_questions\": all_questions, \"answer\": answer,\n",
    "                \"keywords\": list(final_keywords), \"difficulty_level\": \"beginner\"\n",
    "            }\n",
    "            enriched_data.append(faq_item)\n",
    "            \n",
    "            print(f\"  -> Ãœretilen Keywords: {list(final_keywords)}\")\n",
    "            print(f\"  -> Toplam Soru Varyasyonu: {len(all_questions)}\")\n",
    "\n",
    "        # 6. Sonucu dosyaya yazdÄ±m.\n",
    "        with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(enriched_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        print(f\"\\nğŸ‰ BAÅARILI: Veri seti '{output_json_path}' dosyasÄ±na kaydedildi!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Kritik bir hata oluÅŸtu: {e}\")\n",
    "\n",
    "# Bu if bloÄŸu, script'in sadece doÄŸrudan Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda main() fonksiyonunu\n",
    "# Ã§aÄŸÄ±rmasÄ±nÄ± saÄŸlar.\n",
    "if __name__ == \"__main__\":\n",
    "    # main() # Bu satÄ±rÄ±, bu eski script'i tekrar Ã§alÄ±ÅŸtÄ±rmamak iÃ§in yorum satÄ±rÄ± yaptÄ±m.\n",
    "    print(\"\\nBu not defteri, projenin ilk veri iÅŸleme adÄ±mlarÄ±nÄ± belgelemektedir.\")\n",
    "    print(\"Aktif geliÅŸtirme diÄŸer not defterlerinde devam etmektedir.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
