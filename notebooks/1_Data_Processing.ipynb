{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb67632-f52c-4ca9-a592-f38d9d0dfb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# BLOK 0: PROJE GÜNLÜĞÜM - Geliştirme Serüvenim, Karşılaştığım Zorluklar ve Öğrenimlerim\n",
    "# ======================================================================================\n",
    "\n",
    "\"\"\"\n",
    "########################################################################################\n",
    "# 1. BAŞLANGIÇ NOKTAM: Ham Veriden Anlamlı Bir Veri Seti Oluşturma\n",
    "########################################################################################\n",
    "# Bu projedeki ilk hedefim, `zulip_data.txt` dosyasındaki ham metinleri alıp, her bir\n",
    "# Soru-Cevap çifti için LLM (Gemini) kullanarak anahtar kelimeler (keywords) ve ek soru\n",
    "# varyasyonları (`all_questions`) üreterek yapılandırılmış bir JSON dosyası oluşturmaktı.\n",
    "# Bu not defteri, o ilk denememin ve geliştirme sürecimin adımlarını içeriyor.\n",
    "\n",
    "########################################################################################\n",
    "# 2. KARŞILAŞTIĞIM ZORLUKLAR ve PİVOT (YÖN DEĞİŞTİRME) ANLARIM\n",
    "########################################################################################\n",
    "\n",
    "# ZORLUK 1: VERİ KALİTESİ (\"Dandik Veri Sendromu\")\n",
    "# --------------------------------------------------------------------------------------\n",
    "# - TESPİTİM: Otomatik olarak zenginleştirdiğim veri setini (`enriched_dataset.jsonl`)\n",
    "#   daha sonra analiz ettiğimde, birçok sorunun anlamsal olarak alakasız cevaplarla\n",
    "#   eşleştiğini fark ettim. Örneğin, \"Sertifika alacak mıyım?\" sorusuna \"Grup kurmak\n",
    "#   zorunlu değil\" gibi saçma cevaplar atanmıştı.\n",
    "# - ÇÖZÜMÜM: Bu şekilde devam etmenin \"çöp veriyi çoğaltmak\" olacağına karar verdim.\n",
    "#   Veri üretme sürecini durdurdum ve bir \"Veri Doktoru\" script'i yazarak hangi cevabın\n",
    "#   hangi sorulara atandığını gösteren bir rapor oluşturdum. Bu rapor sayesinde,\n",
    "#   `enriched_dataset.jsonl` dosyası üzerinde manuel bir veri temizliği yaptım.\n",
    "# - ÖĞRENİMİM: Bir yapay zeka projesinin başarısının, modelin gücünden önce, beslendiği\n",
    "#   verinin kalitesine bağlı olduğunu ilk elden tecrübe ettim. \"Garbage In, Garbage Out\"\n",
    "#   prensibinin ne kadar doğru olduğunu anladım.\n",
    "\n",
    "# ZORLUK 2: API LİMİTLERİ ve KÜTÜPHANE UYUMSUZLUKLARI\n",
    "# --------------------------------------------------------------------------------------\n",
    "# - TESPİTİM: Temizlenmiş veri setiyle sentetik cevap varyasyonları üretmeye çalıştığımda,\n",
    "#   farklı API sağlayıcılarının çeşitli limitleriyle ve kütüphane sorunlarıyla karşılaştım:\n",
    "#     a) Google Gemini: Başta \"404 Model Not Found\" hatası aldım. Kütüphane versiyonlarımın\n",
    "#        eski olduğunu fark edip `pip install --upgrade` ile tüm paketleri güncelledim.\n",
    "#        Sonrasında ise Google'ın \"Günlük Toplam İstek Limiti\"ne takıldım.\n",
    "#     b) Hugging Face: Burada da \"Model Görev Uyumsuzluğu\" ve kütüphane kurulum hataları\n",
    "#        yaşadım. Düzeltmelerden sonra ise bu kez \"Aylık Ücretsiz Kullanım Kredisi\" bitti.\n",
    "# - KIYMETLİ ÖĞRENİMİM (API TEŞHİS ARACI): Hangi API'ın neden çalışmadığını anlamak için\n",
    "#   tahmin yürütmek yerine, doğrudan API'ye \"hangi modelleri kullanabilirim?\" diye soran\n",
    "#   bir teşhis script'i yazdım. Bu script, kütüphane versiyonu sorununu net bir şekilde\n",
    "#   ortaya çıkardı ve bana kullanabileceğim doğru model isimlerini listeledi. Bu sayede,\n",
    "#   problem çözümünde varsayımlar yerine kanıtlara dayalı hareket etmenin önemini öğrendim.\n",
    "# - ÇÖZÜMÜM: Tek bir API'ye bağımlı kalmak yerine, modüler bir yaklaşım benimsedim.\n",
    "#   Her API sağlayıcısı için ayrı bir \"Veri Üretici\" hücresi oluşturdum ve bu hücrelere\n",
    "#   \"kaldığı yerden devam etme\" mantığı ekledim. Bu, uzun soluklu veri üretme işlemini\n",
    "#   yönetilebilir kıldı.\n",
    "\n",
    "########################################################################################\n",
    "# 3. NİHAİ ÇÖZÜM ve PROJENİN MEVCUT MİMARİSİ\n",
    "########################################################################################\n",
    "# Bu zorluklar sonucunda, projem sadece bir SSS botu olmaktan çıkıp, dayanıklı bir\n",
    "# veri işleme ve RAG pipeline'ına dönüştü.\n",
    "#\n",
    "# - VERİ TARAFI: Artık manuel olarak temizlenmiş bir \"altın\" veri setim ve bu seti\n",
    "#   farklı API'larla zenginleştirebilen modüler script'lerim var.\n",
    "# - BOT TARAFI: Sadece cevap veren bir yapı yerine; konuşma geçmişini hatırlayan (Hafıza),\n",
    "#   bulduğu bilgiyi kendi cümleleriyle anlatan (Dinamik Cevap), hangi kaynaktan\n",
    "#   yararlandığını belirten (Kaynak Gösterme) gelişmiş bir mimari geliştirdim.\n",
    "#\n",
    "# GENEL ÖĞRENİMİM: Bu proje, bir mühendis olarak sadece kod yazmanın değil, aynı zamanda\n",
    "# karşılaşılan sorunları sistematik bir şekilde teşhis etmenin, farklı çözüm yolları\n",
    "# denemenin ve hedefe ulaşmak için gerektiğinde strateji değiştirmenin (pivot) ne kadar\n",
    "# önemli olduğunu bana öğretti.\n",
    "########################################################################################\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3366338-8fa7-43ce-92bd-98c71dfd168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# BLOK 1: KÜTÜPHANELERİN YÜKLENMESİ\n",
    "# ============================================================================\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "\n",
    "print(\"Kütüphaneler yüklendi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ef0f6d-e688-4f80-bfa2-573db17224f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# BLOK 2: API YAPILANDIRMASI\n",
    "# Bu blokta, sadece Google API anahtarımı kullanarak servise bağlantı kurdum.\n",
    "# Henüz bir model seçimi yapmadım.\n",
    "# ============================================================================\n",
    "try:\n",
    "    api_key = os.environ.get('GOOGLE_API_KEY')\n",
    "    if not api_key:\n",
    "        raise ValueError(\"GOOGLE_API_KEY ortam değişkeni bulunamadı.\")\n",
    "    \n",
    "    genai.configure(api_key=api_key)\n",
    "    print(\"Gemini API anahtarı başarıyla yapılandırıldı.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"API yapılandırma hatası: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dd4687-181d-4f2d-9994-a0ce23451923",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# BLOK 2.1: KULLANILABİLİR MODELLERİ LİSTELEME (TEŞHİS ADIMI)\n",
    "# Projenin ilk aşamalarında karşılaştığım \"Model Not Found\" hatalarını\n",
    "# çözmek için bu teşhis adımını uyguladım. API anahtarımın hangi modellere\n",
    "# erişimi olduğunu doğrudan API'ye sorarak, doğru model adını öğrendim.\n",
    "# ============================================================================\n",
    "print(\"\\n----- Bu API Anahtarının Kullanabildiği Modeller -----\")\n",
    "try:\n",
    "    for m in genai.list_models():\n",
    "        if 'generateContent' in m.supported_generation_methods:\n",
    "            print(f\"✅ {m.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Modeller listelenirken bir hata oluştu: {e}\")\n",
    "print(\"-\" * 65)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05284e2-a89d-40ae-8794-202791a59518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# BLOK 2.2: MODEL SEÇİMİ VE KONFİGÜRASYONU\n",
    "# Yukarıdaki listeden edindiğim bilgiyle, projemin bu aşaması için\n",
    "# en uygun olan modeli (hızlı ve verimli) seçip yapılandırdım.\n",
    "# ============================================================================\n",
    "# --- Proje Ayarları ---\n",
    "raw_data_path = '../data/zulip_data.txt'\n",
    "output_json_path = '../data/sss_dataset_augmented.json'\n",
    "# Yukarıdaki listeden 'gemini-2.0-flash' modelini seçtim.\n",
    "MODEL_NAME = \"models/gemini-2.0-flash\" \n",
    "\n",
    "try:\n",
    "    # Seçtiğim model adıyla bir model nesnesi oluşturdum.\n",
    "    model = genai.GenerativeModel(MODEL_NAME)\n",
    "    print(f\"Model seçimi yapıldı ve '{MODEL_NAME}' başarıyla yüklendi.\")\n",
    "except Exception as e:\n",
    "    print(f\"Model yüklenirken hata oluştu: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a82ea19-6eb9-4a90-bbc4-12eccff02122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# BLOK 3: VERİ İŞLEME FONKSİYONLARIM\n",
    "# Bu blokta, ham metin verisini işlemek ve Gemini API'sini kullanarak\n",
    "# zenginleştirmek için yazdığım yardımcı fonksiyonlar yer alıyor.\n",
    "# ============================================================================\n",
    "\n",
    "def parse_zulip_data(file_path):\n",
    "    \"\"\"\n",
    "    Bu fonksiyonu, 'zulip_data.txt' formatındaki ham metin dosyasını okuyup\n",
    "    içindeki Soru-Cevap çiftlerini bir liste olarak ayıklamak için yazdım.\n",
    "    \"\"\"\n",
    "    print(f\"'{file_path}' dosyasındaki ham veri okunuyor...\")\n",
    "    qa_pairs = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        \n",
    "    # Metni \":question:\" ifadesine göre bölerek her bir soru bloğunu ayırdım.\n",
    "    blocks = content.split(':question:')\n",
    "    for block in blocks:\n",
    "        if ':answer:' in block:\n",
    "            # Her bloğu \":answer:\" ifadesine göre soru ve cevap olarak ikiye ayırdım.\n",
    "            parts = block.split(':answer:')\n",
    "            question = parts[0].strip()\n",
    "            answer = parts[1].strip()\n",
    "            if question and answer:\n",
    "                qa_pairs.append({'question': question, 'answer': answer})\n",
    "    print(f\"-> {len(qa_pairs)} adet Soru-Cevap çifti bulundu.\")\n",
    "    return qa_pairs\n",
    "\n",
    "def generate_keywords_for_qa(question, answer):\n",
    "    \"\"\"\n",
    "    Bu fonksiyonu, verilen bir Soru-Cevap çifti için Gemini API'sini kullanarak\n",
    "    ilişkili anahtar kelimeler üretmek amacıyla yazdım.\n",
    "    \"\"\"\n",
    "    # LLM'e ne yapması gerektiğini anlatan bir talimat (prompt) hazırladım.\n",
    "    prompt = f\"Aşağıdaki soru ve cevapla ilgili en önemli 5 anahtar kelimeyi virgülle ayırarak listele. Sadece kelimeleri yaz, başka bir şey ekleme:\\n\\nSORU: \\\"{question}\\\"\\nCEVAP: \\\"{answer}\\\"\\n\\nANAHTAR KELİMELER:\"\n",
    "    # API'ye isteği gönderip cevabı aldım.\n",
    "    response = model.generate_content(prompt)\n",
    "    # Gelen cevabı temizleyip küçük harfe çevirdim.\n",
    "    keywords = {kw.strip().lower() for kw in response.text.split(',')}\n",
    "    return list(keywords)\n",
    "\n",
    "def generate_alternative_questions(question, answer):\n",
    "    \"\"\"\n",
    "    Bu fonksiyonu, verilen bir Soru-Cevap çiftinden yola çıkarak, aynı anlama gelen\n",
    "    4 farklı alternatif soru cümlesi üretmek için yazdım. Bu, veri setimi\n",
    "    zenginleştirmek için kullandığım bir yöntemdi.\n",
    "    \"\"\"\n",
    "    prompt = f\"Aşağıdaki soruya anlamsal olarak benzeyen, aynı cevabı gerektiren 4 farklı soru cümlesi üret. Soruları alt alta, başında numara olmadan yaz.\\n\\nÖRNEK SORU: 'Bootcamp ücretli mi?'\\nÖRNEK ÇIKTI:\\nBootcamp'e katılmak için ödeme yapmam gerekiyor mu?\\nEğitimin bir maliyeti var mı?\\nBu program için ücret talep ediliyor mu?\\nBootcamp katılımı paralı mı?\\n\\nSENİN GÖREVİN:\\nSORU: '{question}'\\nCEVAP: '{answer}'\\n\\nALTERNATİF SORULAR:\"\n",
    "    response = model.generate_content(prompt)\n",
    "    # Gelen cevaptaki her bir satırı ayrı bir soru olarak alıp listeye ekledim.\n",
    "    alt_questions = [q.strip() for q in response.text.split('\\n') if q.strip()]\n",
    "    return alt_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0335b5d-f02a-4a62-9a9a-5d894aba39d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# BLOK 4: ANA İŞ AKIŞIM\n",
    "# Bu blok, yukarıdaki fonksiyonları sırasıyla çağırarak projenin bu ilk\n",
    "# veri işleme adımını baştan sona çalıştırır.\n",
    "# NOT: Bu kod, projenin ilk denemelerini içerdiği için ve API limitleri nedeniyle\n",
    "# artık aktif olarak çalıştırılmamaktadır.\n",
    "# ============================================================================\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Projemin ana veri işleme fonksiyonu.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"🚀 VERİ ZENGİNLEŞTİRME SÜRECİ BAŞLATILDI 🚀\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # 1. Ham veriyi okudum.\n",
    "        qa_dataset = parse_zulip_data(raw_data_path)\n",
    "        \n",
    "        enriched_data = []\n",
    "        # 2. Her bir Soru-Cevap çifti için döngü başlattım.\n",
    "        for i, item in enumerate(qa_dataset):\n",
    "            question = item['question']\n",
    "            answer = item['answer']\n",
    "            print(f\"\\n[{i+1}/{len(qa_dataset)}] İşleniyor: {question[:60]}...\")\n",
    "            \n",
    "            # 3. Anahtar kelimeler ürettim.\n",
    "            print(\"  - Anahtar kelimeler üretiliyor...\")\n",
    "            final_keywords = generate_keywords_for_qa(question, answer)\n",
    "            time.sleep(5) \n",
    "            \n",
    "            # 4. Alternatif sorular ürettim.\n",
    "            print(\"  - Alternatif sorular üretiliyor...\")\n",
    "            all_questions = [question] + generate_alternative_questions(question, answer)\n",
    "            time.sleep(5) \n",
    "            \n",
    "            # 5. Tüm bilgileri tek bir JSON objesinde birleştirdim.\n",
    "            faq_item = {\n",
    "                \"category\": \"Genel\", \"original_question\": question,\n",
    "                \"all_questions\": all_questions, \"answer\": answer,\n",
    "                \"keywords\": list(final_keywords), \"difficulty_level\": \"beginner\"\n",
    "            }\n",
    "            enriched_data.append(faq_item)\n",
    "            \n",
    "            print(f\"  -> Üretilen Keywords: {list(final_keywords)}\")\n",
    "            print(f\"  -> Toplam Soru Varyasyonu: {len(all_questions)}\")\n",
    "\n",
    "        # 6. Sonucu dosyaya yazdım.\n",
    "        with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(enriched_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        print(f\"\\n🎉 BAŞARILI: Veri seti '{output_json_path}' dosyasına kaydedildi!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Kritik bir hata oluştu: {e}\")\n",
    "\n",
    "# Bu if bloğu, script'in sadece doğrudan çalıştırıldığında main() fonksiyonunu\n",
    "# çağırmasını sağlar.\n",
    "if __name__ == \"__main__\":\n",
    "    # main() # Bu satırı, bu eski script'i tekrar çalıştırmamak için yorum satırı yaptım.\n",
    "    print(\"\\nBu not defteri, projenin ilk veri işleme adımlarını belgelemektedir.\")\n",
    "    print(\"Aktif geliştirme diğer not defterlerinde devam etmektedir.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
