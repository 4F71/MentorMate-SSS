{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c5c8796-1ac1-44cf-9bd0-380b4e5f213b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  spaCy kurulu değil\n",
      " FAISS yüklü değil\n",
      "\n",
      " Tüm kütüphaneler yüklendi!\n",
      "Konfigürasyon:\n",
      "  input1: ..\\data\\sss_dataset_augmented.json\n",
      "  input2: ..\\data\\sss_dataset_heavily_augmented.json\n",
      "  out_dir: ../output\n",
      "  n_paraphrases: 30\n",
      "  provider: local\n",
      "  seed: 42\n",
      "  cluster_threshold: 0.3\n",
      "  batch_size: 32\n",
      "================================================================================\n",
      " DEEP SSS ENRICHER BAŞLATILDI\n",
      "================================================================================\n",
      " Yükleniyor: ..\\data\\sss_dataset_augmented.json\n",
      " 14 satır yüklendi\n",
      " Yükleniyor: ..\\data\\sss_dataset_heavily_augmented.json\n",
      " 14 satır yüklendi\n",
      "\n",
      " Veri setleri işleniyor...\n",
      "Toplam satır (birleştirme sonrası): 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding questions: 100%|██████████| 28/28 [00:00<00:00, 1084.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam soru (expand sonrası): 812\n",
      "  Exact tekrar silindi: 56 satır\n",
      " Temizlenmiş veri: 756 satır\n",
      "\n",
      " Embedding model yükleniyor: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 756 metin için embedding üretiliyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 24/24 [00:11<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Semantik kümeleme yapılıyor (threshold=0.3)...\n",
      " 93 küme oluşturuldu\n",
      "\n",
      "Canonical sorular oluşturuluyor...\n",
      " 93 canonical soru oluşturuldu\n",
      " 23 küme inceleme gerekiyor\n",
      "\n",
      " Paraphrase üretimi (30 varyasyon/soru)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paraphrasing: 100%|█████████████████████████████| 93/93 [00:07<00:00, 12.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 261 yeni paraphrase oluşturuldu\n",
      "\n",
      " Toplam satır (paraphrase sonrası): 1017\n",
      "\n",
      " Metadata zenginleştiriliyor...\n",
      " Metadata zenginleştirme tamamlandı\n",
      "\\ Tüm çıktılar kaydedildi!\n",
      "================================================================================\n",
      " İŞLEM TAMAMLANDI\n",
      "================================================================================\n",
      " Toplam kayıt: 1,017\n",
      " Orijinal kayıt: 0\n",
      " Paraphrase kayıt: 261\n",
      " Küme sayısı: 93\n",
      " Canonical soru: 93\n",
      "  İnceleme gereken: 23\n",
      "  İşlem süresi: 22.63 saniye\n",
      " Çıktı dizini: ../output\n",
      "================================================================================\n",
      "\n",
      " Örnek Canonical Sorular:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>canonical_question</th>\n",
       "      <th>canonical_answer</th>\n",
       "      <th>category</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>**Bootcamp Sertifikası Alacak mıyım?**</td>\n",
       "      <td>Evet, bootcamp sonunda projenizi başarıyla tam...</td>\n",
       "      <td>Genel</td>\n",
       "      <td>bootcamp, iş imkanı, staj imkanı, bootcamp iş ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Canlı yayınlar arşivleniyor mu?</td>\n",
       "      <td>Evet, tüm canlı yayınlar kaydedilmekte ve **Yo...</td>\n",
       "      <td>Genel</td>\n",
       "      <td>canlı yayın yoklama, katılım belgesi, canlı ya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16.0</td>\n",
       "      <td>Bu projeyi takım halinde mi gerçekleştirmeliyiz?</td>\n",
       "      <td>Projeleri tek başınıza ya da en fazla 2 kişili...</td>\n",
       "      <td>Genel</td>\n",
       "      <td>grup projesi, tek kişilik proje, proje grup zo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Grup kurmak zorunda mıyım?</td>\n",
       "      <td>Projeleri tek başınıza ya da en fazla 2 kişili...</td>\n",
       "      <td>Genel</td>\n",
       "      <td>grup projesi, tek kişilik proje, proje grup zo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>69.0</td>\n",
       "      <td>Projeyi ekipçe yürütmemiz mi bekleniyor?</td>\n",
       "      <td>Projeleri tek başınıza ya da en fazla 2 kişili...</td>\n",
       "      <td>Genel</td>\n",
       "      <td>grup projesi, tek kişilik proje, proje grup zo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Mentor buluşmalarına katılmak faydalı mı?</td>\n",
       "      <td>Mentor toplantıları ve saatleri, Zulip'teki du...</td>\n",
       "      <td>Genel</td>\n",
       "      <td>mentor toplantıları, mentor toplantı saatleri,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Kodumu GitHub'a hızlıca nasıl yükleyebilirim?</td>\n",
       "      <td>Web arayüzü ile yükleme: https://www.youtube.c...</td>\n",
       "      <td>Genel</td>\n",
       "      <td>GitHub'a kod yükleme, Git kullanmadan GitHub, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>37.0</td>\n",
       "      <td>YouTube kanalınızın adı nedir?</td>\n",
       "      <td>Evet, tüm canlı yayınlar kaydedilmekte ve **Yo...</td>\n",
       "      <td>Genel</td>\n",
       "      <td>Youtube Canlı Yayın, Canlı Yayın Yoklama, Katı...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>71.0</td>\n",
       "      <td>Sertifika'da İsim-Harf Problemi</td>\n",
       "      <td>Merhaba, Bazı kullanıcılarımız sertifikalarınd...</td>\n",
       "      <td>Genel</td>\n",
       "      <td>sertifika isim hatası, sertifika karakter soru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>91.0</td>\n",
       "      <td>Belgelerdeki ad yazımında harf yanlışlığı</td>\n",
       "      <td>Merhaba, Bazı kullanıcılarımız sertifikalarınd...</td>\n",
       "      <td>Genel</td>\n",
       "      <td>sertifika isim hatası, sertifika karakter soru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cluster_id                                canonical_question  \\\n",
       "0          0.0            **Bootcamp Sertifikası Alacak mıyım?**   \n",
       "8         22.0                   Canlı yayınlar arşivleniyor mu?   \n",
       "17        16.0  Bu projeyi takım halinde mi gerçekleştirmeliyiz?   \n",
       "18         2.0                        Grup kurmak zorunda mıyım?   \n",
       "19        69.0          Projeyi ekipçe yürütmemiz mi bekleniyor?   \n",
       "20         1.0         Mentor buluşmalarına katılmak faydalı mı?   \n",
       "28         9.0     Kodumu GitHub'a hızlıca nasıl yükleyebilirim?   \n",
       "32        37.0                    YouTube kanalınızın adı nedir?   \n",
       "36        71.0                   Sertifika'da İsim-Harf Problemi   \n",
       "38        91.0         Belgelerdeki ad yazımında harf yanlışlığı   \n",
       "\n",
       "                                     canonical_answer category  \\\n",
       "0   Evet, bootcamp sonunda projenizi başarıyla tam...    Genel   \n",
       "8   Evet, tüm canlı yayınlar kaydedilmekte ve **Yo...    Genel   \n",
       "17  Projeleri tek başınıza ya da en fazla 2 kişili...    Genel   \n",
       "18  Projeleri tek başınıza ya da en fazla 2 kişili...    Genel   \n",
       "19  Projeleri tek başınıza ya da en fazla 2 kişili...    Genel   \n",
       "20  Mentor toplantıları ve saatleri, Zulip'teki du...    Genel   \n",
       "28  Web arayüzü ile yükleme: https://www.youtube.c...    Genel   \n",
       "32  Evet, tüm canlı yayınlar kaydedilmekte ve **Yo...    Genel   \n",
       "36  Merhaba, Bazı kullanıcılarımız sertifikalarınd...    Genel   \n",
       "38  Merhaba, Bazı kullanıcılarımız sertifikalarınd...    Genel   \n",
       "\n",
       "                                             keywords  \n",
       "0   bootcamp, iş imkanı, staj imkanı, bootcamp iş ...  \n",
       "8   canlı yayın yoklama, katılım belgesi, canlı ya...  \n",
       "17  grup projesi, tek kişilik proje, proje grup zo...  \n",
       "18  grup projesi, tek kişilik proje, proje grup zo...  \n",
       "19  grup projesi, tek kişilik proje, proje grup zo...  \n",
       "20  mentor toplantıları, mentor toplantı saatleri,...  \n",
       "28  GitHub'a kod yükleme, Git kullanmadan GitHub, ...  \n",
       "32  Youtube Canlı Yayın, Canlı Yayın Yoklama, Katı...  \n",
       "36  sertifika isim hatası, sertifika karakter soru...  \n",
       "38  sertifika isim hatası, sertifika karakter soru...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Örnek Paraphrase'ler:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>original_question</th>\n",
       "      <th>category</th>\n",
       "      <th>keywords</th>\n",
       "      <th>difficulty_level</th>\n",
       "      <th>source</th>\n",
       "      <th>created_at</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>canonical_question</th>\n",
       "      <th>canonical_answer</th>\n",
       "      <th>cluster_size</th>\n",
       "      <th>is_canonical</th>\n",
       "      <th>canonical_id</th>\n",
       "      <th>augmentation_method</th>\n",
       "      <th>confidence</th>\n",
       "      <th>id</th>\n",
       "      <th>intent</th>\n",
       "      <th>entities</th>\n",
       "      <th>difficulty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>**bootcamp sertifikası alacak mıyım?**?</td>\n",
       "      <td>Evet, bootcamp sonunda projenizi başarıyla tam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>courses</td>\n",
       "      <td>bootcamp, alacak, sertifikası, mıyım</td>\n",
       "      <td>NaN</td>\n",
       "      <td>generated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>**Bootcamp Sertifikası Alacak mıyım?**</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>paraphrase_local</td>\n",
       "      <td>0.787344</td>\n",
       "      <td>140d4588eb60f4d5</td>\n",
       "      <td>information</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>**bootcamp sertifikası alacak mıyım?** hakkınd...</td>\n",
       "      <td>Evet, bootcamp sonunda projenizi başarıyla tam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>courses</td>\n",
       "      <td>bootcamp, verir, sertifikası, bilgi, hakkında</td>\n",
       "      <td>NaN</td>\n",
       "      <td>generated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>**Bootcamp Sertifikası Alacak mıyım?**</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>paraphrase_local</td>\n",
       "      <td>0.750345</td>\n",
       "      <td>de5e6100b415ffce</td>\n",
       "      <td>information</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>**bootcamp sertifikası alacak mıyım?** konusun...</td>\n",
       "      <td>Evet, bootcamp sonunda projenizi başarıyla tam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>courses</td>\n",
       "      <td>bootcamp, sertifikası, konusunda, olabilir, al...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>generated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>**Bootcamp Sertifikası Alacak mıyım?**</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>paraphrase_local</td>\n",
       "      <td>0.740952</td>\n",
       "      <td>43dc39c20ac1ecc9</td>\n",
       "      <td>information</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>**bootcamp sertifikası alacak mıyım?**</td>\n",
       "      <td>Evet, bootcamp sonunda projenizi başarıyla tam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>courses</td>\n",
       "      <td>bootcamp, alacak, sertifikası, mıyım</td>\n",
       "      <td>NaN</td>\n",
       "      <td>generated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>**Bootcamp Sertifikası Alacak mıyım?**</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>paraphrase_local</td>\n",
       "      <td>0.848164</td>\n",
       "      <td>46da9f877cc008bc</td>\n",
       "      <td>information</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>Canlı yayınlar arşivleniyor mu??</td>\n",
       "      <td>Evet, tüm canlı yayınlar kaydedilmekte ve **Yo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>general</td>\n",
       "      <td>canlı, yayınlar, arşivleniyor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>generated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Canlı yayınlar arşivleniyor mu?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>22.0</td>\n",
       "      <td>paraphrase_local</td>\n",
       "      <td>0.866781</td>\n",
       "      <td>8e5dded6322d5a7f</td>\n",
       "      <td>information</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>Canlı yayınlar arşivleniyor mu? hakkında bilgi...</td>\n",
       "      <td>Evet, tüm canlı yayınlar kaydedilmekte ve **Yo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>general</td>\n",
       "      <td>verir, bilgi, hakkında, canlı, misiniz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>generated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Canlı yayınlar arşivleniyor mu?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>22.0</td>\n",
       "      <td>paraphrase_local</td>\n",
       "      <td>0.798673</td>\n",
       "      <td>d6b30092cedc3ab5</td>\n",
       "      <td>information</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>Canlı yayınlar arşivleniyor mu? konusunda yard...</td>\n",
       "      <td>Evet, tüm canlı yayınlar kaydedilmekte ve **Yo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>support</td>\n",
       "      <td>konusunda, olabilir, canlı, misiniz, yayınlar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>generated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Canlı yayınlar arşivleniyor mu?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>22.0</td>\n",
       "      <td>paraphrase_local</td>\n",
       "      <td>0.790438</td>\n",
       "      <td>de9a60a0749731ce</td>\n",
       "      <td>information</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>Canlı yayınlar arşivleniyor mu?</td>\n",
       "      <td>Evet, tüm canlı yayınlar kaydedilmekte ve **Yo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>general</td>\n",
       "      <td>canlı, yayınlar, arşivleniyor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>generated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Canlı yayınlar arşivleniyor mu?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>22.0</td>\n",
       "      <td>paraphrase_local</td>\n",
       "      <td>0.859113</td>\n",
       "      <td>059091a1c6046881</td>\n",
       "      <td>information</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>Bu projeyi takım halinde mi gerçekleştirmeliyi...</td>\n",
       "      <td>Projeleri tek başınıza ya da en fazla 2 kişili...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>general</td>\n",
       "      <td>verir, gerçekleştirmeliyiz, takım, halinde, ha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>generated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bu projeyi takım halinde mi gerçekleştirmeliyiz?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>16.0</td>\n",
       "      <td>paraphrase_local</td>\n",
       "      <td>0.921963</td>\n",
       "      <td>203802ce140d2a32</td>\n",
       "      <td>information</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>Bu projeyi takım halinde mi gerçekleştirmeliyi...</td>\n",
       "      <td>Projeleri tek başınıza ya da en fazla 2 kişili...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>support</td>\n",
       "      <td>gerçekleştirmeliyiz, takım, halinde, konusunda...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>generated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bu projeyi takım halinde mi gerçekleştirmeliyiz?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>16.0</td>\n",
       "      <td>paraphrase_local</td>\n",
       "      <td>0.901847</td>\n",
       "      <td>4f554fa9ea0c6cb6</td>\n",
       "      <td>information</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "756            **bootcamp sertifikası alacak mıyım?**?   \n",
       "757  **bootcamp sertifikası alacak mıyım?** hakkınd...   \n",
       "758  **bootcamp sertifikası alacak mıyım?** konusun...   \n",
       "759             **bootcamp sertifikası alacak mıyım?**   \n",
       "760                   Canlı yayınlar arşivleniyor mu??   \n",
       "761  Canlı yayınlar arşivleniyor mu? hakkında bilgi...   \n",
       "762  Canlı yayınlar arşivleniyor mu? konusunda yard...   \n",
       "763                    Canlı yayınlar arşivleniyor mu?   \n",
       "764  Bu projeyi takım halinde mi gerçekleştirmeliyi...   \n",
       "765  Bu projeyi takım halinde mi gerçekleştirmeliyi...   \n",
       "\n",
       "                                                answer original_question  \\\n",
       "756  Evet, bootcamp sonunda projenizi başarıyla tam...               NaN   \n",
       "757  Evet, bootcamp sonunda projenizi başarıyla tam...               NaN   \n",
       "758  Evet, bootcamp sonunda projenizi başarıyla tam...               NaN   \n",
       "759  Evet, bootcamp sonunda projenizi başarıyla tam...               NaN   \n",
       "760  Evet, tüm canlı yayınlar kaydedilmekte ve **Yo...               NaN   \n",
       "761  Evet, tüm canlı yayınlar kaydedilmekte ve **Yo...               NaN   \n",
       "762  Evet, tüm canlı yayınlar kaydedilmekte ve **Yo...               NaN   \n",
       "763  Evet, tüm canlı yayınlar kaydedilmekte ve **Yo...               NaN   \n",
       "764  Projeleri tek başınıza ya da en fazla 2 kişili...               NaN   \n",
       "765  Projeleri tek başınıza ya da en fazla 2 kişili...               NaN   \n",
       "\n",
       "    category                                           keywords  \\\n",
       "756  courses               bootcamp, alacak, sertifikası, mıyım   \n",
       "757  courses      bootcamp, verir, sertifikası, bilgi, hakkında   \n",
       "758  courses  bootcamp, sertifikası, konusunda, olabilir, al...   \n",
       "759  courses               bootcamp, alacak, sertifikası, mıyım   \n",
       "760  general                      canlı, yayınlar, arşivleniyor   \n",
       "761  general             verir, bilgi, hakkında, canlı, misiniz   \n",
       "762  support      konusunda, olabilir, canlı, misiniz, yayınlar   \n",
       "763  general                      canlı, yayınlar, arşivleniyor   \n",
       "764  general  verir, gerçekleştirmeliyiz, takım, halinde, ha...   \n",
       "765  support  gerçekleştirmeliyiz, takım, halinde, konusunda...   \n",
       "\n",
       "    difficulty_level     source created_at  cluster_id  \\\n",
       "756              NaN  generated        NaN         NaN   \n",
       "757              NaN  generated        NaN         NaN   \n",
       "758              NaN  generated        NaN         NaN   \n",
       "759              NaN  generated        NaN         NaN   \n",
       "760              NaN  generated        NaN         NaN   \n",
       "761              NaN  generated        NaN         NaN   \n",
       "762              NaN  generated        NaN         NaN   \n",
       "763              NaN  generated        NaN         NaN   \n",
       "764              NaN  generated        NaN         NaN   \n",
       "765              NaN  generated        NaN         NaN   \n",
       "\n",
       "                                   canonical_question canonical_answer  \\\n",
       "756            **Bootcamp Sertifikası Alacak mıyım?**              NaN   \n",
       "757            **Bootcamp Sertifikası Alacak mıyım?**              NaN   \n",
       "758            **Bootcamp Sertifikası Alacak mıyım?**              NaN   \n",
       "759            **Bootcamp Sertifikası Alacak mıyım?**              NaN   \n",
       "760                   Canlı yayınlar arşivleniyor mu?              NaN   \n",
       "761                   Canlı yayınlar arşivleniyor mu?              NaN   \n",
       "762                   Canlı yayınlar arşivleniyor mu?              NaN   \n",
       "763                   Canlı yayınlar arşivleniyor mu?              NaN   \n",
       "764  Bu projeyi takım halinde mi gerçekleştirmeliyiz?              NaN   \n",
       "765  Bu projeyi takım halinde mi gerçekleştirmeliyiz?              NaN   \n",
       "\n",
       "     cluster_size  is_canonical  canonical_id augmentation_method  confidence  \\\n",
       "756           NaN         False           0.0    paraphrase_local    0.787344   \n",
       "757           NaN         False           0.0    paraphrase_local    0.750345   \n",
       "758           NaN         False           0.0    paraphrase_local    0.740952   \n",
       "759           NaN         False           0.0    paraphrase_local    0.848164   \n",
       "760           NaN         False          22.0    paraphrase_local    0.866781   \n",
       "761           NaN         False          22.0    paraphrase_local    0.798673   \n",
       "762           NaN         False          22.0    paraphrase_local    0.790438   \n",
       "763           NaN         False          22.0    paraphrase_local    0.859113   \n",
       "764           NaN         False          16.0    paraphrase_local    0.921963   \n",
       "765           NaN         False          16.0    paraphrase_local    0.901847   \n",
       "\n",
       "                   id       intent entities difficulty  \n",
       "756  140d4588eb60f4d5  information                 NaN  \n",
       "757  de5e6100b415ffce  information                 NaN  \n",
       "758  43dc39c20ac1ecc9  information                 NaN  \n",
       "759  46da9f877cc008bc  information                 NaN  \n",
       "760  8e5dded6322d5a7f  information                 NaN  \n",
       "761  d6b30092cedc3ab5  information                 NaN  \n",
       "762  de9a60a0749731ce  information                 NaN  \n",
       "763  059091a1c6046881  information                 NaN  \n",
       "764  203802ce140d2a32  information                 NaN  \n",
       "765  4f554fa9ea0c6cb6  information                 NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Kategori Dağılımı:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "category\n",
       "Genel            756\n",
       "general          131\n",
       "support           68\n",
       "certification     41\n",
       "account           13\n",
       "courses            8\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Intent Dağılımı:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "intent\n",
       "information    716\n",
       "how_to         161\n",
       "definition     114\n",
       "reasoning       18\n",
       "timing           8\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import time\n",
    "import re\n",
    "import hashlib\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm  \n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "try:\n",
    "    import spacy\n",
    "    try:\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        print(\"spaCy modeli yüklendi\")\n",
    "    except:\n",
    "        print(\"  spaCy modeli bulunamadı, basit mod aktif\")\n",
    "        nlp = None\n",
    "except ImportError:\n",
    "    nlp = None\n",
    "    print(\"  spaCy kurulu değil\")\n",
    "\n",
    "import requests\n",
    "\n",
    "try:\n",
    "    import faiss\n",
    "    FAISS_AVAILABLE = True\n",
    "    print(\" FAISS kullanılabilir\")\n",
    "except:\n",
    "    FAISS_AVAILABLE = False\n",
    "    print(\" FAISS yüklü değil\")\n",
    "\n",
    "print(\"\\n Tüm kütüphaneler yüklendi!\")\n",
    "\n",
    "\n",
    "CONFIG = {\n",
    "    'input1': r'..\\data\\sss_dataset_augmented.json',\n",
    "    'input2': r'..\\data\\sss_dataset_heavily_augmented.json',\n",
    "    'out_dir': '../output',\n",
    "    'n_paraphrases': 30,\n",
    "    'provider': 'local',  \n",
    "    'api_key': None,  \n",
    "    'seed': 42,\n",
    "    'cluster_threshold': 0.3,\n",
    "    'batch_size': 32\n",
    "}\n",
    "\n",
    "print(\"Konfigürasyon:\")\n",
    "for key, value in CONFIG.items():\n",
    "    if key != 'api_key':\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "def setup_logger(log_dir: str) -> logging.Logger:\n",
    "    \"\"\"Log yapılandırması\"\"\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    log_file = os.path.join(log_dir, f\"enricher_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")\n",
    "    \n",
    "    logger = logging.getLogger(\"DeepEnricher\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.handlers = []  \n",
    "    \n",
    "    fh = logging.FileHandler(log_file, encoding='utf-8')\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    fh.setFormatter(formatter)\n",
    "    logger.addHandler(fh)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "def normalize_text(text: str) -> str:\n",
    "    \n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).strip()\n",
    "    text = text.encode('utf-8', 'ignore').decode('utf-8')\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def load_dataset(file_path: str) -> pd.DataFrame:\n",
    "    \n",
    "    print(f\" Yükleniyor: {file_path}\")\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Dosya bulunamadı: {file_path}\")\n",
    "    \n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    \n",
    "    if ext == '.csv':\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    elif ext == '.jsonl':\n",
    "        df = pd.read_json(file_path, lines=True, encoding='utf-8')\n",
    "    elif ext == '.json':\n",
    "        try:\n",
    "            df = pd.read_json(file_path, encoding='utf-8')\n",
    "        except:\n",
    "            df = pd.read_json(file_path, lines=True, encoding='utf-8')\n",
    "    else:\n",
    "        raise ValueError(f\"Desteklenmeyen format: {ext}\")\n",
    "    \n",
    "    print(f\" {len(df)} satır yüklendi\")\n",
    "    return df\n",
    "\n",
    "def merge_and_deduplicate(df1: pd.DataFrame, df2: pd.DataFrame) -> pd.DataFrame:\n",
    "    print(\"\\n Veri setleri işleniyor...\")\n",
    "    \n",
    "    \n",
    "    combined = pd.concat([df1, df2], ignore_index=True)\n",
    "    print(f\"Toplam satır (birleştirme sonrası): {len(combined)}\")\n",
    "    \n",
    "    combined.columns = combined.columns.str.lower().str.strip()\n",
    "    \n",
    "    expanded_rows = []\n",
    "    \n",
    "    for idx, row in tqdm(combined.iterrows(), total=len(combined), desc=\"Expanding questions\"):\n",
    "        all_questions = row['all_questions']\n",
    "        \n",
    "        if isinstance(all_questions, str):\n",
    "            try:\n",
    "                all_questions = eval(all_questions)\n",
    "            except:\n",
    "                all_questions = [all_questions]\n",
    "        \n",
    "        if isinstance(all_questions, list) and len(all_questions) > 0:\n",
    "            if isinstance(all_questions[0], dict):\n",
    "                questions = [q.get('question', q.get('text', '')) for q in all_questions]\n",
    "            else:\n",
    "                questions = all_questions\n",
    "        else:\n",
    "            questions = [row.get('original_question', '')]\n",
    "        \n",
    "        for question in questions:\n",
    "            expanded_rows.append({\n",
    "                'question': normalize_text(str(question)),\n",
    "                'answer': normalize_text(str(row['answer'])),\n",
    "                'original_question': normalize_text(str(row['original_question'])),\n",
    "                'category': row.get('category', 'general'),\n",
    "                'keywords': row.get('keywords', ''),\n",
    "                'difficulty_level': row.get('difficulty_level', 'medium'),\n",
    "                'source': 'original'\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(expanded_rows)\n",
    "    print(f\"Toplam soru (expand sonrası): {len(df)}\")\n",
    "    \n",
    "    df = df[df['question'].str.len() > 0]\n",
    "    df = df[df['answer'].str.len() > 0]\n",
    "    \n",
    "    initial_count = len(df)\n",
    "    df = df.drop_duplicates(subset=['question', 'answer'], keep='first')\n",
    "    print(f\"  Exact tekrar silindi: {initial_count - len(df)} satır\")\n",
    "    \n",
    "    df['created_at'] = datetime.now().isoformat()\n",
    "    \n",
    "    df = df.reset_index(drop=True)\n",
    "    print(f\" Temizlenmiş veri: {len(df)} satır\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_embeddings(texts: List[str], model_name: str = 'sentence-transformers/all-MiniLM-L6-v2') -> np.ndarray:\n",
    "    print(f\"\\n Embedding model yükleniyor: {model_name}\")\n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    print(f\" {len(texts)} metin için embedding üretiliyor...\")\n",
    "    embeddings = model.encode(texts, show_progress_bar=True, batch_size=32)\n",
    "    \n",
    "    return embeddings, model\n",
    "\n",
    "def cluster_questions(df: pd.DataFrame, embeddings: np.ndarray, threshold: float) -> pd.DataFrame:\n",
    "    print(f\"\\n Semantik kümeleme yapılıyor (threshold={threshold})...\")\n",
    "    \n",
    "    clustering = AgglomerativeClustering(\n",
    "        n_clusters=None,\n",
    "        distance_threshold=threshold,\n",
    "        linkage='average',\n",
    "        metric='cosine'\n",
    "    )\n",
    "    \n",
    "    clusters = clustering.fit_predict(embeddings)\n",
    "    df['cluster_id'] = clusters\n",
    "    \n",
    "    n_clusters = len(set(clusters))\n",
    "    print(f\" {n_clusters} küme oluşturuldu\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def select_canonical(group: pd.DataFrame) -> pd.Series:\n",
    "    group = group.copy()\n",
    "    group['q_len'] = group['question'].str.len()\n",
    "    canonical_row = group.sort_values('q_len').iloc[0]\n",
    "    \n",
    "    unique_answers = group['answer'].unique()\n",
    "    \n",
    "    if len(unique_answers) == 1:\n",
    "        canonical_answer = unique_answers[0]\n",
    "        needs_review = False\n",
    "    else:\n",
    "        canonical_answer = canonical_row['answer']\n",
    "        needs_review = True\n",
    "    \n",
    "    return pd.Series({\n",
    "        'canonical_question': canonical_row['question'],\n",
    "        'canonical_answer': canonical_answer,\n",
    "        'cluster_size': len(group),\n",
    "        'needs_review': needs_review,\n",
    "        'initial_sources': '; '.join(group['source'].unique())\n",
    "    })\n",
    "\n",
    "def canonicalize_clusters(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    print(\"\\nCanonical sorular oluşturuluyor...\")\n",
    "    \n",
    "    canonical_df = df.groupby('cluster_id').apply(select_canonical).reset_index()\n",
    "    review_needed = canonical_df[canonical_df['needs_review'] == True].copy()\n",
    "    \n",
    "    df = df.merge(\n",
    "        canonical_df[['cluster_id', 'canonical_question', 'canonical_answer', 'cluster_size']],\n",
    "        on='cluster_id',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    print(f\" {len(canonical_df)} canonical soru oluşturuldu\")\n",
    "    print(f\" {len(review_needed)} küme inceleme gerekiyor\")\n",
    "    \n",
    "    return df, review_needed\n",
    "\n",
    "\n",
    "class ParaphraseGenerator:\n",
    "    \n",
    "    def __init__(self, provider: str, api_key: str = None, seed: int = 42):\n",
    "        self.provider = provider\n",
    "        self.api_key = api_key\n",
    "        self.seed = seed\n",
    "        \n",
    "    def generate(self, question: str, n: int) -> List[str]:\n",
    "        if self.provider == 'local':\n",
    "            return self._local_paraphrase(question, n)\n",
    "        elif self.provider == 'anthropic':\n",
    "            return self._anthropic_paraphrase(question, n)\n",
    "        elif self.provider == 'openai':\n",
    "            return self._openai_paraphrase(question, n)\n",
    "        else:\n",
    "            print(f\" Bilinmeyen provider: {self.provider}\")\n",
    "            return []\n",
    "    \n",
    "    def _local_paraphrase(self, question: str, n: int) -> List[str]:\n",
    "        synonyms = {\n",
    "            'nasıl': ['ne şekilde', 'hangi yolla', 'ne biçimde'],\n",
    "            'nedir': ['ne demektir', 'nedir', 'ne anlama gelir'],\n",
    "            'yapabilirim': ['yapabilir miyim', 'yapmak mümkün mü', 'yapma imkanı var mı'],\n",
    "            'öğrenmek': ['bilgi edinmek', 'hakkında bilgi almak', 'öğrenmek'],\n",
    "            'ne zaman': ['hangi zamanda', 'ne vakit'],\n",
    "            'nerede': ['hangi yerde', 'nerede'],\n",
    "            'kim': ['hangi kişi', 'kimler'],\n",
    "        }\n",
    "        \n",
    "        paraphrases = []\n",
    "        \n",
    "        for i in range(min(n, 10)):\n",
    "            new_q = question\n",
    "            for word, syns in synonyms.items():\n",
    "                if word in new_q.lower():\n",
    "                    new_q = new_q.lower().replace(word, np.random.choice(syns))\n",
    "            \n",
    "            # Varyasyonlar\n",
    "            if i % 4 == 0:\n",
    "                new_q = new_q.capitalize() + \"?\"\n",
    "            elif i % 4 == 1:\n",
    "                new_q = new_q.capitalize() + \" hakkında bilgi verir misiniz?\"\n",
    "            elif i % 4 == 2:\n",
    "                new_q = new_q.capitalize() + \" konusunda yardımcı olabilir misiniz?\"\n",
    "            else:\n",
    "                new_q = new_q.capitalize()\n",
    "            \n",
    "            if new_q not in paraphrases:\n",
    "                paraphrases.append(new_q)\n",
    "        \n",
    "        return paraphrases[:n]\n",
    "    \n",
    "    def _anthropic_paraphrase(self, question: str, n: int) -> List[str]:\n",
    "\n",
    "        url = \"https://api.anthropic.com/v1/messages\"\n",
    "        headers = {\n",
    "            \"x-api-key\": self.api_key,\n",
    "            \"anthropic-version\": \"2023-06-01\",\n",
    "            \"content-type\": \"application/json\"\n",
    "        }\n",
    "        \n",
    "        paraphrases = []\n",
    "        batch_size = 5\n",
    "        \n",
    "        for batch_idx in range(0, n, batch_size):\n",
    "            batch_n = min(batch_size, n - batch_idx)\n",
    "            \n",
    "            prompt = f\"\"\"Aşağıdaki soruyu {batch_n} farklı şekilde yeniden ifade et.\n",
    "\n",
    "KURALLAR:\n",
    "- Sorunun ANLAMINI ve AMACINI KESINLIKLE değiştirme\n",
    "- Yeni bilgi EKLEME veya ÇIKARMA\n",
    "- Her varyasyon farklı bir tarzda olsun\n",
    "- Her satıra sadece BIR soru yaz\n",
    "- Ekstra açıklama yapma\n",
    "\n",
    "SORU: {question}\n",
    "\n",
    "ÇIKTI:\"\"\"\n",
    "\n",
    "            payload = {\n",
    "                \"model\": \"claude-3-5-sonnet-20241022\",\n",
    "                \"max_tokens\": 1024,\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                response = requests.post(url, headers=headers, json=payload, timeout=30)\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    content = response.json()['content'][0]['text']\n",
    "                    lines = [l.strip() for l in content.strip().split('\\n') if l.strip() and '?' in l]\n",
    "                    paraphrases.extend(lines[:batch_n])\n",
    "                elif response.status_code == 429:\n",
    "                    print(\" Rate limit, bekleniyor...\")\n",
    "                    time.sleep(10)\n",
    "                \n",
    "                time.sleep(1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\" Request hatası: {e}\")\n",
    "        \n",
    "        return paraphrases[:n]\n",
    "    \n",
    "    def _openai_paraphrase(self, question: str, n: int) -> List[str]:\n",
    "        return self._local_paraphrase(question, n)\n",
    "\n",
    "def generate_paraphrases(df: pd.DataFrame, generator: ParaphraseGenerator, \n",
    "                        n_per_question: int, embeddings: np.ndarray, \n",
    "                        model: SentenceTransformer) -> pd.DataFrame:\n",
    "    print(f\"\\n Paraphrase üretimi ({n_per_question} varyasyon/soru)...\")\n",
    "    \n",
    "    canonical_questions = df[['cluster_id', 'canonical_question', 'canonical_answer']].drop_duplicates('cluster_id')\n",
    "    \n",
    "    all_rows = []\n",
    "    \n",
    "    for idx, row in tqdm(canonical_questions.iterrows(), total=len(canonical_questions), desc=\"Paraphrasing\", ncols=80):\n",
    "        question = row['canonical_question']\n",
    "        answer = row['canonical_answer']\n",
    "        cluster_id = row['cluster_id']\n",
    "        \n",
    "        paraphrases = generator.generate(question, n_per_question)\n",
    "        \n",
    "        if not paraphrases:\n",
    "            continue\n",
    "        \n",
    "        para_embeddings = model.encode(paraphrases, show_progress_bar=False)\n",
    "        orig_embedding = embeddings[df[df['cluster_id'] == cluster_id].index[0]].reshape(1, -1)\n",
    "        \n",
    "        for para, para_emb in zip(paraphrases, para_embeddings):\n",
    "            similarity = cosine_similarity(orig_embedding, para_emb.reshape(1, -1))[0][0]\n",
    "            \n",
    "            if similarity > 0.95 or similarity < 0.70:\n",
    "                continue\n",
    "            \n",
    "            all_rows.append({\n",
    "                'question': para,\n",
    "                'answer': answer,\n",
    "                'canonical_question': question,\n",
    "                'canonical_id': cluster_id,\n",
    "                'is_canonical': False,\n",
    "                'augmentation_method': f'paraphrase_{generator.provider}',\n",
    "                'confidence': float(similarity),\n",
    "                'source': 'generated'\n",
    "            })\n",
    "    \n",
    "    print(f\" {len(all_rows)} yeni paraphrase oluşturuldu\")\n",
    "    \n",
    "    return pd.DataFrame(all_rows)\n",
    "\n",
    "\n",
    "def enrich_metadata(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    print(\"\\n Metadata zenginleştiriliyor...\")\n",
    "    \n",
    "    df['id'] = df.apply(lambda x: hashlib.md5(f\"{x['question']}_{x['answer']}\".encode()).hexdigest()[:16], axis=1)\n",
    "    \n",
    "    if 'canonical_id' not in df.columns:\n",
    "        df['canonical_id'] = df.get('cluster_id', 0)\n",
    "    \n",
    "    if 'is_canonical' not in df.columns:\n",
    "        df['is_canonical'] = False\n",
    "    \n",
    "    if 'category' not in df.columns or df['category'].isna().any():\n",
    "        def predict_category(question: str) -> str:\n",
    "            question_lower = question.lower()\n",
    "            \n",
    "            if any(kw in question_lower for kw in ['kayıt', 'üye', 'hesap']):\n",
    "                return 'account'\n",
    "            elif any(kw in question_lower for kw in ['ders', 'kurs', 'eğitim', 'bootcamp']):\n",
    "                return 'courses'\n",
    "            elif any(kw in question_lower for kw in ['ödeme', 'fiyat', 'ücret']):\n",
    "                return 'payment'\n",
    "            elif any(kw in question_lower for kw in ['sertifika', 'diploma']):\n",
    "                return 'certification'\n",
    "            elif any(kw in question_lower for kw in ['destek', 'yardım', 'sorun']):\n",
    "                return 'support'\n",
    "            else:\n",
    "                return 'general'\n",
    "        \n",
    "        df['category'] = df['category'].fillna(df['question'].apply(predict_category))\n",
    "    \n",
    "    def predict_intent(question: str) -> str:\n",
    "        question_lower = question.lower()\n",
    "        \n",
    "        if any(kw in question_lower for kw in ['nasıl', 'ne şekilde', 'how']):\n",
    "            return 'how_to'\n",
    "        elif any(kw in question_lower for kw in ['nedir', 'ne demek', 'what']):\n",
    "            return 'definition'\n",
    "        elif any(kw in question_lower for kw in ['neden', 'niçin', 'why']):\n",
    "            return 'reasoning'\n",
    "        elif any(kw in question_lower for kw in ['ne zaman', 'when']):\n",
    "            return 'timing'\n",
    "        else:\n",
    "            return 'information'\n",
    "    \n",
    "    df['intent'] = df['question'].apply(predict_intent)\n",
    "    \n",
    "    if 'keywords' not in df.columns or df['keywords'].isna().any():\n",
    "        def extract_keywords(text: str) -> str:\n",
    "            words = re.findall(r'\\b\\w{4,}\\b', text.lower())\n",
    "            return ', '.join(list(set(words))[:5])\n",
    "        \n",
    "        df['keywords'] = df['keywords'].fillna(df['question'].apply(extract_keywords))\n",
    "    \n",
    "    df['keywords'] = df['keywords'].apply(lambda x: ', '.join(x) if isinstance(x, list) else str(x))\n",
    "    \n",
    "    df['entities'] = ''\n",
    "    \n",
    "    if 'difficulty_level' in df.columns:\n",
    "        df['difficulty'] = df['difficulty_level']\n",
    "    else:\n",
    "        def estimate_difficulty(answer: str) -> str:\n",
    "            length = len(answer)\n",
    "            if length < 100:\n",
    "                return 'easy'\n",
    "            elif length < 300:\n",
    "                return 'medium'\n",
    "            else:\n",
    "                return 'hard'\n",
    "        \n",
    "        df['difficulty'] = df['answer'].apply(estimate_difficulty)\n",
    "    \n",
    "    if 'augmentation_method' not in df.columns:\n",
    "        df['augmentation_method'] = 'original'\n",
    "    \n",
    "    if 'confidence' not in df.columns:\n",
    "        df['confidence'] = 1.0\n",
    "    \n",
    "    if 'created_at' not in df.columns:\n",
    "        df['created_at'] = datetime.now().isoformat()\n",
    "    \n",
    "    print(\" Metadata zenginleştirme tamamlandı\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "log_dir = os.path.join(CONFIG['out_dir'], 'logs')\n",
    "logger = setup_logger(log_dir)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\" DEEP SSS ENRICHER BAŞLATILDI\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "df1 = load_dataset(CONFIG['input1'])\n",
    "df2 = load_dataset(CONFIG['input2'])\n",
    "\n",
    "\n",
    "df = merge_and_deduplicate(df1, df2)\n",
    "\n",
    "\n",
    "embeddings, model = create_embeddings(df['question'].tolist())\n",
    "\n",
    "\n",
    "df = cluster_questions(df, embeddings, CONFIG['cluster_threshold'])\n",
    "\n",
    "\n",
    "df, review_df = canonicalize_clusters(df)\n",
    "\n",
    "canonical_mask = df.groupby('cluster_id')['question'].transform(lambda x: x == x.iloc[0])\n",
    "df['is_canonical'] = canonical_mask\n",
    "\n",
    "\n",
    "if CONFIG['n_paraphrases'] > 0:\n",
    "    api_key = CONFIG['api_key'] or os.getenv('ANTHROPIC_API_KEY') or os.getenv('OPENAI_API_KEY')\n",
    "    \n",
    "    if CONFIG['provider'] != 'local' and not api_key:\n",
    "        print(\"  API key bulunamadı, 'local' moda geçiliyor\")\n",
    "        CONFIG['provider'] = 'local'\n",
    "    \n",
    "    generator = ParaphraseGenerator(CONFIG['provider'], api_key, CONFIG['seed'])\n",
    "    para_df = generate_paraphrases(df, generator, CONFIG['n_paraphrases'], embeddings, model)\n",
    "    \n",
    "    df = pd.concat([df, para_df], ignore_index=True)\n",
    "    print(f\"\\n Toplam satır (paraphrase sonrası): {len(df)}\")\n",
    "\n",
    "\n",
    "df = enrich_metadata(df)\n",
    "\n",
    "\n",
    "os.makedirs(CONFIG['out_dir'], exist_ok=True)\n",
    "\n",
    "df.to_json(os.path.join(CONFIG['out_dir'], 'enriched_dataset.jsonl'), \n",
    "           orient='records', lines=True, force_ascii=False)\n",
    "df.to_csv(os.path.join(CONFIG['out_dir'], 'enriched_dataset.csv'), \n",
    "          index=False, encoding='utf-8')\n",
    "\n",
    "canonical_df = df[df['is_canonical'] == True][['cluster_id', 'canonical_question', \n",
    "                                                 'canonical_answer', 'category', 'keywords']]\n",
    "canonical_df.to_csv(os.path.join(CONFIG['out_dir'], 'canonical_questions.csv'), \n",
    "                    index=False, encoding='utf-8')\n",
    "\n",
    "if len(review_df) > 0:\n",
    "    review_df.to_csv(os.path.join(CONFIG['out_dir'], 'review_needed.csv'), \n",
    "                     index=False, encoding='utf-8')\n",
    "\n",
    "df.head(50).to_csv(os.path.join(CONFIG['out_dir'], 'preview.csv'), \n",
    "                   index=False, encoding='utf-8')\n",
    "\n",
    "\n",
    "manifest = {\n",
    "    'creation_date': datetime.now().isoformat(),\n",
    "    'total_records': int(len(df)),\n",
    "    'original_records': int(len(df[df['augmentation_method'] == 'original'])),\n",
    "    'paraphrased_records': int(len(df[df['augmentation_method'].str.contains('paraphrase', na=False)])),\n",
    "    'n_clusters': int(df['cluster_id'].nunique()),\n",
    "    'n_canonical': int(df['is_canonical'].sum()),\n",
    "    'provider': CONFIG['provider'],\n",
    "    'n_paraphrases_per_question': CONFIG['n_paraphrases'],\n",
    "    'seed': CONFIG['seed'],\n",
    "    'categories': {str(k): int(v) for k, v in df['category'].value_counts().to_dict().items()},\n",
    "    'intents': {str(k): int(v) for k, v in df['intent'].value_counts().to_dict().items()},\n",
    "    'augmentation_methods': {str(k): int(v) for k, v in df['augmentation_method'].value_counts().to_dict().items()},\n",
    "    'difficulty_distribution': {str(k): int(v) for k, v in df['difficulty'].value_counts().to_dict().items()},\n",
    "    'review_needed_count': int(len(review_df)),\n",
    "    'processing_time_seconds': round(time.time() - start_time, 2)\n",
    "}\n",
    "\n",
    "with open(os.path.join(CONFIG['out_dir'], 'manifest.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(manifest, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"\\ Tüm çıktılar kaydedildi!\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\" İŞLEM TAMAMLANDI\")\n",
    "print(\"=\"*80)\n",
    "print(f\" Toplam kayıt: {manifest['total_records']:,}\")\n",
    "print(f\" Orijinal kayıt: {manifest['original_records']:,}\")\n",
    "print(f\" Paraphrase kayıt: {manifest['paraphrased_records']:,}\")\n",
    "print(f\" Küme sayısı: {manifest['n_clusters']:,}\")\n",
    "print(f\" Canonical soru: {manifest['n_canonical']:,}\")\n",
    "print(f\"  İnceleme gereken: {manifest['review_needed_count']:,}\")\n",
    "print(f\"  İşlem süresi: {manifest['processing_time_seconds']:.2f} saniye\")\n",
    "print(f\" Çıktı dizini: {CONFIG['out_dir']}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "print(\"\\n Örnek Canonical Sorular:\")\n",
    "display(canonical_df.head(10))\n",
    "\n",
    "print(\"\\n Örnek Paraphrase'ler:\")\n",
    "display(df[df['augmentation_method'].str.contains('paraphrase', na=False)].head(10))\n",
    "\n",
    "print(\"\\n Kategori Dağılımı:\")\n",
    "display(df['category'].value_counts())\n",
    "\n",
    "print(\"\\n Intent Dağılımı:\")\n",
    "display(df['intent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9ff417-6ba0-488f-a37f-7bab981eff15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
