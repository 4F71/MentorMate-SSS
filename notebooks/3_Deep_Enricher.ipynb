{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c5c8796-1ac1-44cf-9bd0-380b4e5f213b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ spaCy modeli yüklendi\n",
      "✅ FAISS kullanılabilir\n",
      "\n",
      "✅ Tüm kütüphaneler yüklendi!\n",
      "📋 Konfigürasyon:\n",
      "  input1: ..\\data\\sss_dataset_augmented.json\n",
      "  input2: ..\\data\\sss_dataset_heavily_augmented.json\n",
      "  out_dir: ../output\n",
      "  n_paraphrases: 30\n",
      "  provider: local\n",
      "  seed: 42\n",
      "  cluster_threshold: 0.3\n",
      "  batch_size: 32\n",
      "================================================================================\n",
      "🚀 DEEP SSS ENRICHER BAŞLATILDI\n",
      "================================================================================\n",
      "📂 Yükleniyor: ..\\data\\sss_dataset_augmented.json\n",
      "✅ 14 satır yüklendi\n",
      "📂 Yükleniyor: ..\\data\\sss_dataset_heavily_augmented.json\n",
      "✅ 14 satır yüklendi\n",
      "\n",
      "🔗 Veri setleri işleniyor...\n",
      "Toplam satır (birleştirme sonrası): 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Expanding questions: 100%|████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 946.26it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam soru (expand sonrası): 812\n",
      "🗑️  Exact tekrar silindi: 56 satır\n",
      "✅ Temizlenmiş veri: 756 satır\n",
      "\n",
      "🧠 Embedding model yükleniyor: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔢 756 metin için embedding üretiliyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches:   0%|                                                                                  | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:   4%|███                                                                       | 1/24 [00:00<00:07,  3.27it/s]\u001b[A\n",
      "Batches:   8%|██████▏                                                                   | 2/24 [00:00<00:05,  4.08it/s]\u001b[A\n",
      "Batches:  12%|█████████▎                                                                | 3/24 [00:00<00:04,  4.74it/s]\u001b[A\n",
      "Batches:  17%|████████████▎                                                             | 4/24 [00:00<00:03,  5.23it/s]\u001b[A\n",
      "Batches:  21%|███████████████▍                                                          | 5/24 [00:00<00:03,  5.80it/s]\u001b[A\n",
      "Batches:  25%|██████████████████▌                                                       | 6/24 [00:01<00:02,  6.24it/s]\u001b[A\n",
      "Batches:  29%|█████████████████████▌                                                    | 7/24 [00:01<00:02,  6.63it/s]\u001b[A\n",
      "Batches:  33%|████████████████████████▋                                                 | 8/24 [00:01<00:02,  7.09it/s]\u001b[A\n",
      "Batches:  38%|███████████████████████████▊                                              | 9/24 [00:01<00:02,  7.44it/s]\u001b[A\n",
      "Batches:  42%|██████████████████████████████▍                                          | 10/24 [00:01<00:01,  7.91it/s]\u001b[A\n",
      "Batches:  46%|█████████████████████████████████▍                                       | 11/24 [00:01<00:01,  8.24it/s]\u001b[A\n",
      "Batches:  50%|████████████████████████████████████▌                                    | 12/24 [00:01<00:01,  8.50it/s]\u001b[A\n",
      "Batches:  54%|███████████████████████████████████████▌                                 | 13/24 [00:01<00:01,  8.76it/s]\u001b[A\n",
      "Batches:  62%|█████████████████████████████████████████████▋                           | 15/24 [00:02<00:00,  9.67it/s]\u001b[A\n",
      "Batches:  71%|███████████████████████████████████████████████████▋                     | 17/24 [00:02<00:00, 10.27it/s]\u001b[A\n",
      "Batches:  79%|█████████████████████████████████████████████████████████▊               | 19/24 [00:02<00:00, 10.70it/s]\u001b[A\n",
      "Batches:  88%|███████████████████████████████████████████████████████████████▉         | 21/24 [00:02<00:00, 11.33it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  8.61it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Semantik kümeleme yapılıyor (threshold=0.3)...\n",
      "✅ 93 küme oluşturuldu\n",
      "\n",
      "📝 Canonical sorular oluşturuluyor...\n",
      "✅ 93 canonical soru oluşturuldu\n",
      "⚠️  23 küme inceleme gerekiyor\n",
      "\n",
      "🎭 Paraphrase üretimi (30 varyasyon/soru)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Paraphrasing:   0%|                                      | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "Paraphrasing:   5%|█▌                            | 5/93 [00:00<00:01, 44.27it/s]\u001b[A\n",
      "Paraphrasing:  11%|███                          | 10/93 [00:00<00:02, 40.68it/s]\u001b[A\n",
      "Paraphrasing:  16%|████▋                        | 15/93 [00:00<00:01, 42.88it/s]\u001b[A\n",
      "Paraphrasing:  22%|██████▏                      | 20/93 [00:00<00:01, 43.38it/s]\u001b[A\n",
      "Paraphrasing:  27%|███████▊                     | 25/93 [00:00<00:01, 40.07it/s]\u001b[A\n",
      "Paraphrasing:  32%|█████████▎                   | 30/93 [00:00<00:01, 37.02it/s]\u001b[A\n",
      "Paraphrasing:  37%|██████████▌                  | 34/93 [00:00<00:01, 37.78it/s]\u001b[A\n",
      "Paraphrasing:  42%|████████████▏                | 39/93 [00:00<00:01, 39.65it/s]\u001b[A\n",
      "Paraphrasing:  47%|█████████████▋               | 44/93 [00:01<00:01, 35.82it/s]\u001b[A\n",
      "Paraphrasing:  52%|██████████████▉              | 48/93 [00:01<00:01, 32.16it/s]\u001b[A\n",
      "Paraphrasing:  56%|████████████████▏            | 52/93 [00:01<00:01, 31.62it/s]\u001b[A\n",
      "Paraphrasing:  61%|█████████████████▊           | 57/93 [00:01<00:01, 34.34it/s]\u001b[A\n",
      "Paraphrasing:  66%|███████████████████          | 61/93 [00:01<00:00, 33.03it/s]\u001b[A\n",
      "Paraphrasing:  70%|████████████████████▎        | 65/93 [00:01<00:00, 34.36it/s]\u001b[A\n",
      "Paraphrasing:  74%|█████████████████████▌       | 69/93 [00:01<00:00, 32.26it/s]\u001b[A\n",
      "Paraphrasing:  78%|██████████████████████▊      | 73/93 [00:02<00:00, 33.16it/s]\u001b[A\n",
      "Paraphrasing:  83%|████████████████████████     | 77/93 [00:02<00:00, 30.44it/s]\u001b[A\n",
      "Paraphrasing:  87%|█████████████████████████▎   | 81/93 [00:02<00:00, 32.24it/s]\u001b[A\n",
      "Paraphrasing:  92%|██████████████████████████▊  | 86/93 [00:02<00:00, 34.74it/s]\u001b[A\n",
      "Paraphrasing: 100%|█████████████████████████████| 93/93 [00:02<00:00, 34.81it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 255 yeni paraphrase oluşturuldu\n",
      "\n",
      "📊 Toplam satır (paraphrase sonrası): 1011\n",
      "\n",
      "🏷️  Metadata zenginleştiriliyor...\n",
      "✅ Metadata zenginleştirme tamamlandı\n",
      "\n",
      "💾 Tüm çıktılar kaydedildi!\n",
      "================================================================================\n",
      "✅ İŞLEM TAMAMLANDI\n",
      "================================================================================\n",
      "📊 Toplam kayıt: 1,011\n",
      "📝 Orijinal kayıt: 0\n",
      "🎭 Paraphrase kayıt: 255\n",
      "🔍 Küme sayısı: 93\n",
      "⭐ Canonical soru: 93\n",
      "⚠️  İnceleme gereken: 23\n",
      "⏱️  İşlem süresi: 8.03 saniye\n",
      "📁 Çıktı dizini: ../output\n",
      "================================================================================\n",
      "\n",
      "📋 Örnek Canonical Sorular:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>canonical_question</th>\n",
       "      <th>canonical_answer</th>\n",
       "      <th>category</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>**Bootcamp Sertifikası Alacak mıyım?**</td>\n",
       "      <td>Evet, bootcamp sonunda projenizi başarıyla tam...</td>\n",
       "      <td>Genel</td>\n",
       "      <td>bootcamp, iş imkanı, staj imkanı, bootcamp iş ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Canlı yayınlar arşivleniyor mu?</td>\n",
       "      <td>Evet, tüm canlı yayınlar kaydedilmekte ve **Yo...</td>\n",
       "      <td>Genel</td>\n",
       "      <td>canlı yayın yoklama, katılım belgesi, canlı ya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16.0</td>\n",
       "      <td>Bu projeyi takım halinde mi gerçekleştirmeliyiz?</td>\n",
       "      <td>Projeleri tek başınıza ya da en fazla 2 kişili...</td>\n",
       "      <td>Genel</td>\n",
       "      <td>grup projesi, tek kişilik proje, proje grup zo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Grup kurmak zorunda mıyım?</td>\n",
       "      <td>Projeleri tek başınıza ya da en fazla 2 kişili...</td>\n",
       "      <td>Genel</td>\n",
       "      <td>grup projesi, tek kişilik proje, proje grup zo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>69.0</td>\n",
       "      <td>Projeyi ekipçe yürütmemiz mi bekleniyor?</td>\n",
       "      <td>Projeleri tek başınıza ya da en fazla 2 kişili...</td>\n",
       "      <td>Genel</td>\n",
       "      <td>grup projesi, tek kişilik proje, proje grup zo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Mentor buluşmalarına katılmak faydalı mı?</td>\n",
       "      <td>Mentor toplantıları ve saatleri, Zulip'teki du...</td>\n",
       "      <td>Genel</td>\n",
       "      <td>mentor toplantıları, mentor toplantı saatleri,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Kodumu GitHub'a hızlıca nasıl yükleyebilirim?</td>\n",
       "      <td>Web arayüzü ile yükleme: https://www.youtube.c...</td>\n",
       "      <td>Genel</td>\n",
       "      <td>GitHub'a kod yükleme, Git kullanmadan GitHub, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>37.0</td>\n",
       "      <td>YouTube kanalınızın adı nedir?</td>\n",
       "      <td>Evet, tüm canlı yayınlar kaydedilmekte ve **Yo...</td>\n",
       "      <td>Genel</td>\n",
       "      <td>Youtube Canlı Yayın, Canlı Yayın Yoklama, Katı...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>71.0</td>\n",
       "      <td>Sertifika'da İsim-Harf Problemi</td>\n",
       "      <td>Merhaba, Bazı kullanıcılarımız sertifikalarınd...</td>\n",
       "      <td>Genel</td>\n",
       "      <td>sertifika isim hatası, sertifika karakter soru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>91.0</td>\n",
       "      <td>Belgelerdeki ad yazımında harf yanlışlığı</td>\n",
       "      <td>Merhaba, Bazı kullanıcılarımız sertifikalarınd...</td>\n",
       "      <td>Genel</td>\n",
       "      <td>sertifika isim hatası, sertifika karakter soru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cluster_id                                canonical_question  \\\n",
       "0          0.0            **Bootcamp Sertifikası Alacak mıyım?**   \n",
       "8         22.0                   Canlı yayınlar arşivleniyor mu?   \n",
       "17        16.0  Bu projeyi takım halinde mi gerçekleştirmeliyiz?   \n",
       "18         2.0                        Grup kurmak zorunda mıyım?   \n",
       "19        69.0          Projeyi ekipçe yürütmemiz mi bekleniyor?   \n",
       "20         1.0         Mentor buluşmalarına katılmak faydalı mı?   \n",
       "28         9.0     Kodumu GitHub'a hızlıca nasıl yükleyebilirim?   \n",
       "32        37.0                    YouTube kanalınızın adı nedir?   \n",
       "36        71.0                   Sertifika'da İsim-Harf Problemi   \n",
       "38        91.0         Belgelerdeki ad yazımında harf yanlışlığı   \n",
       "\n",
       "                                     canonical_answer category  \\\n",
       "0   Evet, bootcamp sonunda projenizi başarıyla tam...    Genel   \n",
       "8   Evet, tüm canlı yayınlar kaydedilmekte ve **Yo...    Genel   \n",
       "17  Projeleri tek başınıza ya da en fazla 2 kişili...    Genel   \n",
       "18  Projeleri tek başınıza ya da en fazla 2 kişili...    Genel   \n",
       "19  Projeleri tek başınıza ya da en fazla 2 kişili...    Genel   \n",
       "20  Mentor toplantıları ve saatleri, Zulip'teki du...    Genel   \n",
       "28  Web arayüzü ile yükleme: https://www.youtube.c...    Genel   \n",
       "32  Evet, tüm canlı yayınlar kaydedilmekte ve **Yo...    Genel   \n",
       "36  Merhaba, Bazı kullanıcılarımız sertifikalarınd...    Genel   \n",
       "38  Merhaba, Bazı kullanıcılarımız sertifikalarınd...    Genel   \n",
       "\n",
       "                                             keywords  \n",
       "0   bootcamp, iş imkanı, staj imkanı, bootcamp iş ...  \n",
       "8   canlı yayın yoklama, katılım belgesi, canlı ya...  \n",
       "17  grup projesi, tek kişilik proje, proje grup zo...  \n",
       "18  grup projesi, tek kişilik proje, proje grup zo...  \n",
       "19  grup projesi, tek kişilik proje, proje grup zo...  \n",
       "20  mentor toplantıları, mentor toplantı saatleri,...  \n",
       "28  GitHub'a kod yükleme, Git kullanmadan GitHub, ...  \n",
       "32  Youtube Canlı Yayın, Canlı Yayın Yoklama, Katı...  \n",
       "36  sertifika isim hatası, sertifika karakter soru...  \n",
       "38  sertifika isim hatası, sertifika karakter soru...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Örnek Paraphrase'ler:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>original_question</th>\n",
       "      <th>category</th>\n",
       "      <th>keywords</th>\n",
       "      <th>difficulty_level</th>\n",
       "      <th>source</th>\n",
       "      <th>created_at</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>canonical_question</th>\n",
       "      <th>canonical_answer</th>\n",
       "      <th>cluster_size</th>\n",
       "      <th>is_canonical</th>\n",
       "      <th>canonical_id</th>\n",
       "      <th>augmentation_method</th>\n",
       "      <th>confidence</th>\n",
       "      <th>id</th>\n",
       "      <th>intent</th>\n",
       "      <th>entities</th>\n",
       "      <th>difficulty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>**bootcamp sertifikası alacak mıyım?**?</td>\n",
       "      <td>Evet, bootcamp sonunda projenizi başarıyla tam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>courses</td>\n",
       "      <td>sertifikası, alacak, bootcamp, mıyım</td>\n",
       "      <td>NaN</td>\n",
       "      <td>generated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>**Bootcamp Sertifikası Alacak mıyım?**</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>paraphrase_local</td>\n",
       "      <td>0.787344</td>\n",
       "      <td>140d4588eb60f4d5</td>\n",
       "      <td>information</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>**bootcamp sertifikası alacak mıyım?** hakkınd...</td>\n",
       "      <td>Evet, bootcamp sonunda projenizi başarıyla tam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>courses</td>\n",
       "      <td>verir, mıyım, misiniz, alacak, sertifikası</td>\n",
       "      <td>NaN</td>\n",
       "      <td>generated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>**Bootcamp Sertifikası Alacak mıyım?**</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>paraphrase_local</td>\n",
       "      <td>0.750345</td>\n",
       "      <td>de5e6100b415ffce</td>\n",
       "      <td>information</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>**bootcamp sertifikası alacak mıyım?** konusun...</td>\n",
       "      <td>Evet, bootcamp sonunda projenizi başarıyla tam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>courses</td>\n",
       "      <td>konusunda, olabilir, mıyım, yardımcı, misiniz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>generated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>**Bootcamp Sertifikası Alacak mıyım?**</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>paraphrase_local</td>\n",
       "      <td>0.740952</td>\n",
       "      <td>43dc39c20ac1ecc9</td>\n",
       "      <td>information</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>**bootcamp sertifikası alacak mıyım?**</td>\n",
       "      <td>Evet, bootcamp sonunda projenizi başarıyla tam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>courses</td>\n",
       "      <td>sertifikası, alacak, bootcamp, mıyım</td>\n",
       "      <td>NaN</td>\n",
       "      <td>generated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>**Bootcamp Sertifikası Alacak mıyım?**</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>paraphrase_local</td>\n",
       "      <td>0.848164</td>\n",
       "      <td>46da9f877cc008bc</td>\n",
       "      <td>information</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>Canlı yayınlar arşivleniyor mu??</td>\n",
       "      <td>Evet, tüm canlı yayınlar kaydedilmekte ve **Yo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>general</td>\n",
       "      <td>arşivleniyor, yayınlar, canlı</td>\n",
       "      <td>NaN</td>\n",
       "      <td>generated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Canlı yayınlar arşivleniyor mu?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>22.0</td>\n",
       "      <td>paraphrase_local</td>\n",
       "      <td>0.866781</td>\n",
       "      <td>8e5dded6322d5a7f</td>\n",
       "      <td>information</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>Canlı yayınlar arşivleniyor mu? hakkında bilgi...</td>\n",
       "      <td>Evet, tüm canlı yayınlar kaydedilmekte ve **Yo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>general</td>\n",
       "      <td>verir, arşivleniyor, yayınlar, canlı, misiniz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>generated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Canlı yayınlar arşivleniyor mu?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>22.0</td>\n",
       "      <td>paraphrase_local</td>\n",
       "      <td>0.798673</td>\n",
       "      <td>d6b30092cedc3ab5</td>\n",
       "      <td>information</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>Canlı yayınlar arşivleniyor mu? konusunda yard...</td>\n",
       "      <td>Evet, tüm canlı yayınlar kaydedilmekte ve **Yo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>support</td>\n",
       "      <td>konusunda, olabilir, arşivleniyor, yayınlar, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>generated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Canlı yayınlar arşivleniyor mu?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>22.0</td>\n",
       "      <td>paraphrase_local</td>\n",
       "      <td>0.790438</td>\n",
       "      <td>de9a60a0749731ce</td>\n",
       "      <td>information</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>Canlı yayınlar arşivleniyor mu?</td>\n",
       "      <td>Evet, tüm canlı yayınlar kaydedilmekte ve **Yo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>general</td>\n",
       "      <td>arşivleniyor, yayınlar, canlı</td>\n",
       "      <td>NaN</td>\n",
       "      <td>generated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Canlı yayınlar arşivleniyor mu?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>22.0</td>\n",
       "      <td>paraphrase_local</td>\n",
       "      <td>0.859113</td>\n",
       "      <td>059091a1c6046881</td>\n",
       "      <td>information</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>Bu projeyi takım halinde mi gerçekleştirmeliyi...</td>\n",
       "      <td>Projeleri tek başınıza ya da en fazla 2 kişili...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>general</td>\n",
       "      <td>verir, projeyi, takım, halinde, misiniz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>generated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bu projeyi takım halinde mi gerçekleştirmeliyiz?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>16.0</td>\n",
       "      <td>paraphrase_local</td>\n",
       "      <td>0.921963</td>\n",
       "      <td>203802ce140d2a32</td>\n",
       "      <td>information</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>Bu projeyi takım halinde mi gerçekleştirmeliyi...</td>\n",
       "      <td>Projeleri tek başınıza ya da en fazla 2 kişili...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>support</td>\n",
       "      <td>konusunda, projeyi, olabilir, takım, halinde</td>\n",
       "      <td>NaN</td>\n",
       "      <td>generated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bu projeyi takım halinde mi gerçekleştirmeliyiz?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>16.0</td>\n",
       "      <td>paraphrase_local</td>\n",
       "      <td>0.901847</td>\n",
       "      <td>4f554fa9ea0c6cb6</td>\n",
       "      <td>information</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "756            **bootcamp sertifikası alacak mıyım?**?   \n",
       "757  **bootcamp sertifikası alacak mıyım?** hakkınd...   \n",
       "758  **bootcamp sertifikası alacak mıyım?** konusun...   \n",
       "759             **bootcamp sertifikası alacak mıyım?**   \n",
       "760                   Canlı yayınlar arşivleniyor mu??   \n",
       "761  Canlı yayınlar arşivleniyor mu? hakkında bilgi...   \n",
       "762  Canlı yayınlar arşivleniyor mu? konusunda yard...   \n",
       "763                    Canlı yayınlar arşivleniyor mu?   \n",
       "764  Bu projeyi takım halinde mi gerçekleştirmeliyi...   \n",
       "765  Bu projeyi takım halinde mi gerçekleştirmeliyi...   \n",
       "\n",
       "                                                answer original_question  \\\n",
       "756  Evet, bootcamp sonunda projenizi başarıyla tam...               NaN   \n",
       "757  Evet, bootcamp sonunda projenizi başarıyla tam...               NaN   \n",
       "758  Evet, bootcamp sonunda projenizi başarıyla tam...               NaN   \n",
       "759  Evet, bootcamp sonunda projenizi başarıyla tam...               NaN   \n",
       "760  Evet, tüm canlı yayınlar kaydedilmekte ve **Yo...               NaN   \n",
       "761  Evet, tüm canlı yayınlar kaydedilmekte ve **Yo...               NaN   \n",
       "762  Evet, tüm canlı yayınlar kaydedilmekte ve **Yo...               NaN   \n",
       "763  Evet, tüm canlı yayınlar kaydedilmekte ve **Yo...               NaN   \n",
       "764  Projeleri tek başınıza ya da en fazla 2 kişili...               NaN   \n",
       "765  Projeleri tek başınıza ya da en fazla 2 kişili...               NaN   \n",
       "\n",
       "    category                                           keywords  \\\n",
       "756  courses               sertifikası, alacak, bootcamp, mıyım   \n",
       "757  courses         verir, mıyım, misiniz, alacak, sertifikası   \n",
       "758  courses      konusunda, olabilir, mıyım, yardımcı, misiniz   \n",
       "759  courses               sertifikası, alacak, bootcamp, mıyım   \n",
       "760  general                      arşivleniyor, yayınlar, canlı   \n",
       "761  general      verir, arşivleniyor, yayınlar, canlı, misiniz   \n",
       "762  support  konusunda, olabilir, arşivleniyor, yayınlar, c...   \n",
       "763  general                      arşivleniyor, yayınlar, canlı   \n",
       "764  general            verir, projeyi, takım, halinde, misiniz   \n",
       "765  support       konusunda, projeyi, olabilir, takım, halinde   \n",
       "\n",
       "    difficulty_level     source created_at  cluster_id  \\\n",
       "756              NaN  generated        NaN         NaN   \n",
       "757              NaN  generated        NaN         NaN   \n",
       "758              NaN  generated        NaN         NaN   \n",
       "759              NaN  generated        NaN         NaN   \n",
       "760              NaN  generated        NaN         NaN   \n",
       "761              NaN  generated        NaN         NaN   \n",
       "762              NaN  generated        NaN         NaN   \n",
       "763              NaN  generated        NaN         NaN   \n",
       "764              NaN  generated        NaN         NaN   \n",
       "765              NaN  generated        NaN         NaN   \n",
       "\n",
       "                                   canonical_question canonical_answer  \\\n",
       "756            **Bootcamp Sertifikası Alacak mıyım?**              NaN   \n",
       "757            **Bootcamp Sertifikası Alacak mıyım?**              NaN   \n",
       "758            **Bootcamp Sertifikası Alacak mıyım?**              NaN   \n",
       "759            **Bootcamp Sertifikası Alacak mıyım?**              NaN   \n",
       "760                   Canlı yayınlar arşivleniyor mu?              NaN   \n",
       "761                   Canlı yayınlar arşivleniyor mu?              NaN   \n",
       "762                   Canlı yayınlar arşivleniyor mu?              NaN   \n",
       "763                   Canlı yayınlar arşivleniyor mu?              NaN   \n",
       "764  Bu projeyi takım halinde mi gerçekleştirmeliyiz?              NaN   \n",
       "765  Bu projeyi takım halinde mi gerçekleştirmeliyiz?              NaN   \n",
       "\n",
       "     cluster_size  is_canonical  canonical_id augmentation_method  confidence  \\\n",
       "756           NaN         False           0.0    paraphrase_local    0.787344   \n",
       "757           NaN         False           0.0    paraphrase_local    0.750345   \n",
       "758           NaN         False           0.0    paraphrase_local    0.740952   \n",
       "759           NaN         False           0.0    paraphrase_local    0.848164   \n",
       "760           NaN         False          22.0    paraphrase_local    0.866781   \n",
       "761           NaN         False          22.0    paraphrase_local    0.798673   \n",
       "762           NaN         False          22.0    paraphrase_local    0.790438   \n",
       "763           NaN         False          22.0    paraphrase_local    0.859113   \n",
       "764           NaN         False          16.0    paraphrase_local    0.921963   \n",
       "765           NaN         False          16.0    paraphrase_local    0.901847   \n",
       "\n",
       "                   id       intent entities difficulty  \n",
       "756  140d4588eb60f4d5  information                 NaN  \n",
       "757  de5e6100b415ffce  information                 NaN  \n",
       "758  43dc39c20ac1ecc9  information                 NaN  \n",
       "759  46da9f877cc008bc  information                 NaN  \n",
       "760  8e5dded6322d5a7f  information                 NaN  \n",
       "761  d6b30092cedc3ab5  information                 NaN  \n",
       "762  de9a60a0749731ce  information                 NaN  \n",
       "763  059091a1c6046881  information                 NaN  \n",
       "764  203802ce140d2a32  information                 NaN  \n",
       "765  4f554fa9ea0c6cb6  information                 NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Kategori Dağılımı:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "category\n",
       "Genel            756\n",
       "general          126\n",
       "support           69\n",
       "certification     38\n",
       "account           14\n",
       "courses            8\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Intent Dağılımı:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "intent\n",
       "information    717\n",
       "how_to         157\n",
       "definition     111\n",
       "reasoning       18\n",
       "timing           8\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Deep SSS Enricher - Jupyter Notebook Versiyonu\n",
    "# \n",
    "# Bu notebook, iki SSS veri setini birleştirir, temizler, zenginleştirir ve RAG-ready hale getirir.\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Kurulum ve Import'lar\n",
    "\n",
    "# %%\n",
    "# Gerekli kütüphanelerin kurulumu (ilk çalıştırmada bir kez çalıştırın)\n",
    "# !pip install pandas numpy tqdm sentence-transformers scikit-learn transformers requests faiss-cpu spacy anthropic openai\n",
    "# !python -m spacy download en_core_web_sm\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import time\n",
    "import re\n",
    "import hashlib\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # Standart tqdm kullan\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "try:\n",
    "    import spacy\n",
    "    try:\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        print(\"✅ spaCy modeli yüklendi\")\n",
    "    except:\n",
    "        print(\"⚠️  spaCy modeli bulunamadı, basit mod aktif\")\n",
    "        nlp = None\n",
    "except ImportError:\n",
    "    nlp = None\n",
    "    print(\"⚠️  spaCy kurulu değil\")\n",
    "\n",
    "import requests\n",
    "\n",
    "try:\n",
    "    import faiss\n",
    "    FAISS_AVAILABLE = True\n",
    "    print(\"✅ FAISS kullanılabilir\")\n",
    "except:\n",
    "    FAISS_AVAILABLE = False\n",
    "    print(\"⚠️  FAISS yüklü değil\")\n",
    "\n",
    "print(\"\\n✅ Tüm kütüphaneler yüklendi!\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Konfigürasyon\n",
    "\n",
    "# %%\n",
    "# AYARLAR - Buradan değiştirebilirsiniz\n",
    "CONFIG = {\n",
    "    'input1': r'..\\data\\sss_dataset_augmented.json',\n",
    "    'input2': r'..\\data\\sss_dataset_heavily_augmented.json',\n",
    "    'out_dir': '../output',\n",
    "    'n_paraphrases': 30,\n",
    "    'provider': 'local',  # 'local', 'anthropic', veya 'openai'\n",
    "    'api_key': None,  # API key varsa buraya yazın\n",
    "    'seed': 42,\n",
    "    'cluster_threshold': 0.3,\n",
    "    'batch_size': 32\n",
    "}\n",
    "\n",
    "print(\"📋 Konfigürasyon:\")\n",
    "for key, value in CONFIG.items():\n",
    "    if key != 'api_key':\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Yardımcı Fonksiyonlar\n",
    "\n",
    "# %%\n",
    "def setup_logger(log_dir: str) -> logging.Logger:\n",
    "    \"\"\"Log yapılandırması\"\"\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    log_file = os.path.join(log_dir, f\"enricher_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")\n",
    "    \n",
    "    logger = logging.getLogger(\"DeepEnricher\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.handlers = []  # Önceki handler'ları temizle\n",
    "    \n",
    "    fh = logging.FileHandler(log_file, encoding='utf-8')\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    fh.setFormatter(formatter)\n",
    "    logger.addHandler(fh)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "def normalize_text(text: str) -> str:\n",
    "    \"\"\"Metin normalizasyonu\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).strip()\n",
    "    text = text.encode('utf-8', 'ignore').decode('utf-8')\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "# %%\n",
    "def load_dataset(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Dosyayı otomatik algılayarak yükle\"\"\"\n",
    "    print(f\"📂 Yükleniyor: {file_path}\")\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Dosya bulunamadı: {file_path}\")\n",
    "    \n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    \n",
    "    if ext == '.csv':\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    elif ext == '.jsonl':\n",
    "        df = pd.read_json(file_path, lines=True, encoding='utf-8')\n",
    "    elif ext == '.json':\n",
    "        try:\n",
    "            df = pd.read_json(file_path, encoding='utf-8')\n",
    "        except:\n",
    "            df = pd.read_json(file_path, lines=True, encoding='utf-8')\n",
    "    else:\n",
    "        raise ValueError(f\"Desteklenmeyen format: {ext}\")\n",
    "    \n",
    "    print(f\"✅ {len(df)} satır yüklendi\")\n",
    "    return df\n",
    "\n",
    "def merge_and_deduplicate(df1: pd.DataFrame, df2: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"İki veri setini birleştir ve tekrarları sil\"\"\"\n",
    "    print(\"\\n🔗 Veri setleri işleniyor...\")\n",
    "    \n",
    "    # Birleştir\n",
    "    combined = pd.concat([df1, df2], ignore_index=True)\n",
    "    print(f\"Toplam satır (birleştirme sonrası): {len(combined)}\")\n",
    "    \n",
    "    # Sütun adlarını normalize et\n",
    "    combined.columns = combined.columns.str.lower().str.strip()\n",
    "    \n",
    "    # all_questions'ı expand et (her soruyu ayrı satır yap)\n",
    "    expanded_rows = []\n",
    "    \n",
    "    for idx, row in tqdm(combined.iterrows(), total=len(combined), desc=\"Expanding questions\"):\n",
    "        all_questions = row['all_questions']\n",
    "        \n",
    "        # Liste formatını kontrol et\n",
    "        if isinstance(all_questions, str):\n",
    "            try:\n",
    "                all_questions = eval(all_questions)\n",
    "            except:\n",
    "                all_questions = [all_questions]\n",
    "        \n",
    "        # Dict listesi mi yoksa string listesi mi?\n",
    "        if isinstance(all_questions, list) and len(all_questions) > 0:\n",
    "            if isinstance(all_questions[0], dict):\n",
    "                # Dict formatı: [{'question': '...', 'method': '...'}]\n",
    "                questions = [q.get('question', q.get('text', '')) for q in all_questions]\n",
    "            else:\n",
    "                # String listesi\n",
    "                questions = all_questions\n",
    "        else:\n",
    "            questions = [row.get('original_question', '')]\n",
    "        \n",
    "        # Her soru için ayrı satır oluştur\n",
    "        for question in questions:\n",
    "            expanded_rows.append({\n",
    "                'question': normalize_text(str(question)),\n",
    "                'answer': normalize_text(str(row['answer'])),\n",
    "                'original_question': normalize_text(str(row['original_question'])),\n",
    "                'category': row.get('category', 'general'),\n",
    "                'keywords': row.get('keywords', ''),\n",
    "                'difficulty_level': row.get('difficulty_level', 'medium'),\n",
    "                'source': 'original'\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(expanded_rows)\n",
    "    print(f\"Toplam soru (expand sonrası): {len(df)}\")\n",
    "    \n",
    "    # Boş soruları sil\n",
    "    df = df[df['question'].str.len() > 0]\n",
    "    df = df[df['answer'].str.len() > 0]\n",
    "    \n",
    "    # Exact deduplication\n",
    "    initial_count = len(df)\n",
    "    df = df.drop_duplicates(subset=['question', 'answer'], keep='first')\n",
    "    print(f\"🗑️  Exact tekrar silindi: {initial_count - len(df)} satır\")\n",
    "    \n",
    "    # Created at ekle\n",
    "    df['created_at'] = datetime.now().isoformat()\n",
    "    \n",
    "    df = df.reset_index(drop=True)\n",
    "    print(f\"✅ Temizlenmiş veri: {len(df)} satır\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Embedding ve Kümeleme\n",
    "\n",
    "# %%\n",
    "def create_embeddings(texts: List[str], model_name: str = 'sentence-transformers/all-MiniLM-L6-v2') -> np.ndarray:\n",
    "    \"\"\"Embedding oluştur\"\"\"\n",
    "    print(f\"\\n🧠 Embedding model yükleniyor: {model_name}\")\n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    print(f\"🔢 {len(texts)} metin için embedding üretiliyor...\")\n",
    "    embeddings = model.encode(texts, show_progress_bar=True, batch_size=32)\n",
    "    \n",
    "    return embeddings, model\n",
    "\n",
    "def cluster_questions(df: pd.DataFrame, embeddings: np.ndarray, threshold: float) -> pd.DataFrame:\n",
    "    \"\"\"Semantik kümeleme\"\"\"\n",
    "    print(f\"\\n🔍 Semantik kümeleme yapılıyor (threshold={threshold})...\")\n",
    "    \n",
    "    clustering = AgglomerativeClustering(\n",
    "        n_clusters=None,\n",
    "        distance_threshold=threshold,\n",
    "        linkage='average',\n",
    "        metric='cosine'\n",
    "    )\n",
    "    \n",
    "    clusters = clustering.fit_predict(embeddings)\n",
    "    df['cluster_id'] = clusters\n",
    "    \n",
    "    n_clusters = len(set(clusters))\n",
    "    print(f\"✅ {n_clusters} küme oluşturuldu\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def select_canonical(group: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Küme için canonical soru/cevap seç\"\"\"\n",
    "    group = group.copy()\n",
    "    group['q_len'] = group['question'].str.len()\n",
    "    canonical_row = group.sort_values('q_len').iloc[0]\n",
    "    \n",
    "    unique_answers = group['answer'].unique()\n",
    "    \n",
    "    if len(unique_answers) == 1:\n",
    "        canonical_answer = unique_answers[0]\n",
    "        needs_review = False\n",
    "    else:\n",
    "        canonical_answer = canonical_row['answer']\n",
    "        needs_review = True\n",
    "    \n",
    "    return pd.Series({\n",
    "        'canonical_question': canonical_row['question'],\n",
    "        'canonical_answer': canonical_answer,\n",
    "        'cluster_size': len(group),\n",
    "        'needs_review': needs_review,\n",
    "        'initial_sources': '; '.join(group['source'].unique())\n",
    "    })\n",
    "\n",
    "def canonicalize_clusters(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Canonical sorular oluştur\"\"\"\n",
    "    print(\"\\n📝 Canonical sorular oluşturuluyor...\")\n",
    "    \n",
    "    canonical_df = df.groupby('cluster_id').apply(select_canonical).reset_index()\n",
    "    review_needed = canonical_df[canonical_df['needs_review'] == True].copy()\n",
    "    \n",
    "    df = df.merge(\n",
    "        canonical_df[['cluster_id', 'canonical_question', 'canonical_answer', 'cluster_size']],\n",
    "        on='cluster_id',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ {len(canonical_df)} canonical soru oluşturuldu\")\n",
    "    print(f\"⚠️  {len(review_needed)} küme inceleme gerekiyor\")\n",
    "    \n",
    "    return df, review_needed\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Paraphrase Üretimi\n",
    "\n",
    "# %%\n",
    "class ParaphraseGenerator:\n",
    "    \"\"\"LLM tabanlı paraphrase üretici\"\"\"\n",
    "    \n",
    "    def __init__(self, provider: str, api_key: str = None, seed: int = 42):\n",
    "        self.provider = provider\n",
    "        self.api_key = api_key\n",
    "        self.seed = seed\n",
    "        \n",
    "    def generate(self, question: str, n: int) -> List[str]:\n",
    "        \"\"\"N adet paraphrase üret\"\"\"\n",
    "        if self.provider == 'local':\n",
    "            return self._local_paraphrase(question, n)\n",
    "        elif self.provider == 'anthropic':\n",
    "            return self._anthropic_paraphrase(question, n)\n",
    "        elif self.provider == 'openai':\n",
    "            return self._openai_paraphrase(question, n)\n",
    "        else:\n",
    "            print(f\"❌ Bilinmeyen provider: {self.provider}\")\n",
    "            return []\n",
    "    \n",
    "    def _local_paraphrase(self, question: str, n: int) -> List[str]:\n",
    "        \"\"\"Basit kural tabanlı paraphrase\"\"\"\n",
    "        synonyms = {\n",
    "            'nasıl': ['ne şekilde', 'hangi yolla', 'ne biçimde'],\n",
    "            'nedir': ['ne demektir', 'nedir', 'ne anlama gelir'],\n",
    "            'yapabilirim': ['yapabilir miyim', 'yapmak mümkün mü', 'yapma imkanı var mı'],\n",
    "            'öğrenmek': ['bilgi edinmek', 'hakkında bilgi almak', 'öğrenmek'],\n",
    "            'ne zaman': ['hangi zamanda', 'ne vakit'],\n",
    "            'nerede': ['hangi yerde', 'nerede'],\n",
    "            'kim': ['hangi kişi', 'kimler'],\n",
    "        }\n",
    "        \n",
    "        paraphrases = []\n",
    "        \n",
    "        for i in range(min(n, 10)):\n",
    "            new_q = question\n",
    "            for word, syns in synonyms.items():\n",
    "                if word in new_q.lower():\n",
    "                    new_q = new_q.lower().replace(word, np.random.choice(syns))\n",
    "            \n",
    "            # Varyasyonlar\n",
    "            if i % 4 == 0:\n",
    "                new_q = new_q.capitalize() + \"?\"\n",
    "            elif i % 4 == 1:\n",
    "                new_q = new_q.capitalize() + \" hakkında bilgi verir misiniz?\"\n",
    "            elif i % 4 == 2:\n",
    "                new_q = new_q.capitalize() + \" konusunda yardımcı olabilir misiniz?\"\n",
    "            else:\n",
    "                new_q = new_q.capitalize()\n",
    "            \n",
    "            if new_q not in paraphrases:\n",
    "                paraphrases.append(new_q)\n",
    "        \n",
    "        return paraphrases[:n]\n",
    "    \n",
    "    def _anthropic_paraphrase(self, question: str, n: int) -> List[str]:\n",
    "        \"\"\"Claude API ile paraphrase\"\"\"\n",
    "        url = \"https://api.anthropic.com/v1/messages\"\n",
    "        headers = {\n",
    "            \"x-api-key\": self.api_key,\n",
    "            \"anthropic-version\": \"2023-06-01\",\n",
    "            \"content-type\": \"application/json\"\n",
    "        }\n",
    "        \n",
    "        paraphrases = []\n",
    "        batch_size = 5\n",
    "        \n",
    "        for batch_idx in range(0, n, batch_size):\n",
    "            batch_n = min(batch_size, n - batch_idx)\n",
    "            \n",
    "            prompt = f\"\"\"Aşağıdaki soruyu {batch_n} farklı şekilde yeniden ifade et.\n",
    "\n",
    "KURALLAR:\n",
    "- Sorunun ANLAMINI ve AMACINI KESINLIKLE değiştirme\n",
    "- Yeni bilgi EKLEME veya ÇIKARMA\n",
    "- Her varyasyon farklı bir tarzda olsun\n",
    "- Her satıra sadece BIR soru yaz\n",
    "- Ekstra açıklama yapma\n",
    "\n",
    "SORU: {question}\n",
    "\n",
    "ÇIKTI:\"\"\"\n",
    "\n",
    "            payload = {\n",
    "                \"model\": \"claude-3-5-sonnet-20241022\",\n",
    "                \"max_tokens\": 1024,\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                response = requests.post(url, headers=headers, json=payload, timeout=30)\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    content = response.json()['content'][0]['text']\n",
    "                    lines = [l.strip() for l in content.strip().split('\\n') if l.strip() and '?' in l]\n",
    "                    paraphrases.extend(lines[:batch_n])\n",
    "                elif response.status_code == 429:\n",
    "                    print(\"⏳ Rate limit, bekleniyor...\")\n",
    "                    time.sleep(10)\n",
    "                \n",
    "                time.sleep(1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Request hatası: {e}\")\n",
    "        \n",
    "        return paraphrases[:n]\n",
    "    \n",
    "    def _openai_paraphrase(self, question: str, n: int) -> List[str]:\n",
    "        \"\"\"OpenAI API ile paraphrase\"\"\"\n",
    "        # Benzer implementasyon\n",
    "        return self._local_paraphrase(question, n)\n",
    "\n",
    "def generate_paraphrases(df: pd.DataFrame, generator: ParaphraseGenerator, \n",
    "                        n_per_question: int, embeddings: np.ndarray, \n",
    "                        model: SentenceTransformer) -> pd.DataFrame:\n",
    "    \"\"\"Tüm canonical sorular için paraphrase üret\"\"\"\n",
    "    print(f\"\\n🎭 Paraphrase üretimi ({n_per_question} varyasyon/soru)...\")\n",
    "    \n",
    "    canonical_questions = df[['cluster_id', 'canonical_question', 'canonical_answer']].drop_duplicates('cluster_id')\n",
    "    \n",
    "    all_rows = []\n",
    "    \n",
    "    for idx, row in tqdm(canonical_questions.iterrows(), total=len(canonical_questions), desc=\"Paraphrasing\", ncols=80):\n",
    "        question = row['canonical_question']\n",
    "        answer = row['canonical_answer']\n",
    "        cluster_id = row['cluster_id']\n",
    "        \n",
    "        paraphrases = generator.generate(question, n_per_question)\n",
    "        \n",
    "        if not paraphrases:\n",
    "            continue\n",
    "        \n",
    "        para_embeddings = model.encode(paraphrases, show_progress_bar=False)\n",
    "        orig_embedding = embeddings[df[df['cluster_id'] == cluster_id].index[0]].reshape(1, -1)\n",
    "        \n",
    "        for para, para_emb in zip(paraphrases, para_embeddings):\n",
    "            similarity = cosine_similarity(orig_embedding, para_emb.reshape(1, -1))[0][0]\n",
    "            \n",
    "            if similarity > 0.95 or similarity < 0.70:\n",
    "                continue\n",
    "            \n",
    "            all_rows.append({\n",
    "                'question': para,\n",
    "                'answer': answer,\n",
    "                'canonical_question': question,\n",
    "                'canonical_id': cluster_id,\n",
    "                'is_canonical': False,\n",
    "                'augmentation_method': f'paraphrase_{generator.provider}',\n",
    "                'confidence': float(similarity),\n",
    "                'source': 'generated'\n",
    "            })\n",
    "    \n",
    "    print(f\"✅ {len(all_rows)} yeni paraphrase oluşturuldu\")\n",
    "    \n",
    "    return pd.DataFrame(all_rows)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Metadata Zenginleştirme\n",
    "\n",
    "# %%\n",
    "def enrich_metadata(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Metadata zenginleştir\"\"\"\n",
    "    print(\"\\n🏷️  Metadata zenginleştiriliyor...\")\n",
    "    \n",
    "    df['id'] = df.apply(lambda x: hashlib.md5(f\"{x['question']}_{x['answer']}\".encode()).hexdigest()[:16], axis=1)\n",
    "    \n",
    "    if 'canonical_id' not in df.columns:\n",
    "        df['canonical_id'] = df.get('cluster_id', 0)\n",
    "    \n",
    "    if 'is_canonical' not in df.columns:\n",
    "        df['is_canonical'] = False\n",
    "    \n",
    "    # Kategori zaten var, eksikse doldur\n",
    "    if 'category' not in df.columns or df['category'].isna().any():\n",
    "        def predict_category(question: str) -> str:\n",
    "            question_lower = question.lower()\n",
    "            \n",
    "            if any(kw in question_lower for kw in ['kayıt', 'üye', 'hesap']):\n",
    "                return 'account'\n",
    "            elif any(kw in question_lower for kw in ['ders', 'kurs', 'eğitim', 'bootcamp']):\n",
    "                return 'courses'\n",
    "            elif any(kw in question_lower for kw in ['ödeme', 'fiyat', 'ücret']):\n",
    "                return 'payment'\n",
    "            elif any(kw in question_lower for kw in ['sertifika', 'diploma']):\n",
    "                return 'certification'\n",
    "            elif any(kw in question_lower for kw in ['destek', 'yardım', 'sorun']):\n",
    "                return 'support'\n",
    "            else:\n",
    "                return 'general'\n",
    "        \n",
    "        df['category'] = df['category'].fillna(df['question'].apply(predict_category))\n",
    "    \n",
    "    def predict_intent(question: str) -> str:\n",
    "        question_lower = question.lower()\n",
    "        \n",
    "        if any(kw in question_lower for kw in ['nasıl', 'ne şekilde', 'how']):\n",
    "            return 'how_to'\n",
    "        elif any(kw in question_lower for kw in ['nedir', 'ne demek', 'what']):\n",
    "            return 'definition'\n",
    "        elif any(kw in question_lower for kw in ['neden', 'niçin', 'why']):\n",
    "            return 'reasoning'\n",
    "        elif any(kw in question_lower for kw in ['ne zaman', 'when']):\n",
    "            return 'timing'\n",
    "        else:\n",
    "            return 'information'\n",
    "    \n",
    "    df['intent'] = df['question'].apply(predict_intent)\n",
    "    \n",
    "    # Keywords zaten var, eksikse doldur\n",
    "    if 'keywords' not in df.columns or df['keywords'].isna().any():\n",
    "        def extract_keywords(text: str) -> str:\n",
    "            words = re.findall(r'\\b\\w{4,}\\b', text.lower())\n",
    "            return ', '.join(list(set(words))[:5])\n",
    "        \n",
    "        df['keywords'] = df['keywords'].fillna(df['question'].apply(extract_keywords))\n",
    "    \n",
    "    # Keywords listeyse stringe çevir\n",
    "    df['keywords'] = df['keywords'].apply(lambda x: ', '.join(x) if isinstance(x, list) else str(x))\n",
    "    \n",
    "    df['entities'] = ''\n",
    "    \n",
    "    # Difficulty zaten var, eksikse hesapla\n",
    "    if 'difficulty_level' in df.columns:\n",
    "        df['difficulty'] = df['difficulty_level']\n",
    "    else:\n",
    "        def estimate_difficulty(answer: str) -> str:\n",
    "            length = len(answer)\n",
    "            if length < 100:\n",
    "                return 'easy'\n",
    "            elif length < 300:\n",
    "                return 'medium'\n",
    "            else:\n",
    "                return 'hard'\n",
    "        \n",
    "        df['difficulty'] = df['answer'].apply(estimate_difficulty)\n",
    "    \n",
    "    if 'augmentation_method' not in df.columns:\n",
    "        df['augmentation_method'] = 'original'\n",
    "    \n",
    "    if 'confidence' not in df.columns:\n",
    "        df['confidence'] = 1.0\n",
    "    \n",
    "    if 'created_at' not in df.columns:\n",
    "        df['created_at'] = datetime.now().isoformat()\n",
    "    \n",
    "    print(\"✅ Metadata zenginleştirme tamamlandı\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7. Ana İşlem\n",
    "\n",
    "# %%\n",
    "# Logger kur\n",
    "log_dir = os.path.join(CONFIG['out_dir'], 'logs')\n",
    "logger = setup_logger(log_dir)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"🚀 DEEP SSS ENRICHER BAŞLATILDI\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# %% \n",
    "# 1. Veri Yükleme\n",
    "df1 = load_dataset(CONFIG['input1'])\n",
    "df2 = load_dataset(CONFIG['input2'])\n",
    "\n",
    "# %%\n",
    "# 2. Birleştirme ve Temizleme\n",
    "df = merge_and_deduplicate(df1, df2)\n",
    "\n",
    "# %%\n",
    "# 3. Embedding Oluşturma\n",
    "embeddings, model = create_embeddings(df['question'].tolist())\n",
    "\n",
    "# %%\n",
    "# 4. Semantik Kümeleme\n",
    "df = cluster_questions(df, embeddings, CONFIG['cluster_threshold'])\n",
    "\n",
    "# %%\n",
    "# 5. Canonical Sorular\n",
    "df, review_df = canonicalize_clusters(df)\n",
    "\n",
    "canonical_mask = df.groupby('cluster_id')['question'].transform(lambda x: x == x.iloc[0])\n",
    "df['is_canonical'] = canonical_mask\n",
    "\n",
    "# %%\n",
    "# 6. Paraphrase Üretimi\n",
    "if CONFIG['n_paraphrases'] > 0:\n",
    "    api_key = CONFIG['api_key'] or os.getenv('ANTHROPIC_API_KEY') or os.getenv('OPENAI_API_KEY')\n",
    "    \n",
    "    if CONFIG['provider'] != 'local' and not api_key:\n",
    "        print(\"⚠️  API key bulunamadı, 'local' moda geçiliyor\")\n",
    "        CONFIG['provider'] = 'local'\n",
    "    \n",
    "    generator = ParaphraseGenerator(CONFIG['provider'], api_key, CONFIG['seed'])\n",
    "    para_df = generate_paraphrases(df, generator, CONFIG['n_paraphrases'], embeddings, model)\n",
    "    \n",
    "    df = pd.concat([df, para_df], ignore_index=True)\n",
    "    print(f\"\\n📊 Toplam satır (paraphrase sonrası): {len(df)}\")\n",
    "\n",
    "# %%\n",
    "# 7. Metadata Zenginleştirme\n",
    "df = enrich_metadata(df)\n",
    "\n",
    "# %%\n",
    "# 8. Sonuçları Kaydetme\n",
    "os.makedirs(CONFIG['out_dir'], exist_ok=True)\n",
    "\n",
    "df.to_json(os.path.join(CONFIG['out_dir'], 'enriched_dataset.jsonl'), \n",
    "           orient='records', lines=True, force_ascii=False)\n",
    "df.to_csv(os.path.join(CONFIG['out_dir'], 'enriched_dataset.csv'), \n",
    "          index=False, encoding='utf-8')\n",
    "\n",
    "canonical_df = df[df['is_canonical'] == True][['cluster_id', 'canonical_question', \n",
    "                                                 'canonical_answer', 'category', 'keywords']]\n",
    "canonical_df.to_csv(os.path.join(CONFIG['out_dir'], 'canonical_questions.csv'), \n",
    "                    index=False, encoding='utf-8')\n",
    "\n",
    "if len(review_df) > 0:\n",
    "    review_df.to_csv(os.path.join(CONFIG['out_dir'], 'review_needed.csv'), \n",
    "                     index=False, encoding='utf-8')\n",
    "\n",
    "df.head(50).to_csv(os.path.join(CONFIG['out_dir'], 'preview.csv'), \n",
    "                   index=False, encoding='utf-8')\n",
    "\n",
    "# %%\n",
    "# 9. Manifest Oluşturma\n",
    "manifest = {\n",
    "    'creation_date': datetime.now().isoformat(),\n",
    "    'total_records': int(len(df)),\n",
    "    'original_records': int(len(df[df['augmentation_method'] == 'original'])),\n",
    "    'paraphrased_records': int(len(df[df['augmentation_method'].str.contains('paraphrase', na=False)])),\n",
    "    'n_clusters': int(df['cluster_id'].nunique()),\n",
    "    'n_canonical': int(df['is_canonical'].sum()),\n",
    "    'provider': CONFIG['provider'],\n",
    "    'n_paraphrases_per_question': CONFIG['n_paraphrases'],\n",
    "    'seed': CONFIG['seed'],\n",
    "    'categories': {str(k): int(v) for k, v in df['category'].value_counts().to_dict().items()},\n",
    "    'intents': {str(k): int(v) for k, v in df['intent'].value_counts().to_dict().items()},\n",
    "    'augmentation_methods': {str(k): int(v) for k, v in df['augmentation_method'].value_counts().to_dict().items()},\n",
    "    'difficulty_distribution': {str(k): int(v) for k, v in df['difficulty'].value_counts().to_dict().items()},\n",
    "    'review_needed_count': int(len(review_df)),\n",
    "    'processing_time_seconds': round(time.time() - start_time, 2)\n",
    "}\n",
    "\n",
    "with open(os.path.join(CONFIG['out_dir'], 'manifest.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(manifest, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"\\n💾 Tüm çıktılar kaydedildi!\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8. Sonuç Özeti\n",
    "\n",
    "# %%\n",
    "print(\"=\"*80)\n",
    "print(\"✅ İŞLEM TAMAMLANDI\")\n",
    "print(\"=\"*80)\n",
    "print(f\"📊 Toplam kayıt: {manifest['total_records']:,}\")\n",
    "print(f\"📝 Orijinal kayıt: {manifest['original_records']:,}\")\n",
    "print(f\"🎭 Paraphrase kayıt: {manifest['paraphrased_records']:,}\")\n",
    "print(f\"🔍 Küme sayısı: {manifest['n_clusters']:,}\")\n",
    "print(f\"⭐ Canonical soru: {manifest['n_canonical']:,}\")\n",
    "print(f\"⚠️  İnceleme gereken: {manifest['review_needed_count']:,}\")\n",
    "print(f\"⏱️  İşlem süresi: {manifest['processing_time_seconds']:.2f} saniye\")\n",
    "print(f\"📁 Çıktı dizini: {CONFIG['out_dir']}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# %%\n",
    "# Örnek sonuçları görüntüle\n",
    "print(\"\\n📋 Örnek Canonical Sorular:\")\n",
    "display(canonical_df.head(10))\n",
    "\n",
    "print(\"\\n📋 Örnek Paraphrase'ler:\")\n",
    "display(df[df['augmentation_method'].str.contains('paraphrase', na=False)].head(10))\n",
    "\n",
    "print(\"\\n📊 Kategori Dağılımı:\")\n",
    "display(df['category'].value_counts())\n",
    "\n",
    "print(\"\\n📊 Intent Dağılımı:\")\n",
    "display(df['intent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9ff417-6ba0-488f-a37f-7bab981eff15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
