{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574b9f03-d145-40db-be06-120261c82c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "print(\"Uyumlu kütüphane versiyonları kuruluyor... Lütfen bekleyin.\")\n",
    "%pip install --upgrade --quiet \"langchain==0.1.20\" \"langchain-community==0.0.38\" \"langchain-core==0.1.52\" \"langchain-google-genai\" \"langchain-chroma\" \"langchain-huggingface\" \"torch\" \"sentence-transformers\" \"beautifulsoup4\" \"jq\" \"numpy<2.0.0\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Kurulum tamamlandı. Ortam başarıyla yüklendi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0741327-3b36-4663-a271-bd3af1aded1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "project_root = r\"C:\\Users\\yedis\\Desktop\\yehu\\Github Repo\\MentorMate-SSS\"\n",
    "output_path = os.path.join(project_root, \"output\")\n",
    "enriched_file_path = os.path.join(output_path, \"enriched_dataset.jsonl\")\n",
    "generated_file_path = os.path.join(output_path, \"generated_data_google.jsonl\")\n",
    "\n",
    "\n",
    "print(\"Veri setleri temel formatta yükleniyor...\")\n",
    "loader_enriched = JSONLoader(\n",
    "    file_path=enriched_file_path,\n",
    "    jq_schema='.',\n",
    "    json_lines=True,\n",
    "    text_content=False\n",
    ")\n",
    "loader_generated = JSONLoader(\n",
    "    file_path=generated_file_path,\n",
    "    jq_schema='.',\n",
    "    json_lines=True,\n",
    "    text_content=False\n",
    ")\n",
    "documents_enriched = loader_enriched.load()\n",
    "documents_generated = loader_generated.load()\n",
    "all_documents_raw = documents_enriched + documents_generated\n",
    "print(f\"Başarıyla yüklendi. {len(all_documents_raw)} ham döküman bulundu.\")\n",
    "\n",
    "print(\"Dökümanlar 'Soru-Cevap' formatına dönüştürülüyor...\")\n",
    "all_documents = []\n",
    "for doc in all_documents_raw:\n",
    "    try:\n",
    "\n",
    "        record = json.loads(doc.page_content) if isinstance(doc.page_content, str) else doc.page_content\n",
    "        \n",
    "        question = record.get(\"question\") or record.get(\"soru\", \"Soru belirtilmemiş\")\n",
    "        answer = record.get(\"answer\") or record.get(\"cevap\", \"Cevap belirtilmemiş\")\n",
    "        source = record.get(\"source\", \"N/A\")\n",
    "\n",
    "        new_content = f\"Soru: {question}\\nCevap: {answer}\"\n",
    "        \n",
    "        doc.page_content = new_content\n",
    "        doc.metadata = {\"source\": source}\n",
    "        all_documents.append(doc)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Uyarı: Bir satır işlenirken hata oluştu ve atlandı: {e}\")\n",
    "        continue\n",
    "\n",
    "print(\"Dönüştürme işlemi tamamlandı!\")\n",
    "print(f\"Toplam döküman sayısı: {len(all_documents)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87724b7d-ee67-4474-89e4-0125337b5d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "file_to_check = r\"C:\\Users\\yedis\\Desktop\\yehu\\Github Repo\\MentorMate-SSS\\output\\enriched_dataset.jsonl\"\n",
    "\n",
    "print(f\"'{os.path.basename(file_to_check)}' dosyası kontrol ediliyor...\")\n",
    "\n",
    "error_found = False\n",
    "try:\n",
    "    with open(file_to_check, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            try:\n",
    "                json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"\\n!!! HATA BULUNDU !!!\")\n",
    "                print(f\"Sorunlu Satır Numarası: {i + 1}\")\n",
    "                print(f\"Hata Mesajı: {e}\")\n",
    "                print(\"\\n--- Sorunlu Satırın İçeriği ---\")\n",
    "                print(line)\n",
    "                print(\"---------------------------------\")\n",
    "                error_found = True\n",
    "                break\n",
    "    \n",
    "    if not error_found:\n",
    "        print(\"\\nDosya kontrol edildi, herhangi bir JSON format hatası bulunamadı.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"HATA: Dosya bulunamadı! -> {file_to_check}\")\n",
    "except Exception as e:\n",
    "    print(f\"Beklenmedik bir hata oluştu: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccea00a-90da-41a1-98ab-5c5b748cf0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "file_to_check = r\"C:\\Users\\yedis\\Desktop\\yehu\\Github Repo\\MentorMate-SSS\\output\\generated_data_google.jsonl\"\n",
    "\n",
    "print(f\"'{os.path.basename(file_to_check)}' dosyası kontrol ediliyor...\")\n",
    "\n",
    "error_found = False\n",
    "try:\n",
    "    with open(file_to_check, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if not line.strip():\n",
    "                print(f\"\\n!!! UYARI: Boş satır bulundu !!!\")\n",
    "                print(f\"Satır Numarası: {i + 1}\")\n",
    "                error_found = True\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                if 'question' not in data:\n",
    "                    print(f\"\\n!!! HATA BULUNDU: 'soru' anahtarı eksik !!!\")\n",
    "                    print(f\"Sorunlu Satır Numarası: {i + 1}\")\n",
    "                    print(\"\\n--- Sorunlu Satırın İçeriği ---\")\n",
    "                    print(line)\n",
    "                    print(\"---------------------------------\")\n",
    "                    error_found = True\n",
    "                    break \n",
    "            except json.JSONDecodeError as e:\n",
    "                \n",
    "                print(f\"\\n!!! HATA BULUNDU: JSON format hatası !!!\")\n",
    "                print(f\"Sorunlu Satır Numarası: {i + 1}\")\n",
    "                print(f\"Hata Mesajı: {e}\")\n",
    "                print(\"\\n--- Sorunlu Satırın İçeriği ---\")\n",
    "                print(line)\n",
    "                error_found = True\n",
    "                break\n",
    "\n",
    "    if not error_found:\n",
    "        print(\"\\nDosya kontrol edildi, 'soru' anahtarı tüm satırlarda mevcut.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"HATA: Dosya bulunamadı! -> {file_to_check}\")\n",
    "except Exception as e:\n",
    "    print(f\"Beklenmedik bir hata oluştu: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2120c04c-8f4a-44d8-93ea-2269d023dd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document\n",
    "import shutil \n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\*\\*', '', text) \n",
    "    text = text.strip()              \n",
    "    return text\n",
    "\n",
    "project_root = \"..\" \n",
    "db_path = os.path.join(project_root, \"chroma_db\")\n",
    "collection_name = \"mentormate_faq\"\n",
    "\n",
    "file_paths = [\n",
    "    os.path.join(project_root, \"output\", \"generated_data_google.jsonl\"),\n",
    "    os.path.join(project_root, \"output\", \"enriched_dataset.jsonl\")\n",
    "]\n",
    "\n",
    "\n",
    "if os.path.exists(db_path):\n",
    "    print(f\"'{db_path}' konumunda mevcut bir veritabanı bulundu. Temiz kurulum için siliniyor...\")\n",
    "    shutil.rmtree(db_path) \n",
    "    print(\"Eski veritabanı silindi.\")\n",
    "\n",
    "print(\"Veritabanı sıfırdan oluşturulacak...\")\n",
    "\n",
    "print(\"Embedding modeli yükleniyor...\")\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    model_kwargs={'device': 'cpu'}\n",
    ")\n",
    "print(\"Embedding modeli yüklendi.\")\n",
    "\n",
    "all_documents = []\n",
    "print(\"Veri setleri okunuyor ve birleştiriliyor...\")\n",
    "for file_path in file_paths:\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"UYARI: '{file_path}' dosyası bulunamadı, atlanıyor.\")\n",
    "        continue\n",
    "        \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                item = json.loads(line)\n",
    "                cleaned_question = clean_text(item['question'])\n",
    "                \n",
    "                page_content = f\"Soru: {cleaned_question}\\nCevap: {item['answer']}\"\n",
    "                doc = Document(page_content=page_content, metadata={\"source\": os.path.basename(file_path)})\n",
    "                all_documents.append(doc)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"UYARI: '{file_path}' dosyasında hatalı bir satır atlandı.\")\n",
    "\n",
    "print(f\"Toplam {len(all_documents)} adet doküman temizlendi ve birleştirildi.\")\n",
    "\n",
    "if all_documents:\n",
    "    print(\"Birleştirilmiş verilerle ChromaDB veritabanı oluşturuluyor...\")\n",
    "    vectordb = Chroma.from_documents(\n",
    "        documents=all_documents,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=db_path,\n",
    "        collection_name=collection_name\n",
    "    )\n",
    "    print(f\"Veritabanı başarıyla oluşturuldu! Toplam {len(all_documents)} doküman eklendi.\")\n",
    "else:\n",
    "    print(\"HATA: Veritabanına eklenecek hiçbir doküman bulunamadı. Lütfen dosya yollarını kontrol edin.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f00ec6f-4558-4dd5-b329-9998012d7583",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "db_path = os.path.join(project_root, \"chroma_db\")\n",
    "collection_name = \"mentormate_faq\"\n",
    "\n",
    "\n",
    "print(\"Embedding modeli ve mevcut veritabanı yükleniyor...\")\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    model_kwargs={'device': 'cpu'}\n",
    ")\n",
    "\n",
    "vectordb = Chroma(\n",
    "    persist_directory=db_path, \n",
    "    embedding_function=embeddings,\n",
    "    collection_name=collection_name\n",
    ")\n",
    "\n",
    "print(\"Veritabanı başarıyla yüklendi!\")\n",
    "print(f\"Koleksiyondaki döküman sayısı: {vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06857e02-f577-413e-91f4-9d3c2bbe7143",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "print(\"Chatbot bileşenleri yükleniyor...\")\n",
    "chatbot_key = os.getenv(\"GOOGLE_API_KEY-cap\") \n",
    "if not chatbot_key: raise ValueError(\"HATA: GOOGLE_API_KEY-cap ortam değişkeni bulunamadı.\")\n",
    "else: print(\"Gemini API anahtarı başarıyla yüklendi.\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=chatbot_key, temperature=0.3)\n",
    "db_path = os.path.join(project_root, \"chroma_db\")\n",
    "collection_name = \"mentormate_faq\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\", model_kwargs={'device': 'cpu'})\n",
    "vectordb = Chroma(persist_directory=db_path, embedding_function=embeddings, collection_name=collection_name)\n",
    "print(\"Veritabanı başarıyla yüklendi.\")\n",
    "\n",
    "\n",
    "base_retriever = vectordb.as_retriever(search_kwargs={\"k\": 7})\n",
    "\n",
    "\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=base_retriever, llm=llm\n",
    ")\n",
    "print(\"Multi-Query Retriever başarıyla kuruldu.\")\n",
    "\n",
    "memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", k=4, return_messages=True, output_key='answer')\n",
    "custom_prompt_template = \"\"\"\n",
    "Sen, adı MentorMate olan, iki farklı uzmanlık alanına sahip bir yapay zeka asistanısın: \"Bootcamp Uzmanı\" ve \"Genel Konu Yardımcısı\".\n",
    "\n",
    "Görevin için izlemen gereken katı adımlar şunlardır:\n",
    "1.  **Önce Dokümanları Ara:** Kullanıcının sorusunu aldığında, ilk ve tek önceliğin cevabı sana verilen DOKÜMANLAR içinde aramaktır.\n",
    "2.  **Cevap Dokümanlardaysa (\"Bootcamp Uzmanı\" Rolü):**\n",
    "    * Cevabını oluşturmak için SADECE DOKÜMANLAR'daki \"Cevap:\" kısmını kullan. DOKÜMANLAR'daki \"Soru:\" metnini asla tekrarlama.\n",
    "    * Bilgiyi doğrudan, net ve profesyonel bir dille sun.\n",
    "    * Asla tahmin yürütme. Güvenilirlik senin en önemli özelliğindir.\n",
    "    * Cevabının sonunda mutlaka \"Kaynak:\" başlığı altında dokümanın 'source' bilgisini paylaş.\n",
    "3.  **Cevap Dokümanlarda Yoksa (\"Genel Konu Yardımcısı\" Rolü):**\n",
    "    * Kullanıcıya karşı tamamen dürüst ol ve durumu net bir şekilde belirt. Cevabına şu cümleyle başla: \"**Bu konu bootcamp'e özel veri setimde yer almıyor. Ancak, genel bilgimle yanıtlıyorum:**\"\n",
    "    * Bu giriş cümlesinden sonra, soruyu genel yapay zeka bilginle en iyi şekilde yanıtla.\n",
    "    * Bu modda cevap verirken kaynak gösterme.\n",
    "\n",
    "DOKÜMANLAR:\n",
    "{context}\n",
    "SOHBET GEÇMİŞİ:\n",
    "{chat_history}\n",
    "SORU:\n",
    "{question}\n",
    "CEVAP:\n",
    "\"\"\"\n",
    "CUSTOM_PROMPT = PromptTemplate(template=custom_prompt_template, input_variables=[\"context\", \"chat_history\", \"question\"])\n",
    "\n",
    "chatbot_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    combine_docs_chain_kwargs={\"prompt\": CUSTOM_PROMPT},\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"MentorMate Chatbot (PRO Sürüm) Hazır!\")\n",
    "print(\"=\"*50)\n",
    "print(\"Sohbete başlayabilirsin...\")\n",
    "print(\"\\n\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        query = input(\"Sen: \")\n",
    "        if query.lower() in [\"çıkış\", \"exit\"]:\n",
    "            print(\"Görüşmek üzere!\")\n",
    "            break\n",
    "        if not query.strip(): continue\n",
    "        result = chatbot_chain.invoke({\"question\": query})\n",
    "        answer = result[\"answer\"]\n",
    "        print(\"\\nMentorMate:\")\n",
    "        print(answer)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nBir hata oluştu: {e}\")\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
