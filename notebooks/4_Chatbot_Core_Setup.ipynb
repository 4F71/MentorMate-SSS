{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "574b9f03-d145-40db-be06-120261c82c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uyumlu kÃ¼tÃ¼phane versiyonlarÄ± kuruluyor... LÃ¼tfen bekleyin.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -yasn1-modules (c:\\users\\yedis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yasn1-modules (c:\\users\\yedis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yasn1-modules (c:\\users\\yedis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "==================================================\n",
      "Kurulum tamamlandÄ±. Ortam baÅŸarÄ±yla yÃ¼klendi.\n",
      "ArtÄ±k diÄŸer hÃ¼crelerle devam edebilirsiniz.\n",
      "EÄER BU HÃœCREDEN SONRA HATA ALIRSANIZ, SADECE KERNEL'I YENÄ°DEN BAÅLATIP BU HÃœCREYÄ° TEKRAR Ã‡ALIÅTIRIN.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# --- HÃœCRE 1: KURULUM VE YÃœKLEME (ZAMAN MAKÄ°NESÄ° Ã‡Ã–ZÃœMÃœ) ---\n",
    "\n",
    "# Bu komut, tÃ¼m kÃ¼tÃ¼phaneleri en son sÃ¼rÃ¼me deÄŸil,\n",
    "# bizim kodumuzla %100 uyumlu olduÄŸu bilinen belirli, kararlÄ± versiyonlara kurar.\n",
    "# Bu, \"ModuleNotFoundError\" hatasÄ±nÄ± kalÄ±cÄ± olarak Ã§Ã¶zecektir.\n",
    "print(\"Uyumlu kÃ¼tÃ¼phane versiyonlarÄ± kuruluyor... LÃ¼tfen bekleyin.\")\n",
    "%pip install --upgrade --quiet \"langchain==0.1.20\" \"langchain-community==0.0.38\" \"langchain-core==0.1.52\" \"langchain-google-genai\" \"langchain-chroma\" \"langchain-huggingface\" \"torch\" \"sentence-transformers\" \"beautifulsoup4\" \"jq\" \"numpy<2.0.0\"\n",
    "\n",
    "# Gerekli tÃ¼m modÃ¼lleri import et\n",
    "import os\n",
    "import json\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Kurulum tamamlandÄ±. Ortam baÅŸarÄ±yla yÃ¼klendi.\")\n",
    "print(\"ArtÄ±k diÄŸer hÃ¼crelerle devam edebilirsiniz.\")\n",
    "print(\"EÄER BU HÃœCREDEN SONRA HATA ALIRSANIZ, SADECE KERNEL'I YENÄ°DEN BAÅLATIP BU HÃœCREYÄ° TEKRAR Ã‡ALIÅTIRIN.\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0741327-3b36-4663-a271-bd3af1aded1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri setleri temel formatta yÃ¼kleniyor...\n",
      "BaÅŸarÄ±yla yÃ¼klendi. 3232 ham dÃ¶kÃ¼man bulundu.\n",
      "DÃ¶kÃ¼manlar 'Soru-Cevap' formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor...\n",
      "DÃ¶nÃ¼ÅŸtÃ¼rme iÅŸlemi tamamlandÄ±!\n",
      "Toplam dÃ¶kÃ¼man sayÄ±sÄ±: 3232\n"
     ]
    }
   ],
   "source": [
    "# --- HÃ¼cre 2: Veri YÃ¼kleme (Son ve Nihai DÃ¼zeltilmiÅŸ Versiyon) ---\n",
    "\n",
    "import json\n",
    "\n",
    "# --- Gerekli TanÄ±mlamalar ---\n",
    "project_root = r\"C:\\Users\\yedis\\Desktop\\yehu\\Github Repo\\MentorMate-SSS\"\n",
    "output_path = os.path.join(project_root, \"output\")\n",
    "enriched_file_path = os.path.join(output_path, \"enriched_dataset.jsonl\")\n",
    "generated_file_path = os.path.join(output_path, \"generated_data_google.jsonl\")\n",
    "\n",
    "# --- AdÄ±m 1: Veriyi 'text_content=False' ile yÃ¼kle ---\n",
    "# Bu, kÃ¼tÃ¼phanenin eski versiyonunun hata vermeden veriyi ham metin olarak yÃ¼klemesini saÄŸlar.\n",
    "print(\"Veri setleri temel formatta yÃ¼kleniyor...\")\n",
    "loader_enriched = JSONLoader(\n",
    "    file_path=enriched_file_path,\n",
    "    jq_schema='.',\n",
    "    json_lines=True,\n",
    "    text_content=False\n",
    ")\n",
    "loader_generated = JSONLoader(\n",
    "    file_path=generated_file_path,\n",
    "    jq_schema='.',\n",
    "    json_lines=True,\n",
    "    text_content=False\n",
    ")\n",
    "documents_enriched = loader_enriched.load()\n",
    "documents_generated = loader_generated.load()\n",
    "all_documents_raw = documents_enriched + documents_generated\n",
    "print(f\"BaÅŸarÄ±yla yÃ¼klendi. {len(all_documents_raw)} ham dÃ¶kÃ¼man bulundu.\")\n",
    "\n",
    "# --- AdÄ±m 2: Ham metinleri JSON'a Ã§evirip istediÄŸimiz formata getir ---\n",
    "print(\"DÃ¶kÃ¼manlar 'Soru-Cevap' formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor...\")\n",
    "all_documents = []\n",
    "for doc in all_documents_raw:\n",
    "    try:\n",
    "        # DÄ°KKAT: 'page_content' artÄ±k doÄŸrudan bir sÃ¶zlÃ¼k deÄŸil, bir metin.\n",
    "        # Bu metni json.loads() ile sÃ¶zlÃ¼ÄŸe (dict) Ã§eviriyoruz.\n",
    "        # --- DÃœZELTME BURADA ---\n",
    "        record = json.loads(doc.page_content) if isinstance(doc.page_content, str) else doc.page_content\n",
    "        \n",
    "        question = record.get(\"question\") or record.get(\"soru\", \"Soru belirtilmemiÅŸ\")\n",
    "        answer = record.get(\"answer\") or record.get(\"cevap\", \"Cevap belirtilmemiÅŸ\")\n",
    "        source = record.get(\"source\", \"N/A\")\n",
    "\n",
    "        new_content = f\"Soru: {question}\\nCevap: {answer}\"\n",
    "        \n",
    "        doc.page_content = new_content\n",
    "        doc.metadata = {\"source\": source}\n",
    "        all_documents.append(doc)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"UyarÄ±: Bir satÄ±r iÅŸlenirken hata oluÅŸtu ve atlandÄ±: {e}\")\n",
    "        continue\n",
    "\n",
    "print(\"DÃ¶nÃ¼ÅŸtÃ¼rme iÅŸlemi tamamlandÄ±!\")\n",
    "print(f\"Toplam dÃ¶kÃ¼man sayÄ±sÄ±: {len(all_documents)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87724b7d-ee67-4474-89e4-0125337b5d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hata AyÄ±klama Kodu (Girintileme DÃ¼zeltildi) ---\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Kontrol edilecek dosyanÄ±n tam yolunu belirt\n",
    "# Hata ilk olarak bu dosyada Ã§Ä±ktÄ±ÄŸÄ± iÃ§in bunu kontrol ediyoruz\n",
    "file_to_check = r\"C:\\Users\\yedis\\Desktop\\yehu\\Github Repo\\MentorMate-SSS\\output\\enriched_dataset.jsonl\"\n",
    "\n",
    "print(f\"'{os.path.basename(file_to_check)}' dosyasÄ± kontrol ediliyor...\")\n",
    "\n",
    "error_found = False\n",
    "try:\n",
    "    with open(file_to_check, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            try:\n",
    "                # Her satÄ±rÄ± tek tek JSON olarak iÅŸlemeyi dene\n",
    "                json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                # EÄŸer bir satÄ±rda hata bulunursa...\n",
    "                print(f\"\\n!!! HATA BULUNDU !!!\")\n",
    "                print(f\"Sorunlu SatÄ±r NumarasÄ±: {i + 1}\")\n",
    "                print(f\"Hata MesajÄ±: {e}\")\n",
    "                print(\"\\n--- Sorunlu SatÄ±rÄ±n Ä°Ã§eriÄŸi ---\")\n",
    "                print(line)\n",
    "                print(\"---------------------------------\")\n",
    "                error_found = True\n",
    "                # Ä°lk hatayÄ± bulduktan sonra dur\n",
    "                break\n",
    "    \n",
    "    # DÃ¶ngÃ¼ bittikten sonra kontrol et\n",
    "    if not error_found:\n",
    "        print(\"\\nDosya kontrol edildi, herhangi bir JSON format hatasÄ± bulunamadÄ±.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"HATA: Dosya bulunamadÄ±! -> {file_to_check}\")\n",
    "except Exception as e:\n",
    "    print(f\"Beklenmedik bir hata oluÅŸtu: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccea00a-90da-41a1-98ab-5c5b748cf0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hata AyÄ±klama Kodu: Eksik AnahtarÄ± Bulan Script ---\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Bu sefer ikinci dosyayÄ± kontrol ediyoruz\n",
    "file_to_check = r\"C:\\Users\\yedis\\Desktop\\yehu\\Github Repo\\MentorMate-SSS\\output\\generated_data_google.jsonl\"\n",
    "\n",
    "print(f\"'{os.path.basename(file_to_check)}' dosyasÄ± kontrol ediliyor...\")\n",
    "\n",
    "error_found = False\n",
    "try:\n",
    "    with open(file_to_check, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # BoÅŸ satÄ±rlarÄ± atla\n",
    "            if not line.strip():\n",
    "                print(f\"\\n!!! UYARI: BoÅŸ satÄ±r bulundu !!!\")\n",
    "                print(f\"SatÄ±r NumarasÄ±: {i + 1}\")\n",
    "                error_found = True\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                # 'soru' anahtarÄ± var mÄ± diye kontrol et\n",
    "                if 'question' not in data:\n",
    "                    print(f\"\\n!!! HATA BULUNDU: 'soru' anahtarÄ± eksik !!!\")\n",
    "                    print(f\"Sorunlu SatÄ±r NumarasÄ±: {i + 1}\")\n",
    "                    print(\"\\n--- Sorunlu SatÄ±rÄ±n Ä°Ã§eriÄŸi ---\")\n",
    "                    print(line)\n",
    "                    print(\"---------------------------------\")\n",
    "                    error_found = True\n",
    "                    break # Ä°lk hatayÄ± bulunca dur\n",
    "            except json.JSONDecodeError as e:\n",
    "                # Ã–nceki gibi format hatalarÄ±nÄ± da yakalayalÄ±m\n",
    "                print(f\"\\n!!! HATA BULUNDU: JSON format hatasÄ± !!!\")\n",
    "                print(f\"Sorunlu SatÄ±r NumarasÄ±: {i + 1}\")\n",
    "                print(f\"Hata MesajÄ±: {e}\")\n",
    "                print(\"\\n--- Sorunlu SatÄ±rÄ±n Ä°Ã§eriÄŸi ---\")\n",
    "                print(line)\n",
    "                error_found = True\n",
    "                break\n",
    "\n",
    "    if not error_found:\n",
    "        print(\"\\nDosya kontrol edildi, 'soru' anahtarÄ± tÃ¼m satÄ±rlarda mevcut.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"HATA: Dosya bulunamadÄ±! -> {file_to_check}\")\n",
    "except Exception as e:\n",
    "    print(f\"Beklenmedik bir hata oluÅŸtu: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2120c04c-8f4a-44d8-93ea-2269d023dd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VeritabanÄ± sÄ±fÄ±rdan oluÅŸturulacak...\n",
      "Embedding modeli yÃ¼kleniyor... (Bu iÅŸlem biraz sÃ¼rebilir)\n",
      "Embedding modeli yÃ¼klendi.\n",
      "Veri setleri okunuyor ve birleÅŸtiriliyor...\n",
      "Toplam 3232 adet dokÃ¼man temizlendi ve birleÅŸtirildi.\n",
      "BirleÅŸtirilmiÅŸ verilerle ChromaDB veritabanÄ± oluÅŸturuluyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… VeritabanÄ± baÅŸarÄ±yla oluÅŸturuldu! Toplam 3232 dokÃ¼man eklendi.\n"
     ]
    }
   ],
   "source": [
    "# --- HÃ¼cre 3A (Revize EdilmiÅŸ): BÄ°RLEÅÄ°K VeritabanÄ± OluÅŸturucu ---\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document\n",
    "import shutil # KlasÃ¶r silmek iÃ§in eklendi\n",
    "\n",
    "# --- 1. AdÄ±m: Temizlik Fonksiyonu ---\n",
    "# Bu fonksiyonun bu hÃ¼creden Ã¶nceki bir hÃ¼crede tanÄ±mlÄ± olduÄŸundan emin olun.\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\*\\*', '', text) # Markdown bold'u temizle\n",
    "    text = text.strip()              # BaÅŸtaki/sondaki boÅŸluklarÄ± temizle\n",
    "    return text\n",
    "\n",
    "# --- 2. AdÄ±m: Gerekli YollarÄ± ve DeÄŸiÅŸkenleri TanÄ±mla ---\n",
    "project_root = \"..\" \n",
    "db_path = os.path.join(project_root, \"chroma_db\")\n",
    "collection_name = \"mentormate_faq\"\n",
    "\n",
    "# --- HER Ä°KÄ° VERÄ° SETÄ°NÄ°N YOLUNU TANIMLA ---\n",
    "file_paths = [\n",
    "    os.path.join(project_root, \"output\", \"generated_data_google.jsonl\"),\n",
    "    os.path.join(project_root, \"output\", \"enriched_dataset.jsonl\") # <-- EKSÄ°K OLAN DOSYA EKLENDÄ°\n",
    "]\n",
    "\n",
    "# --- 3. AdÄ±m: VeritabanÄ±nÄ± Temiz ve BÄ°RLEÅÄ°K Veriyle Yeniden OluÅŸtur ---\n",
    "if os.path.exists(db_path):\n",
    "    print(f\"'{db_path}' konumunda mevcut bir veritabanÄ± bulundu. Temiz kurulum iÃ§in siliniyor...\")\n",
    "    shutil.rmtree(db_path) # Mevcut veritabanÄ±nÄ± otomatik olarak sil\n",
    "    print(\"Eski veritabanÄ± silindi.\")\n",
    "\n",
    "print(\"VeritabanÄ± sÄ±fÄ±rdan oluÅŸturulacak...\")\n",
    "\n",
    "# Embedding modelini yÃ¼kle\n",
    "print(\"Embedding modeli yÃ¼kleniyor... (Bu iÅŸlem biraz sÃ¼rebilir)\")\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    model_kwargs={'device': 'cpu'}\n",
    ")\n",
    "print(\"Embedding modeli yÃ¼klendi.\")\n",
    "\n",
    "# --- HER Ä°KÄ° DOSYAYI OKU, TEMÄ°ZLE VE BÄ°RLEÅTÄ°R ---\n",
    "all_documents = []\n",
    "print(\"Veri setleri okunuyor ve birleÅŸtiriliyor...\")\n",
    "for file_path in file_paths:\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"UYARI: '{file_path}' dosyasÄ± bulunamadÄ±, atlanÄ±yor.\")\n",
    "        continue\n",
    "        \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                item = json.loads(line)\n",
    "                # 'question' alanÄ±nÄ± temizle\n",
    "                cleaned_question = clean_text(item['question'])\n",
    "                \n",
    "                # DokÃ¼manÄ± temizlenmiÅŸ soru ile oluÅŸtur\n",
    "                page_content = f\"Soru: {cleaned_question}\\nCevap: {item['answer']}\"\n",
    "                doc = Document(page_content=page_content, metadata={\"source\": os.path.basename(file_path)})\n",
    "                all_documents.append(doc)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"UYARI: '{file_path}' dosyasÄ±nda hatalÄ± bir satÄ±r atlandÄ±.\")\n",
    "\n",
    "print(f\"Toplam {len(all_documents)} adet dokÃ¼man temizlendi ve birleÅŸtirildi.\")\n",
    "\n",
    "# TemizlenmiÅŸ ve birleÅŸtirilmiÅŸ dokÃ¼manlarla ChromaDB'yi oluÅŸtur\n",
    "if all_documents:\n",
    "    print(\"BirleÅŸtirilmiÅŸ verilerle ChromaDB veritabanÄ± oluÅŸturuluyor...\")\n",
    "    vectordb = Chroma.from_documents(\n",
    "        documents=all_documents,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=db_path,\n",
    "        collection_name=collection_name\n",
    "    )\n",
    "    print(f\"âœ… VeritabanÄ± baÅŸarÄ±yla oluÅŸturuldu! Toplam {len(all_documents)} dokÃ¼man eklendi.\")\n",
    "else:\n",
    "    print(\"âŒ HATA: VeritabanÄ±na eklenecek hiÃ§bir dokÃ¼man bulunamadÄ±. LÃ¼tfen dosya yollarÄ±nÄ± kontrol edin.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f00ec6f-4558-4dd5-b329-9998012d7583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- HÃ¼cre 3B: VeritabanÄ± YÃ¼kleyici (Her Zaman BurayÄ± Ã‡alÄ±ÅŸtÄ±r) ---\n",
    "\n",
    "import os\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# VeritabanÄ± yolu ve koleksiyon adÄ±\n",
    "db_path = os.path.join(project_root, \"chroma_db\")\n",
    "collection_name = \"mentormate_faq\"\n",
    "\n",
    "# VeritabanÄ±nÄ± diskten yÃ¼klemek iÃ§in aynÄ± embedding modelini tanÄ±mlamamÄ±z gerekir\n",
    "# Bu iÅŸlem hÄ±zlÄ±dÄ±r, sadece modelin yapÄ±sÄ±nÄ± hafÄ±zaya alÄ±r.\n",
    "print(\"Embedding modeli ve mevcut veritabanÄ± yÃ¼kleniyor...\")\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    model_kwargs={'device': 'cpu'}\n",
    ")\n",
    "\n",
    "# Daha Ã¶nce oluÅŸturulan ve kaydedilen veritabanÄ±nÄ± diskten yÃ¼kle\n",
    "vectordb = Chroma(\n",
    "    persist_directory=db_path, \n",
    "    embedding_function=embeddings,\n",
    "    collection_name=collection_name\n",
    ")\n",
    "\n",
    "print(\"VeritabanÄ± baÅŸarÄ±yla yÃ¼klendi!\")\n",
    "print(f\"Koleksiyondaki dÃ¶kÃ¼man sayÄ±sÄ±: {vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06857e02-f577-413e-91f4-9d3c2bbe7143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- HÃ¼cre 4: Nihai Chatbot (Multi-Query Retriever ile GÃ¼Ã§lendirilmiÅŸ) ---\n",
    "\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "# 1. Gerekli BileÅŸenleri YÃ¼kle (DeÄŸiÅŸiklik yok)\n",
    "print(\"Chatbot bileÅŸenleri yÃ¼kleniyor...\")\n",
    "chatbot_key = os.getenv(\"GOOGLE_API_KEY-cap\") \n",
    "if not chatbot_key: raise ValueError(\"HATA: GOOGLE_API_KEY-cap ortam deÄŸiÅŸkeni bulunamadÄ±.\")\n",
    "else: print(\"Gemini API anahtarÄ± baÅŸarÄ±yla yÃ¼klendi.\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=chatbot_key, temperature=0.3)\n",
    "db_path = os.path.join(project_root, \"chroma_db\")\n",
    "collection_name = \"mentormate_faq\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\", model_kwargs={'device': 'cpu'})\n",
    "vectordb = Chroma(persist_directory=db_path, embedding_function=embeddings, collection_name=collection_name)\n",
    "print(\"VeritabanÄ± baÅŸarÄ±yla yÃ¼klendi.\")\n",
    "\n",
    "# 2. Retriever'Ä± Kur (YENÄ° VE GÃœÃ‡LENDÄ°RÄ°LMÄ°Å YÃ–NTEM)\n",
    "# Ã–nce temel bir getirici oluÅŸturuyoruz.\n",
    "base_retriever = vectordb.as_retriever(search_kwargs={\"k\": 7}) # Arama aÄŸÄ±nÄ± biraz daha geniÅŸletelim (k=7)\n",
    "\n",
    "# Åimdi de MultiQueryRetriever'Ä± oluÅŸturuyoruz.\n",
    "# Bu, LLM'i kullanarak kullanÄ±cÄ± sorusundan birden fazla arama sorgusu Ã¼retir.\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=base_retriever, llm=llm\n",
    ")\n",
    "print(\"Multi-Query Retriever baÅŸarÄ±yla kuruldu.\")\n",
    "\n",
    "# 3. HafÄ±za ve Prompt (DeÄŸiÅŸiklik yok)\n",
    "memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", k=4, return_messages=True, output_key='answer')\n",
    "custom_prompt_template = \"\"\"\n",
    "Sen, adÄ± MentorMate olan, iki farklÄ± uzmanlÄ±k alanÄ±na sahip bir yapay zeka asistanÄ±sÄ±n: \"Bootcamp UzmanÄ±\" ve \"Genel Konu YardÄ±mcÄ±sÄ±\".\n",
    "\n",
    "GÃ¶revin iÃ§in izlemen gereken katÄ± adÄ±mlar ÅŸunlardÄ±r:\n",
    "1.  **Ã–nce DokÃ¼manlarÄ± Ara:** KullanÄ±cÄ±nÄ±n sorusunu aldÄ±ÄŸÄ±nda, ilk ve tek Ã¶nceliÄŸin cevabÄ± sana verilen DOKÃœMANLAR iÃ§inde aramaktÄ±r.\n",
    "2.  **Cevap DokÃ¼manlardaysa (\"Bootcamp UzmanÄ±\" RolÃ¼):**\n",
    "    * CevabÄ±nÄ± oluÅŸturmak iÃ§in SADECE DOKÃœMANLAR'daki \"Cevap:\" kÄ±smÄ±nÄ± kullan. DOKÃœMANLAR'daki \"Soru:\" metnini asla tekrarlama.\n",
    "    * Bilgiyi doÄŸrudan, net ve profesyonel bir dille sun.\n",
    "    * Asla tahmin yÃ¼rÃ¼tme. GÃ¼venilirlik senin en Ã¶nemli Ã¶zelliÄŸindir.\n",
    "    * CevabÄ±nÄ±n sonunda mutlaka \"Kaynak:\" baÅŸlÄ±ÄŸÄ± altÄ±nda dokÃ¼manÄ±n 'source' bilgisini paylaÅŸ.\n",
    "3.  **Cevap DokÃ¼manlarda Yoksa (\"Genel Konu YardÄ±mcÄ±sÄ±\" RolÃ¼):**\n",
    "    * KullanÄ±cÄ±ya karÅŸÄ± tamamen dÃ¼rÃ¼st ol ve durumu net bir ÅŸekilde belirt. CevabÄ±na ÅŸu cÃ¼mleyle baÅŸla: \"**Bu konu bootcamp'e Ã¶zel veri setimde yer almÄ±yor. Ancak, genel bilgimle yanÄ±tlÄ±yorum:**\"\n",
    "    * Bu giriÅŸ cÃ¼mlesinden sonra, soruyu genel yapay zeka bilginle en iyi ÅŸekilde yanÄ±tla.\n",
    "    * Bu modda cevap verirken kaynak gÃ¶sterme.\n",
    "\n",
    "DOKÃœMANLAR:\n",
    "{context}\n",
    "SOHBET GEÃ‡MÄ°ÅÄ°:\n",
    "{chat_history}\n",
    "SORU:\n",
    "{question}\n",
    "CEVAP:\n",
    "\"\"\"\n",
    "CUSTOM_PROMPT = PromptTemplate(template=custom_prompt_template, input_variables=[\"context\", \"chat_history\", \"question\"])\n",
    "\n",
    "# 4. RAG Zincirini Kur (DeÄŸiÅŸiklik yok, artÄ±k yeni 'retriever'Ä± kullanacak)\n",
    "chatbot_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    combine_docs_chain_kwargs={\"prompt\": CUSTOM_PROMPT},\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"ğŸ¤– MentorMate Chatbot (PRO SÃ¼rÃ¼m) HazÄ±r!\")\n",
    "print(\"=\"*50)\n",
    "print(\"Sohbete baÅŸlayabilirsin...\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# 5. Ä°nteraktif Sohbet DÃ¶ngÃ¼sÃ¼ (DeÄŸiÅŸiklik yok)\n",
    "while True:\n",
    "    try:\n",
    "        query = input(\"Sen: \")\n",
    "        if query.lower() in [\"Ã§Ä±kÄ±ÅŸ\", \"exit\"]:\n",
    "            print(\"GÃ¶rÃ¼ÅŸmek Ã¼zere!\")\n",
    "            break\n",
    "        if not query.strip(): continue\n",
    "        result = chatbot_chain.invoke({\"question\": query})\n",
    "        answer = result[\"answer\"]\n",
    "        print(\"\\nMentorMate:\")\n",
    "        print(answer)\n",
    "        # Kaynak gÃ¶sterme mantÄ±ÄŸÄ± aynÄ±\n",
    "    except Exception as e:\n",
    "        print(f\"\\nBir hata oluÅŸtu: {e}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94404366-b5a1-4aa1-a15a-f23d119f650c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
