{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "574b9f03-d145-40db-be06-120261c82c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uyumlu kütüphane versiyonları kuruluyor... Lütfen bekleyin.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -yasn1-modules (c:\\users\\yedis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yasn1-modules (c:\\users\\yedis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yasn1-modules (c:\\users\\yedis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "==================================================\n",
      "Kurulum tamamlandı. Ortam başarıyla yüklendi.\n",
      "Artık diğer hücrelerle devam edebilirsiniz.\n",
      "EĞER BU HÜCREDEN SONRA HATA ALIRSANIZ, SADECE KERNEL'I YENİDEN BAŞLATIP BU HÜCREYİ TEKRAR ÇALIŞTIRIN.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# --- HÜCRE 1: KURULUM VE YÜKLEME (ZAMAN MAKİNESİ ÇÖZÜMÜ) ---\n",
    "\n",
    "# Bu komut, tüm kütüphaneleri en son sürüme değil,\n",
    "# bizim kodumuzla %100 uyumlu olduğu bilinen belirli, kararlı versiyonlara kurar.\n",
    "# Bu, \"ModuleNotFoundError\" hatasını kalıcı olarak çözecektir.\n",
    "print(\"Uyumlu kütüphane versiyonları kuruluyor... Lütfen bekleyin.\")\n",
    "%pip install --upgrade --quiet \"langchain==0.1.20\" \"langchain-community==0.0.38\" \"langchain-core==0.1.52\" \"langchain-google-genai\" \"langchain-chroma\" \"langchain-huggingface\" \"torch\" \"sentence-transformers\" \"beautifulsoup4\" \"jq\" \"numpy<2.0.0\"\n",
    "\n",
    "# Gerekli tüm modülleri import et\n",
    "import os\n",
    "import json\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Kurulum tamamlandı. Ortam başarıyla yüklendi.\")\n",
    "print(\"Artık diğer hücrelerle devam edebilirsiniz.\")\n",
    "print(\"EĞER BU HÜCREDEN SONRA HATA ALIRSANIZ, SADECE KERNEL'I YENİDEN BAŞLATIP BU HÜCREYİ TEKRAR ÇALIŞTIRIN.\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0741327-3b36-4663-a271-bd3af1aded1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri setleri temel formatta yükleniyor...\n",
      "Başarıyla yüklendi. 3232 ham döküman bulundu.\n",
      "Dökümanlar 'Soru-Cevap' formatına dönüştürülüyor...\n",
      "Dönüştürme işlemi tamamlandı!\n",
      "Toplam döküman sayısı: 3232\n"
     ]
    }
   ],
   "source": [
    "# --- Hücre 2: Veri Yükleme (Son ve Nihai Düzeltilmiş Versiyon) ---\n",
    "\n",
    "import json\n",
    "\n",
    "# --- Gerekli Tanımlamalar ---\n",
    "project_root = r\"C:\\Users\\yedis\\Desktop\\yehu\\Github Repo\\MentorMate-SSS\"\n",
    "output_path = os.path.join(project_root, \"output\")\n",
    "enriched_file_path = os.path.join(output_path, \"enriched_dataset.jsonl\")\n",
    "generated_file_path = os.path.join(output_path, \"generated_data_google.jsonl\")\n",
    "\n",
    "# --- Adım 1: Veriyi 'text_content=False' ile yükle ---\n",
    "# Bu, kütüphanenin eski versiyonunun hata vermeden veriyi ham metin olarak yüklemesini sağlar.\n",
    "print(\"Veri setleri temel formatta yükleniyor...\")\n",
    "loader_enriched = JSONLoader(\n",
    "    file_path=enriched_file_path,\n",
    "    jq_schema='.',\n",
    "    json_lines=True,\n",
    "    text_content=False\n",
    ")\n",
    "loader_generated = JSONLoader(\n",
    "    file_path=generated_file_path,\n",
    "    jq_schema='.',\n",
    "    json_lines=True,\n",
    "    text_content=False\n",
    ")\n",
    "documents_enriched = loader_enriched.load()\n",
    "documents_generated = loader_generated.load()\n",
    "all_documents_raw = documents_enriched + documents_generated\n",
    "print(f\"Başarıyla yüklendi. {len(all_documents_raw)} ham döküman bulundu.\")\n",
    "\n",
    "# --- Adım 2: Ham metinleri JSON'a çevirip istediğimiz formata getir ---\n",
    "print(\"Dökümanlar 'Soru-Cevap' formatına dönüştürülüyor...\")\n",
    "all_documents = []\n",
    "for doc in all_documents_raw:\n",
    "    try:\n",
    "        # DİKKAT: 'page_content' artık doğrudan bir sözlük değil, bir metin.\n",
    "        # Bu metni json.loads() ile sözlüğe (dict) çeviriyoruz.\n",
    "        # --- DÜZELTME BURADA ---\n",
    "        record = json.loads(doc.page_content) if isinstance(doc.page_content, str) else doc.page_content\n",
    "        \n",
    "        question = record.get(\"question\") or record.get(\"soru\", \"Soru belirtilmemiş\")\n",
    "        answer = record.get(\"answer\") or record.get(\"cevap\", \"Cevap belirtilmemiş\")\n",
    "        source = record.get(\"source\", \"N/A\")\n",
    "\n",
    "        new_content = f\"Soru: {question}\\nCevap: {answer}\"\n",
    "        \n",
    "        doc.page_content = new_content\n",
    "        doc.metadata = {\"source\": source}\n",
    "        all_documents.append(doc)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Uyarı: Bir satır işlenirken hata oluştu ve atlandı: {e}\")\n",
    "        continue\n",
    "\n",
    "print(\"Dönüştürme işlemi tamamlandı!\")\n",
    "print(f\"Toplam döküman sayısı: {len(all_documents)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87724b7d-ee67-4474-89e4-0125337b5d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hata Ayıklama Kodu (Girintileme Düzeltildi) ---\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Kontrol edilecek dosyanın tam yolunu belirt\n",
    "# Hata ilk olarak bu dosyada çıktığı için bunu kontrol ediyoruz\n",
    "file_to_check = r\"C:\\Users\\yedis\\Desktop\\yehu\\Github Repo\\MentorMate-SSS\\output\\enriched_dataset.jsonl\"\n",
    "\n",
    "print(f\"'{os.path.basename(file_to_check)}' dosyası kontrol ediliyor...\")\n",
    "\n",
    "error_found = False\n",
    "try:\n",
    "    with open(file_to_check, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            try:\n",
    "                # Her satırı tek tek JSON olarak işlemeyi dene\n",
    "                json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                # Eğer bir satırda hata bulunursa...\n",
    "                print(f\"\\n!!! HATA BULUNDU !!!\")\n",
    "                print(f\"Sorunlu Satır Numarası: {i + 1}\")\n",
    "                print(f\"Hata Mesajı: {e}\")\n",
    "                print(\"\\n--- Sorunlu Satırın İçeriği ---\")\n",
    "                print(line)\n",
    "                print(\"---------------------------------\")\n",
    "                error_found = True\n",
    "                # İlk hatayı bulduktan sonra dur\n",
    "                break\n",
    "    \n",
    "    # Döngü bittikten sonra kontrol et\n",
    "    if not error_found:\n",
    "        print(\"\\nDosya kontrol edildi, herhangi bir JSON format hatası bulunamadı.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"HATA: Dosya bulunamadı! -> {file_to_check}\")\n",
    "except Exception as e:\n",
    "    print(f\"Beklenmedik bir hata oluştu: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccea00a-90da-41a1-98ab-5c5b748cf0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hata Ayıklama Kodu: Eksik Anahtarı Bulan Script ---\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Bu sefer ikinci dosyayı kontrol ediyoruz\n",
    "file_to_check = r\"C:\\Users\\yedis\\Desktop\\yehu\\Github Repo\\MentorMate-SSS\\output\\generated_data_google.jsonl\"\n",
    "\n",
    "print(f\"'{os.path.basename(file_to_check)}' dosyası kontrol ediliyor...\")\n",
    "\n",
    "error_found = False\n",
    "try:\n",
    "    with open(file_to_check, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # Boş satırları atla\n",
    "            if not line.strip():\n",
    "                print(f\"\\n!!! UYARI: Boş satır bulundu !!!\")\n",
    "                print(f\"Satır Numarası: {i + 1}\")\n",
    "                error_found = True\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                # 'soru' anahtarı var mı diye kontrol et\n",
    "                if 'question' not in data:\n",
    "                    print(f\"\\n!!! HATA BULUNDU: 'soru' anahtarı eksik !!!\")\n",
    "                    print(f\"Sorunlu Satır Numarası: {i + 1}\")\n",
    "                    print(\"\\n--- Sorunlu Satırın İçeriği ---\")\n",
    "                    print(line)\n",
    "                    print(\"---------------------------------\")\n",
    "                    error_found = True\n",
    "                    break # İlk hatayı bulunca dur\n",
    "            except json.JSONDecodeError as e:\n",
    "                # Önceki gibi format hatalarını da yakalayalım\n",
    "                print(f\"\\n!!! HATA BULUNDU: JSON format hatası !!!\")\n",
    "                print(f\"Sorunlu Satır Numarası: {i + 1}\")\n",
    "                print(f\"Hata Mesajı: {e}\")\n",
    "                print(\"\\n--- Sorunlu Satırın İçeriği ---\")\n",
    "                print(line)\n",
    "                error_found = True\n",
    "                break\n",
    "\n",
    "    if not error_found:\n",
    "        print(\"\\nDosya kontrol edildi, 'soru' anahtarı tüm satırlarda mevcut.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"HATA: Dosya bulunamadı! -> {file_to_check}\")\n",
    "except Exception as e:\n",
    "    print(f\"Beklenmedik bir hata oluştu: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2120c04c-8f4a-44d8-93ea-2269d023dd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veritabanı sıfırdan oluşturulacak...\n",
      "Embedding modeli yükleniyor... (Bu işlem biraz sürebilir)\n",
      "Embedding modeli yüklendi.\n",
      "Veri setleri okunuyor ve birleştiriliyor...\n",
      "Toplam 3232 adet doküman temizlendi ve birleştirildi.\n",
      "Birleştirilmiş verilerle ChromaDB veritabanı oluşturuluyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Veritabanı başarıyla oluşturuldu! Toplam 3232 doküman eklendi.\n"
     ]
    }
   ],
   "source": [
    "# --- Hücre 3A (Revize Edilmiş): BİRLEŞİK Veritabanı Oluşturucu ---\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document\n",
    "import shutil # Klasör silmek için eklendi\n",
    "\n",
    "# --- 1. Adım: Temizlik Fonksiyonu ---\n",
    "# Bu fonksiyonun bu hücreden önceki bir hücrede tanımlı olduğundan emin olun.\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\*\\*', '', text) # Markdown bold'u temizle\n",
    "    text = text.strip()              # Baştaki/sondaki boşlukları temizle\n",
    "    return text\n",
    "\n",
    "# --- 2. Adım: Gerekli Yolları ve Değişkenleri Tanımla ---\n",
    "project_root = \"..\" \n",
    "db_path = os.path.join(project_root, \"chroma_db\")\n",
    "collection_name = \"mentormate_faq\"\n",
    "\n",
    "# --- HER İKİ VERİ SETİNİN YOLUNU TANIMLA ---\n",
    "file_paths = [\n",
    "    os.path.join(project_root, \"output\", \"generated_data_google.jsonl\"),\n",
    "    os.path.join(project_root, \"output\", \"enriched_dataset.jsonl\") # <-- EKSİK OLAN DOSYA EKLENDİ\n",
    "]\n",
    "\n",
    "# --- 3. Adım: Veritabanını Temiz ve BİRLEŞİK Veriyle Yeniden Oluştur ---\n",
    "if os.path.exists(db_path):\n",
    "    print(f\"'{db_path}' konumunda mevcut bir veritabanı bulundu. Temiz kurulum için siliniyor...\")\n",
    "    shutil.rmtree(db_path) # Mevcut veritabanını otomatik olarak sil\n",
    "    print(\"Eski veritabanı silindi.\")\n",
    "\n",
    "print(\"Veritabanı sıfırdan oluşturulacak...\")\n",
    "\n",
    "# Embedding modelini yükle\n",
    "print(\"Embedding modeli yükleniyor... (Bu işlem biraz sürebilir)\")\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    model_kwargs={'device': 'cpu'}\n",
    ")\n",
    "print(\"Embedding modeli yüklendi.\")\n",
    "\n",
    "# --- HER İKİ DOSYAYI OKU, TEMİZLE VE BİRLEŞTİR ---\n",
    "all_documents = []\n",
    "print(\"Veri setleri okunuyor ve birleştiriliyor...\")\n",
    "for file_path in file_paths:\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"UYARI: '{file_path}' dosyası bulunamadı, atlanıyor.\")\n",
    "        continue\n",
    "        \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                item = json.loads(line)\n",
    "                # 'question' alanını temizle\n",
    "                cleaned_question = clean_text(item['question'])\n",
    "                \n",
    "                # Dokümanı temizlenmiş soru ile oluştur\n",
    "                page_content = f\"Soru: {cleaned_question}\\nCevap: {item['answer']}\"\n",
    "                doc = Document(page_content=page_content, metadata={\"source\": os.path.basename(file_path)})\n",
    "                all_documents.append(doc)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"UYARI: '{file_path}' dosyasında hatalı bir satır atlandı.\")\n",
    "\n",
    "print(f\"Toplam {len(all_documents)} adet doküman temizlendi ve birleştirildi.\")\n",
    "\n",
    "# Temizlenmiş ve birleştirilmiş dokümanlarla ChromaDB'yi oluştur\n",
    "if all_documents:\n",
    "    print(\"Birleştirilmiş verilerle ChromaDB veritabanı oluşturuluyor...\")\n",
    "    vectordb = Chroma.from_documents(\n",
    "        documents=all_documents,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=db_path,\n",
    "        collection_name=collection_name\n",
    "    )\n",
    "    print(f\"✅ Veritabanı başarıyla oluşturuldu! Toplam {len(all_documents)} doküman eklendi.\")\n",
    "else:\n",
    "    print(\"❌ HATA: Veritabanına eklenecek hiçbir doküman bulunamadı. Lütfen dosya yollarını kontrol edin.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f00ec6f-4558-4dd5-b329-9998012d7583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hücre 3B: Veritabanı Yükleyici (Her Zaman Burayı Çalıştır) ---\n",
    "\n",
    "import os\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Veritabanı yolu ve koleksiyon adı\n",
    "db_path = os.path.join(project_root, \"chroma_db\")\n",
    "collection_name = \"mentormate_faq\"\n",
    "\n",
    "# Veritabanını diskten yüklemek için aynı embedding modelini tanımlamamız gerekir\n",
    "# Bu işlem hızlıdır, sadece modelin yapısını hafızaya alır.\n",
    "print(\"Embedding modeli ve mevcut veritabanı yükleniyor...\")\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    model_kwargs={'device': 'cpu'}\n",
    ")\n",
    "\n",
    "# Daha önce oluşturulan ve kaydedilen veritabanını diskten yükle\n",
    "vectordb = Chroma(\n",
    "    persist_directory=db_path, \n",
    "    embedding_function=embeddings,\n",
    "    collection_name=collection_name\n",
    ")\n",
    "\n",
    "print(\"Veritabanı başarıyla yüklendi!\")\n",
    "print(f\"Koleksiyondaki döküman sayısı: {vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06857e02-f577-413e-91f4-9d3c2bbe7143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hücre 4: Nihai Chatbot (Multi-Query Retriever ile Güçlendirilmiş) ---\n",
    "\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "# 1. Gerekli Bileşenleri Yükle (Değişiklik yok)\n",
    "print(\"Chatbot bileşenleri yükleniyor...\")\n",
    "chatbot_key = os.getenv(\"GOOGLE_API_KEY-cap\") \n",
    "if not chatbot_key: raise ValueError(\"HATA: GOOGLE_API_KEY-cap ortam değişkeni bulunamadı.\")\n",
    "else: print(\"Gemini API anahtarı başarıyla yüklendi.\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=chatbot_key, temperature=0.3)\n",
    "db_path = os.path.join(project_root, \"chroma_db\")\n",
    "collection_name = \"mentormate_faq\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\", model_kwargs={'device': 'cpu'})\n",
    "vectordb = Chroma(persist_directory=db_path, embedding_function=embeddings, collection_name=collection_name)\n",
    "print(\"Veritabanı başarıyla yüklendi.\")\n",
    "\n",
    "# 2. Retriever'ı Kur (YENİ VE GÜÇLENDİRİLMİŞ YÖNTEM)\n",
    "# Önce temel bir getirici oluşturuyoruz.\n",
    "base_retriever = vectordb.as_retriever(search_kwargs={\"k\": 7}) # Arama ağını biraz daha genişletelim (k=7)\n",
    "\n",
    "# Şimdi de MultiQueryRetriever'ı oluşturuyoruz.\n",
    "# Bu, LLM'i kullanarak kullanıcı sorusundan birden fazla arama sorgusu üretir.\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=base_retriever, llm=llm\n",
    ")\n",
    "print(\"Multi-Query Retriever başarıyla kuruldu.\")\n",
    "\n",
    "# 3. Hafıza ve Prompt (Değişiklik yok)\n",
    "memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", k=4, return_messages=True, output_key='answer')\n",
    "custom_prompt_template = \"\"\"\n",
    "Sen, adı MentorMate olan, iki farklı uzmanlık alanına sahip bir yapay zeka asistanısın: \"Bootcamp Uzmanı\" ve \"Genel Konu Yardımcısı\".\n",
    "\n",
    "Görevin için izlemen gereken katı adımlar şunlardır:\n",
    "1.  **Önce Dokümanları Ara:** Kullanıcının sorusunu aldığında, ilk ve tek önceliğin cevabı sana verilen DOKÜMANLAR içinde aramaktır.\n",
    "2.  **Cevap Dokümanlardaysa (\"Bootcamp Uzmanı\" Rolü):**\n",
    "    * Cevabını oluşturmak için SADECE DOKÜMANLAR'daki \"Cevap:\" kısmını kullan. DOKÜMANLAR'daki \"Soru:\" metnini asla tekrarlama.\n",
    "    * Bilgiyi doğrudan, net ve profesyonel bir dille sun.\n",
    "    * Asla tahmin yürütme. Güvenilirlik senin en önemli özelliğindir.\n",
    "    * Cevabının sonunda mutlaka \"Kaynak:\" başlığı altında dokümanın 'source' bilgisini paylaş.\n",
    "3.  **Cevap Dokümanlarda Yoksa (\"Genel Konu Yardımcısı\" Rolü):**\n",
    "    * Kullanıcıya karşı tamamen dürüst ol ve durumu net bir şekilde belirt. Cevabına şu cümleyle başla: \"**Bu konu bootcamp'e özel veri setimde yer almıyor. Ancak, genel bilgimle yanıtlıyorum:**\"\n",
    "    * Bu giriş cümlesinden sonra, soruyu genel yapay zeka bilginle en iyi şekilde yanıtla.\n",
    "    * Bu modda cevap verirken kaynak gösterme.\n",
    "\n",
    "DOKÜMANLAR:\n",
    "{context}\n",
    "SOHBET GEÇMİŞİ:\n",
    "{chat_history}\n",
    "SORU:\n",
    "{question}\n",
    "CEVAP:\n",
    "\"\"\"\n",
    "CUSTOM_PROMPT = PromptTemplate(template=custom_prompt_template, input_variables=[\"context\", \"chat_history\", \"question\"])\n",
    "\n",
    "# 4. RAG Zincirini Kur (Değişiklik yok, artık yeni 'retriever'ı kullanacak)\n",
    "chatbot_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    combine_docs_chain_kwargs={\"prompt\": CUSTOM_PROMPT},\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"🤖 MentorMate Chatbot (PRO Sürüm) Hazır!\")\n",
    "print(\"=\"*50)\n",
    "print(\"Sohbete başlayabilirsin...\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# 5. İnteraktif Sohbet Döngüsü (Değişiklik yok)\n",
    "while True:\n",
    "    try:\n",
    "        query = input(\"Sen: \")\n",
    "        if query.lower() in [\"çıkış\", \"exit\"]:\n",
    "            print(\"Görüşmek üzere!\")\n",
    "            break\n",
    "        if not query.strip(): continue\n",
    "        result = chatbot_chain.invoke({\"question\": query})\n",
    "        answer = result[\"answer\"]\n",
    "        print(\"\\nMentorMate:\")\n",
    "        print(answer)\n",
    "        # Kaynak gösterme mantığı aynı\n",
    "    except Exception as e:\n",
    "        print(f\"\\nBir hata oluştu: {e}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94404366-b5a1-4aa1-a15a-f23d119f650c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
