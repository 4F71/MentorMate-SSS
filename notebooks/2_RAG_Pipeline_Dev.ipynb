{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371b2240-7f76-40d2-9243-ffdd254948c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# HÜCRE -1: KÜTÜPHANE GÜNCELLEME (HER ŞEYDEN ÖNCE BUNU ÇALIŞTIR)\n",
    "# ============================================================================\n",
    "print(\"Tüm gerekli kütüphaneler en güncel versiyonlara yükseltiliyor...\")\n",
    "print(\"Bu işlem birkaç dakika sürebilir...\")\n",
    "\n",
    "# '!' işareti, bu komutun bir Python kodu değil, bir terminal komutu olduğunu belirtir.\n",
    "!pip install --upgrade --quiet google-generativeai langchain-google-genai langchain langchain-chroma langchain-huggingface\n",
    "\n",
    "print(\"\\n✅ Güncelleme tamamlandı! LÜTFEN BİR SONRAKİ ADIMA GEÇİN.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b416c6-d26e-40b5-993b-4634f9c8c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# HÜCRE 0: MODEL TEŞHİS ARACI\n",
    "# Bu kod, API anahtarınızla hangi Gemini modellerini kullanabileceğinizi listeler.\n",
    "# ============================================================================\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "print(\"API Anahtarınız için kullanılabilir Gemini modelleri listeleniyor...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    api_key = os.environ.get('GOOGLE_API_KEY')\n",
    "    if not api_key:\n",
    "        raise ValueError(\"API Anahtarı bulunamadı! Lütfen 'GOOGLE_API_KEY' ortam değişkenini kontrol edin.\")\n",
    "    \n",
    "    genai.configure(api_key=api_key)\n",
    "\n",
    "    # API'den, 'generateContent' metodunu destekleyen tüm modelleri listelemesini isteyelim.\n",
    "    model_found = False\n",
    "    for m in genai.list_models():\n",
    "        if 'generateContent' in m.supported_generation_methods:\n",
    "            print(f\"✅ Model Adı: {m.name}\")\n",
    "            print(f\"   Açıklama: {m.description}\\n\")\n",
    "            model_found = True\n",
    "            \n",
    "    if not model_found:\n",
    "        print(\"❌ 'generateContent' metodunu destekleyen hiçbir model bulunamadı.\")\n",
    "        print(\"   Lütfen Google AI Studio veya Google Cloud Console üzerinden projenizi ve API anahtarınızı kontrol edin.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"🚨 Modeller listelenirken bir hata oluştu: {e}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Teşhis tamamlandı. Lütfen yukarıdaki 'Model Adı' listesinden birini kopyalayın.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab1899c-e059-474e-a7df-7864e61c589f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# BÖLÜM 1: PROJE GÜNLÜĞÜ - Veri Üretme Serüveni ve Karşılaşılan Zorluklar\n",
    "# AMAÇ: Bu blok, veri zenginleştirme sürecinde karşılaşılan hataları,\n",
    "# denenen çözüm yollarını ve nihai çözüme nasıl ulaşıldığını belgelemektedir.\n",
    "# Bu sayede proje sunumunda, problem çözme yeteneği gösterilebilir.\n",
    "#\n",
    "# Bu bölümdeki kodlar çalıştırılamaz, sadece belgelendirme amaçlıdır.\n",
    "# ======================================================================================\n",
    "\n",
    "\"\"\"\n",
    "########################################################################################\n",
    "# DENEME 1: Google Gemini API ile Veri Üretme (İlk Hata)\n",
    "########################################################################################\n",
    "# HEDEF: Google Gemini API'sinin ücretsiz katmanını kullanarak cevap varyasyonları üretmek.\n",
    "#\n",
    "# KARŞILAŞILAN SORUN: Günlük Kota Hatası (429 ResourceExhausted)\n",
    "#   - Hata Mesajı: \"Quota exceeded for metric: ...generate_content_free_tier_requests, limit: 200\"\n",
    "#   - TEŞHİS: Script bir süre (yaklaşık 90-100 soru) çalıştıktan sonra duruyordu.\n",
    "#     Bunun sebebinin, Google'ın ücretsiz API katmanına koyduğu \"Günlük Toplam İstek Limiti\"\n",
    "#     olduğu anlaşıldı. Dakikalarca beklemek bu sorunu çözmüyordu çünkü limit günlük olarak sıfırlanıyordu.\n",
    "#\n",
    "#   - ÇÖZÜM PLANI: Bu işlemi tamamlamak için ya günlere bölerek manuel çalıştıracaktık ya da\n",
    "#     farklı bir API sağlayıcısına geçecektik. Daha esnek bir çözüm arayışına girdik.\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "# DENEME 2: Hugging Face API'ye Geçiş (Kütüphane ve Model Hataları)\n",
    "########################################################################################\n",
    "# HEDEF: Google'ın günlük limitini aşmak için Hugging Face'in ücretsiz Inference API'ını kullanmak.\n",
    "#        Model olarak Meta'nın güçlü Llama-3 modeli seçildi.\n",
    "#\n",
    "# KARŞILAŞILAN SORUN 1: Kütüphane Uyumluluk Hatası ('thinking' Hatası)\n",
    "#   - Hata Mesajı: \"Model.__init__() got an unexpected keyword argument 'thinking'\"\n",
    "#   - TEŞHİS: Bu hatanın temel sebebi, `google-generativeai` ve `langchain` gibi\n",
    "#     kütüphanelerin bilgisayarımızda yüklü olan versiyonlarının eski olmasıydı.\n",
    "#     API'dan gelen yeni bir alanı tanıyamıyorlardı.\n",
    "#   - ÇÖZÜM: Projenin en başına bir kurulum hücresi eklenerek tüm kütüphaneler\n",
    "#     `!pip install --upgrade` komutuyla en güncel sürümlerine yükseltildi.\n",
    "#\n",
    "# KARŞILAŞILAN SORUN 2: Model Görev Uyumsuzluğu Hatası\n",
    "#   - Hata Mesajı: \"Model ... is not supported for task text-generation... Supported task: conversational\"\n",
    "#   - TEŞHİS: LangChain'deki `HuggingFaceEndpoint` aracının, Llama-3-Instruct gibi\n",
    "#     modelleri \"sohbet\" formatı yerine \"düz metin üretme\" formatında çağırmaya çalıştığı anlaşıldı.\n",
    "#\n",
    "# KARŞILAŞILAN SORUN 3: Yanlış Sarmalayıcı (Wrapper) Kullanımı\n",
    "#   - Hata Mesajı: \"ValidationError: ... llm Field required\"\n",
    "#   - TEŞHİS: `ChatHuggingFace` aracının, doğrudan model bilgileriyle değil, önce\n",
    "#     oluşturulmuş bir `HuggingFaceEndpoint` nesnesini `llm=` parametresi olarak beklediği\n",
    "#     tespit edildi. Kod bu yapıya uygun değildi.\n",
    "#\n",
    "#   - ÇÖZÜM PLANI: Bu üç sorunu çözmek için kod, temel bağlantıyı `HuggingFaceEndpoint` ile\n",
    "#     kuracak ve ardından bu bağlantıyı `ChatHuggingFace` sarmalayıcısına verecek şekilde\n",
    "#     yeniden düzenlendi. Bu, hem doğru görev formatını (`conversational`) kullanmamızı sağladı\n",
    "#     hem de kütüphanenin beklediği doğru kurulumu gerçekleştirdi.\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "# DENEME 3: Hugging Face ile Uzun Süreli Çalışma (Aylık Kredi Hatası)\n",
    "########################################################################################\n",
    "# HEDEF: Düzeltilmiş Hugging Face koduyla tüm veri setini işlemek.\n",
    "#\n",
    "# KARŞILAŞILAN SORUN: Ödeme Gerekli Hatası (402 Payment Required)\n",
    "#   - Hata Mesajı: \"You have exceeded your monthly included credits for Inference Providers.\"\n",
    "#   - TEŞHİS: Script'in bir süre sorunsuz çalıştıktan sonra durması, bu sefer de\n",
    "#     Hugging Face'in \"aylık ücretsiz kullanım kredisinin\" bittiğini gösterdi.\n",
    "#     Bu, günlük sıfırlanan bir limit değildi ve bu yolu da tıkamış oldu.\n",
    "#     Bu durum, ücretsiz katmanların büyük ölçekli toplu işlemler için uygun\n",
    "#     olmadığını, daha çok deneme ve düşük trafikli uygulamalar için tasarlandığını kanıtladı.\n",
    "########################################################################################\n",
    "\n",
    "\"\"\"\n",
    "# ======================================================================================\n",
    "# HÜCRE 1: SENTETİK VERİ ÜRETİCİ (Hugging Face - Tam Açıklamalı ve Güvenli Versiyon)\n",
    "# AMAÇ: API limitlerine takılmadan, uzun süre boyunca hatasız bir şekilde çalışarak\n",
    "# veri setini zenginleştirmek.\n",
    "# YÖNTEM: Hugging Face Inference API'ı ve Llama-3 modeli kullanılır.\n",
    "# ÖZELLİKLER:\n",
    "#   - Kaldığı Yerden Devam Etme: Script durdurulursa veya hata alırsa, yeniden\n",
    "#     çalıştığında kaldığı yerden devam eder, ilerleme kaybolmaz.\n",
    "#   - Hata Yönetimi: Tek bir API çağrısı hata verse bile tüm işlem çökmez.\n",
    "#   - Hız Limiti Koruması: API limitlerine takılmamak için istekler arasında bekler.\n",
    "# ======================================================================================\n",
    "\n",
    "# -- Gerekli Kütüphanelerin İçe Aktarılması --\n",
    "import os  # Ortam değişkenlerini (API anahtarı gibi) okumak için\n",
    "import json  # Veri setimiz JSON formatında olduğu için verileri okumak ve yazmak için\n",
    "import time  # API istekleri arasında bekleme yapmak için\n",
    "\n",
    "# LangChain'in Hugging Face ile iletişim kurmamızı sağlayan araçları\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "# LLM'e göndereceğimiz talimatları (prompt) formatlamak için\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "# LLM'den gelen cevabı temiz bir metne dönüştürmek için\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "print(\"🤖 Sentetik Cevap Üretici (Hugging Face - Güvenli Mod) Başlatılıyor...\")\n",
    "\n",
    "# --- AYARLAR ---\n",
    "# Bu bölümde, script'in çalışması için gerekli olan dosya yolları ve parametreler tanımlanır.\n",
    "\n",
    "# Orijinal, temizlenmiş veri setimizin tam dosya yolu.\n",
    "INPUT_FILE_PATH = r\"C:\\Users\\yedis\\Desktop\\yehu\\Github Repo\\MentorMate-SSS\\output\\enriched_dataset.jsonl\"\n",
    "# Üretilecek yeni cevapların kaydedileceği dosyanın tam yolu.\n",
    "OUTPUT_FILE_PATH = r\"C:\\Users\\yedis\\Desktop\\yehu\\Github Repo\\MentorMate-SSS\\output\\generated_data_hf.jsonl\"\n",
    "# Orijinal veri setindeki her bir soru için kaç adet yeni cevap varyasyonu üretileceği.\n",
    "VARIANTS_PER_QUESTION = 2 \n",
    "\n",
    "# GÜVENLİK AYARI: Her API isteği arasında beklenecek saniye.\n",
    "# Bu, Hugging Face'in ücretsiz katmanının hız limitlerine takılma riskini en aza indirir.\n",
    "DELAY_SECONDS = 25 \n",
    "\n",
    "# Hugging Face üzerinde kullanmak istediğimiz açık kaynak modelin kimliği.\n",
    "HF_MODEL_NAME = \"meta-llama/Meta-Llama-3-8B-Instruct\" \n",
    "\n",
    "# --- API ve Model Yapılandırması ---\n",
    "# Bilgisayarın ortam değişkenlerinden 'HUGGINGFACE_HUB_TOKEN' adlı anahtarı okuyoruz.\n",
    "hf_token = os.environ.get('HUGGINGFACE_HUB_TOKEN')\n",
    "if not hf_token:\n",
    "    # Eğer anahtar bulunamazsa, kullanıcıyı uyararak programı durduruyoruz.\n",
    "    raise ValueError(\"Hugging Face API Token bulunamadı! Lütfen 'HUGGINGFACE_HUB_TOKEN' ortam değişkenini ayarlayın.\")\n",
    "\n",
    "# 1. Aşama: Hugging Face'teki model sunucusuna temel bir bağlantı (endpoint) kuruyoruz.\n",
    "# Bu bağlantı, modelin nasıl davranacağını belirleyen parametreleri içerir.\n",
    "endpoint_llm = HuggingFaceEndpoint(\n",
    "    repo_id=HF_MODEL_NAME,  # Hangi modeli kullanacağımız\n",
    "    huggingfacehub_api_token=hf_token,  # Kimlik doğrulama için API token'ımız\n",
    "    temperature=0.7,  # Modelin ne kadar \"yaratıcı\" olacağı (0'a yakın daha net, 1'e yakın daha rastgele)\n",
    "    max_new_tokens=256,  # Modelin üreteceği cevabın maksimum uzunluğu (kelime/token sayısı)\n",
    "    repetition_penalty=1.2,  # Modelin aynı kelimeleri tekrar etmesini engellemeye yönelik bir ceza puanı\n",
    ")\n",
    "\n",
    "# 2. Aşama: Bu temel bağlantıyı, LangChain'in sohbet formatında iletişim kurabilen\n",
    "# `ChatHuggingFace` sarmalayıcısına (wrapper) veriyoruz. Bu, modelle sohbet eder gibi konuşmamızı sağlar.\n",
    "llm = ChatHuggingFace(llm=endpoint_llm)\n",
    "print(f\"✅ Hugging Face Endpoint ve '{HF_MODEL_NAME}' modeli yapılandırıldı.\")\n",
    "\n",
    "# --- Prompt ve Zincir Yapılandırması ---\n",
    "# LLM'e ne yapması gerektiğini anlatan detaylı talimat metnimiz.\n",
    "# Llama-3'ün kendi özel formatına (<|...|>) tam uyan bir yapı kullanıyoruz.\n",
    "prompt_template_str = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "Sen bir metin yeniden yazma asistanısın. Görevin, verilen bir cevabı, anlamını tamamen koruyarak ama farklı kelimelerle yeniden yazmaktır. Sadece ve sadece yeniden yazılmış cevabı döndür. Başka hiçbir açıklama ekleme.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "Orijinal Soru: {soru}\n",
    "Orijinal Cevap: {orijinal_cevap}\n",
    "Yeniden Yazılmış Cevap:<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "# Yukarıdaki metni LangChain'in kullanabileceği bir şablon nesnesine dönüştürüyoruz.\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template_str)\n",
    "# LLM'den gelen cevabı, içindeki ekstra bilgileri temizleyerek saf bir metne dönüştüren bir ayrıştırıcı.\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# LangChain Expression Language (LCEL) kullanarak adımları birbirine zincirliyoruz.\n",
    "# Okunuşu: Prompt'u al -> LLM'e gönder -> Gelen cevabı ayrıştırıcıdan geçir.\n",
    "chain = prompt | llm | output_parser\n",
    "print(\"✅ LangChain zinciri oluşturuldu.\")\n",
    "\n",
    "# --- Veri Üretme Döngüsü ---\n",
    "# Tüm bu uzun işlemi, herhangi bir kritik hata durumunda çökmemesi için bir try-except bloğu içine alıyoruz.\n",
    "try:\n",
    "    # --- Kaldığı Yeri Hesaplama ---\n",
    "    start_index = 0\n",
    "    # Eğer daha önce bir çıktı dosyası oluşturulmuşsa...\n",
    "    if os.path.exists(OUTPUT_FILE_PATH):\n",
    "        # ...bu dosyayı aç ve içindeki satır sayısını oku.\n",
    "        with open(OUTPUT_FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "            lines_in_output = len(f.readlines())\n",
    "        # Üretilen varyasyon sayısından yola çıkarak, orijinal dosyada hangi sorudan devam etmemiz gerektiğini hesapla.\n",
    "        start_index = lines_in_output // VARIANTS_PER_QUESTION\n",
    "        print(f\"\\n Mevcut dosyada {lines_in_output} varyasyon bulundu.\")\n",
    "        if start_index > 0:\n",
    "            print(f\" İşleme {start_index + 1}. sorudan devam edilecek.\")\n",
    "\n",
    "    # Girdi dosyasını okuma ('r') modunda, çıktı dosyasını ise 'append' ('a' - sonuna ekle) modunda aç.\n",
    "    # 'a' modu, var olan veriyi silmeden yeni verileri dosyanın sonuna eklememizi sağlar.\n",
    "    with open(INPUT_FILE_PATH, 'r', encoding='utf-8') as infile, \\\n",
    "         open(OUTPUT_FILE_PATH, 'a', encoding='utf-8') as outfile:\n",
    "        \n",
    "        # Orijinal dosyadaki tüm satırları oku\n",
    "        lines = infile.readlines()\n",
    "        # Sadece kaldığımız yerden itibaren olan soruları işleme al\n",
    "        lines_to_process = lines[start_index:]\n",
    "        \n",
    "        total_lines = len(lines)\n",
    "        print(f\" Orijinal dosyada toplam {total_lines} soru var. Kalan {len(lines_to_process)} soru işlenecek.\")\n",
    "\n",
    "        if not lines_to_process:\n",
    "            print(\"Tüm sorular zaten işlenmiş. İşlem tamamlandı.\")\n",
    "        else:\n",
    "            print(f\"Her API çağrısı arasında {DELAY_SECONDS} saniye beklenecektir...\")\n",
    "\n",
    "        # İşlenecek her bir satır (soru-cevap çifti) için döngüyü başlat\n",
    "        for i, line in enumerate(lines_to_process, start=start_index):\n",
    "            original_data = json.loads(line)\n",
    "            question = original_data.get(\"question\")\n",
    "            answer = original_data.get(\"answer\")\n",
    "            if not question or not answer: continue\n",
    "\n",
    "            print(f\"\\n[{i+1}/{total_lines}] İşleniyor: '{question[:50]}...'\")\n",
    "            # Her soru için belirlediğimiz sayıda varyasyon üret\n",
    "            for j in range(VARIANTS_PER_QUESTION):\n",
    "                print(f\"  -> Varyasyon {j+1}/{VARIANTS_PER_QUESTION} üretiliyor...\")\n",
    "                # Bu iç try-except bloğu, tek bir API çağrısı hata verse bile döngünün devam etmesini sağlar.\n",
    "                try:\n",
    "                    # Zinciri çağırarak LLM'den yeni cevabı istiyoruz.\n",
    "                    new_answer = chain.invoke({\n",
    "                        \"soru\": question,\n",
    "                        \"orijinal_cevap\": answer\n",
    "                    })\n",
    "                    \n",
    "                    # Yeni oluşturulan veriyi formatlayıp dosyaya yazıyoruz.\n",
    "                    new_data_entry = {\"question\": question, \"answer\": new_answer.strip()}\n",
    "                    outfile.write(json.dumps(new_data_entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"    !! API Hatası: {e}. Bu varyasyon atlanıyor.\")\n",
    "                    # Eğer hata bir kota hatası ise, işlemi tamamen durdur.\n",
    "                    if \"quota\" in str(e).lower() or \"payment required\" in str(e).lower():\n",
    "                        print(\"    !! KOTA LİMİTİNE ULAŞILDI. İşlem durduruluyor. Lütfen daha sonra tekrar deneyin.\")\n",
    "                        raise e # Script'i durdurmak için hatayı yeniden fırlat.\n",
    "                \n",
    "                # Hız limitine takılmamak için bekle.\n",
    "                time.sleep(DELAY_SECONDS)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80 + f\"\\n✅ İŞLEM TAMAMLANDI! Üretilen veriler '{OUTPUT_FILE_PATH}' dosyasına kaydedildi.\\n\" + \"=\"*80)\n",
    "\n",
    "except Exception as e:\n",
    "    # Üstteki 'raise e' komutu çalıştığında veya dosyalarla ilgili bir sorun olduğunda bu mesaj gösterilir.\n",
    "    print(f\"\\nİşlem durduruldu. Üretilen veriler kaydedildi. Limitin sıfırlanmasını bekledikten sonra aynı hücreyi tekrar çalıştırarak devam edebilirsiniz.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2820b793-74f1-4482-8629-47aa9d9e5e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# HÜCRE: VERİ DOKTORU - TEKRAR EDEN VE POTANSİYEL YANLIŞ CEVAPLARI TESPİT ETME\n",
    "# ============================================================================\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Lütfen veri setinin yolunun doğru olduğundan emin ol\n",
    "INPUT_FILE_PATH = r\"C:\\Users\\yedis\\Desktop\\yehu\\Github Repo\\MentorMate-SSS\\output\\enriched_dataset.jsonl\"\n",
    "REPORT_FILE_PATH = r\"C:\\Users\\yedis\\Desktop\\yehu\\Github Repo\\MentorMate-SSS\\output\\data_quality_report.txt\"\n",
    "\n",
    "# Cevapları anahtar, soruları ise bir liste olarak tutacak bir sözlük oluşturalım\n",
    "answers_to_questions = defaultdict(list)\n",
    "\n",
    "print(f\"'{INPUT_FILE_PATH}' dosyası analiz ediliyor...\")\n",
    "\n",
    "# Dosyayı oku ve cevaplara göre soruları grupla\n",
    "try:\n",
    "    with open(INPUT_FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                if 'question' in data and 'answer' in data:\n",
    "                    answers_to_questions[data['answer']].append(data['question'])\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Uyarı: Bir satır okunamadı, geçiliyor.\")\n",
    "                continue\n",
    "\n",
    "    print(\"Analiz tamamlandı. Rapor oluşturuluyor...\")\n",
    "\n",
    "    # Rapor dosyasını yaz\n",
    "    with open(REPORT_FILE_PATH, 'w', encoding='utf-8') as f:\n",
    "        # En çok tekrar eden cevapları başa alalım\n",
    "        sorted_answers = sorted(answers_to_questions.items(), key=lambda item: len(item[1]), reverse=True)\n",
    "        \n",
    "        for answer, questions in sorted_answers:\n",
    "            f.write(\"=\"*80 + \"\\n\")\n",
    "            f.write(f\"CEVAP (Toplam {len(questions)} soru için kullanılmış):\\n\")\n",
    "            f.write(f\"{answer}\\n\")\n",
    "            f.write(\"-\" * 20 + \"\\n\")\n",
    "            f.write(\"Bu Cevabın Atandığı Sorular:\\n\")\n",
    "            for i, question in enumerate(questions, 1):\n",
    "                f.write(f\"  {i}. {question}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    print(f\"✅ Rapor başarıyla '{REPORT_FILE_PATH}' dosyasına kaydedildi.\")\n",
    "    print(\"Lütfen bu dosyayı açıp mantıksız Soru-Cevap eşleşmelerini kontrol et.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"HATA: Dosya bulunamadı: {INPUT_FILE_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"Beklenmedik bir hata oluştu: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85bbeb7b-6e50-4a75-a881-76e916ea1c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Sentetik Cevap Üretici (Google Gemini Versiyonu) Başlatılıyor...\n",
      "✅ LangChain ve Gemini modeli (models/gemini-2.0-flash) veri üretimi için yapılandırıldı.\n",
      "✅ LangChain zinciri oluşturuldu.\n",
      "\n",
      " Mevcut dosyada 2047 varyasyon bulundu.\n",
      " İşleme 1024. sorudan devam edilecek.\n",
      " Orijinal dosyada toplam 1077 soru var. Kalan 54 soru işlenecek.\n",
      "İşlem başlıyor...\n",
      "\n",
      "[1024/1077] İşleniyor: 'Yetenek havuzuna dahil edilme, bootcamp'in bir çık...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1025/1077] İşleniyor: 'Yetenek havuzuna dahil edilme, bootcamp'in bir çık...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1026/1077] İşleniyor: 'Sponsor şirket, başarıyla tamamlayanları kendi yet...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1027/1077] İşleniyor: 'Sponsor şirket, başarıyla tamamlayanları kendi yet...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1028/1077] İşleniyor: 'Başarılı bootcamp katılımcıları sponsor şirket tar...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1029/1077] İşleniyor: 'Başarılı bootcamp katılımcıları sponsor şirket tar...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1030/1077] İşleniyor: 'Yetenek havuzuna dahil olmak için ek bir başvuru g...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1031/1077] İşleniyor: 'Yetenek havuzuna dahil olmak için ek bir başvuru g...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1032/1077] İşleniyor: 'Bootcamp mezunları, sponsor şirketin yetenek havuz...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1033/1077] İşleniyor: 'Bootcamp mezunları, sponsor şirketin yetenek havuz...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1034/1077] İşleniyor: 'Sponsor şirket, yetenek havuzundan işe alım yapıyo...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1035/1077] İşleniyor: 'Sponsor şirket, yetenek havuzundan işe alım yapıyo...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1036/1077] İşleniyor: 'Bootcamp'i tamamlayan herkes yetenek havuzuna gire...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1037/1077] İşleniyor: 'Bootcamp'i tamamlayan herkes yetenek havuzuna gire...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1038/1077] İşleniyor: 'Yetenek havuzu, sponsor şirketin gelecekteki işe a...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1039/1077] İşleniyor: 'Yetenek havuzu, sponsor şirketin gelecekteki işe a...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1040/1077] İşleniyor: 'Bootcamp'i bitirince sponsor şirketin gözünde bir ...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1041/1077] İşleniyor: 'Bootcamp'i bitirince sponsor şirketin gözünde bir ...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1042/1077] İşleniyor: 'Sponsor şirketin yetenek havuzuna dahil olmanın fa...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1043/1077] İşleniyor: 'Sponsor şirketin yetenek havuzuna dahil olmanın fa...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1044/1077] İşleniyor: 'Bootcamp'i başarıyla tamamlamak sponsor şirkette i...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1045/1077] İşleniyor: 'Bootcamp'i başarıyla tamamlamak sponsor şirkette i...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1046/1077] İşleniyor: 'Sponsor şirketin yetenek havuzuna dahil olmak bir ...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1047/1077] İşleniyor: 'Sponsor şirketin yetenek havuzuna dahil olmak bir ...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1048/1077] İşleniyor: 'Sponsor şirketin yetenek havuzuna dahil edilme sür...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1049/1077] İşleniyor: 'Sponsor şirketin yetenek havuzuna dahil edilme sür...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1050/1077] İşleniyor: 'Yetenek havuzuna dahil edildikten sonra sponsor şi...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1051/1077] İşleniyor: 'Yetenek havuzuna dahil edildikten sonra sponsor şi...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1052/1077] İşleniyor: 'Bootcamp'i başarıyla tamamlamanın kriterleri yeten...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1053/1077] İşleniyor: 'Bootcamp'i başarıyla tamamlamanın kriterleri yeten...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1054/1077] İşleniyor: 'Sponsor şirketin yetenek havuzundaki kişilere önce...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1055/1077] İşleniyor: 'Sponsor şirketin yetenek havuzundaki kişilere önce...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1056/1077] İşleniyor: 'Sertifika alabilmek için projenin tamamlanması ger...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1057/1077] İşleniyor: 'Sertifika alabilmek için projenin tamamlanması ger...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1058/1077] İşleniyor: 'Eğitimin sonunda bir sertifika verileceğini doğrul...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1059/1077] İşleniyor: 'Eğitimin sonunda bir sertifika verileceğini doğrul...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1060/1077] İşleniyor: 'Bootcamp sertifikası projenin başarısına bağlı mı?...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1061/1077] İşleniyor: 'Bootcamp sertifikası projenin başarısına bağlı mı?...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1062/1077] İşleniyor: 'Projemi başarıyla tamamlayabilirsem sertifika alır...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1063/1077] İşleniyor: 'Projemi başarıyla tamamlayabilirsem sertifika alır...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1064/1077] İşleniyor: 'Sertifika, bootcamp'in sonunda mı verilir?...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1065/1077] İşleniyor: 'Sertifika, bootcamp'in sonunda mı verilir?...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1066/1077] İşleniyor: 'Başarılı bir proje sunumu sonrasında sertifika ala...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1067/1077] İşleniyor: 'Başarılı bir proje sunumu sonrasında sertifika ala...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1068/1077] İşleniyor: 'Bootcamp'i tamamlayınca sertifika alabilir miyim?...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1069/1077] İşleniyor: 'Bootcamp'i tamamlayınca sertifika alabilir miyim?...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1070/1077] İşleniyor: 'Bootcamp'i başarıyla tamamladığımda bir sertifika ...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1071/1077] İşleniyor: 'Bootcamp'i başarıyla tamamladığımda bir sertifika ...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1072/1077] İşleniyor: 'Bootcamp sertifikası için projenin başarıyla tamam...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1073/1077] İşleniyor: 'Bootcamp sertifikası için projenin başarıyla tamam...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1074/1077] İşleniyor: 'Sertifika alabilmek için projenin belirli bir başa...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1075/1077] İşleniyor: 'Sertifika alabilmek için projenin belirli bir başa...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1076/1077] İşleniyor: 'Projenin başarıyla tamamlanmaması durumunda sertif...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "[1077/1077] İşleniyor: 'Projenin başarıyla tamamlanmaması durumunda sertif...'\n",
      "  -> Varyasyon 1/2 üretiliyor...\n",
      "  -> Varyasyon 2/2 üretiliyor...\n",
      "\n",
      "================================================================================\n",
      "✅ İŞLEM TAMAMLANDI! Üretilen veriler 'C:\\Users\\yedis\\Desktop\\yehu\\Github Repo\\MentorMate-SSS\\output\\generated_data_google.jsonl' dosyasına kaydedildi.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================================\n",
    "# HÜCRE 1.4: VERİ ÜRETİCİ (Google Gemini 2.0 - Güvenli Devam Etme Modu)\n",
    "# AMAÇ: Google'ın günlük limitine takılsa bile, ertesi gün kaldığı yerden\n",
    "# devam edebilen bir veri üretme script'i.\n",
    "# ======================================================================================\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "print(\"🤖 Sentetik Cevap Üretici (Google Gemini Versiyonu) Başlatılıyor...\")\n",
    "\n",
    "# --- AYARLAR ---\n",
    "INPUT_FILE_PATH = r\"C:\\Users\\yedis\\Desktop\\yehu\\Github Repo\\MentorMate-SSS\\output\\enriched_dataset.jsonl\"\n",
    "# Hugging Face'ten ayrı bir dosya oluşturalım ki karışmasın\n",
    "OUTPUT_FILE_PATH = r\"C:\\Users\\yedis\\Desktop\\yehu\\Github Repo\\MentorMate-SSS\\output\\generated_data_google.jsonl\"\n",
    "VARIANTS_PER_QUESTION = 2 \n",
    "# Google'ın dakikalık limiti (RPM) daha yüksek olduğu için bekleme süresini daha düşük tutabiliriz.\n",
    "DELAY_SECONDS = 15 \n",
    "LLM_MODEL_NAME = \"models/gemini-2.0-flash\" \n",
    "\n",
    "# --- API ve Model Yapılandırması ---\n",
    "api_key = os.environ.get('GOOGLE_API_KEY-cosmo')\n",
    "if not api_key:\n",
    "    raise ValueError(\"Google API Anahtarı bulunamadı! Lütfen 'GOOGLE_API_KEY' ortam değişkenini ayarlayın.\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=LLM_MODEL_NAME, temperature=0.7, google_api_key=api_key)\n",
    "print(f\"✅ LangChain ve Gemini modeli ({LLM_MODEL_NAME}) veri üretimi için yapılandırıldı.\")\n",
    "\n",
    "# --- Prompt ve Zincir ---\n",
    "prompt_template_str = \"\"\"\n",
    "Sen bir metin yeniden yazma asistanısın. Görevin, verilen bir cevabı, anlamını tamamen koruyarak ama farklı kelimelerle yeniden yazmaktır. Sadece ve sadece yeniden yazılmış cevabı döndür. Başka hiçbir açıklama ekleme.\n",
    "\n",
    "Orijinal Soru: {soru}\n",
    "Orijinal Cevap: {orijinal_cevap}\n",
    "Yeniden Yazılmış Cevap:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template_str)\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | llm | output_parser\n",
    "print(\"✅ LangChain zinciri oluşturuldu.\")\n",
    "\n",
    "# --- Kaldığı Yeri Hesaplama ---\n",
    "start_index = 0\n",
    "if os.path.exists(OUTPUT_FILE_PATH):\n",
    "    with open(OUTPUT_FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "        lines_in_output = len(f.readlines())\n",
    "        start_index = lines_in_output // VARIANTS_PER_QUESTION\n",
    "        print(f\"\\n Mevcut dosyada {lines_in_output} varyasyon bulundu.\")\n",
    "        if start_index > 0:\n",
    "            print(f\" İşleme {start_index + 1}. sorudan devam edilecek.\")\n",
    "\n",
    "# --- Veri Üretme Döngüsü ---\n",
    "try:\n",
    "    # DOSYA MODU 'a' (append/ekleme) olarak ayarlandı!\n",
    "    with open(INPUT_FILE_PATH, 'r', encoding='utf-8') as infile, \\\n",
    "         open(OUTPUT_FILE_PATH, 'a', encoding='utf-8') as outfile:\n",
    "        \n",
    "        lines = infile.readlines()\n",
    "        lines_to_process = lines[start_index:]\n",
    "        total_lines = len(lines)\n",
    "        \n",
    "        print(f\" Orijinal dosyada toplam {total_lines} soru var. Kalan {len(lines_to_process)} soru işlenecek.\")\n",
    "        if not lines_to_process:\n",
    "            print(\"Tüm sorular zaten işlenmiş. İşlem tamamlandı.\")\n",
    "        else:\n",
    "            print(\"İşlem başlıyor...\")\n",
    "\n",
    "        for i, line in enumerate(lines_to_process, start=start_index):\n",
    "            original_data = json.loads(line)\n",
    "            question = original_data.get(\"question\")\n",
    "            answer = original_data.get(\"answer\")\n",
    "            if not question or not answer: continue\n",
    "\n",
    "            print(f\"\\n[{i+1}/{total_lines}] İşleniyor: '{question[:50]}...'\")\n",
    "            for j in range(VARIANTS_PER_QUESTION):\n",
    "                print(f\"  -> Varyasyon {j+1}/{VARIANTS_PER_QUESTION} üretiliyor...\")\n",
    "                try:\n",
    "                    new_answer = chain.invoke({\"soru\": question, \"orijinal_cevap\": answer})\n",
    "                    new_data_entry = {\"question\": question, \"answer\": new_answer.strip()}\n",
    "                    outfile.write(json.dumps(new_data_entry, ensure_ascii=False) + \"\\n\")\n",
    "                except Exception as e:\n",
    "                    print(f\"    !! API Hatası: {e}. Bu varyasyon atlanıyor.\")\n",
    "                    # Günlük limite takıldığımızda script'in durması için hatayı yeniden fırlatabiliriz.\n",
    "                    if \"quota\" in str(e).lower():\n",
    "                        print(\"    !! GÜNLÜK KOTA LİMİTİNE ULAŞILDI. Lütfen yarın tekrar deneyin.\")\n",
    "                        raise e # Script'i durdur.\n",
    "                \n",
    "                time.sleep(DELAY_SECONDS)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80 + f\"\\n✅ İŞLEM TAMAMLANDI! Üretilen veriler '{OUTPUT_FILE_PATH}' dosyasına kaydedildi.\\n\" + \"=\"*80)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"İşlem durduruldu: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daef232b-8f50-4a0a-93d6-ddc62edd451c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
