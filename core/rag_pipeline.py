# ============================================================================
# CORE/RAG_PIPELINE.PY: RAG Sistemi - Hibrit Mod (GÃ¼venli LLM Fallback)
# ============================================================================

import os
from typing import Dict, List, Optional
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain.retrievers.multi_query import MultiQueryRetriever
from langchain.memory import ConversationBufferWindowMemory
from langchain_core.prompts import PromptTemplate
from langchain.chains import ConversationalRetrievalChain

# ============================================================================
# 1. PROMPT ÅABLONLARI
# ============================================================================

EXPERT_PROMPT_TEMPLATE = """Sen MentorMate adlÄ± bootcamp uzman asistanÄ±sÄ±n. SADECE verilen dokÃ¼manlarÄ± kullanarak cevap veriyorsun.

KRÄ°TÄ°K KURALLAR:
1. CevabÄ±nÄ± SADECE aÅŸaÄŸÄ±daki DOKÃœMANLAR'dan al
2. DokÃ¼manlarda cevap YOKSA: "Bu konuda veri setimde bilgi bulunmuyor."
3. Kendi bilgini ASLA KULLANMA
4. KÄ±sa, net, profesyonel ve DOÄAL bir dille cevap ver
5. ASLA kaynak, dosya adÄ± veya meta bilgi ekleme
6. AYNI SORUYA HER ZAMAN AYNI CEVABI VER (tutarlÄ±lÄ±k Ã¶nemli)
7. CevabÄ±nÄ± tek seferde ver, tekrar etme

DOKÃœMANLAR:
{context}

SORU: {question}

CEVAP:"""

# YENÄ°: Genel sorular iÃ§in LLM promptu
GENERAL_LLM_PROMPT = """Sen MentorMate adlÄ± yardÄ±mcÄ± bir asistansÄ±n. Bu soru bootcamp veritabanÄ±nda yok ama genel bir soru.

KRÄ°TÄ°K KURALLAR:
1. Sadece GENEL BÄ°LGÄ° gerektiren sorulara cevap ver
2. Bootcamp-spesifik bilgi ASLA uydurma (tarih, sÃ¼re, kurallar vb.)
3. KÄ±sa, doÄŸal ve yardÄ±mcÄ± ol
4. Emin deÄŸilsen "Bu konuda emin deÄŸilim" de

SORU: {question}

CEVAP:"""

CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template("""
Sohbet geÃ§miÅŸi ve yeni soruyu kullanarak, ANAHTAR KELÄ°MELERÄ° Ä°Ã‡EREN tek baÅŸÄ±na anlaÅŸÄ±lÄ±r bir arama sorgusu oluÅŸtur.

Ã–NEMLÄ° KURALLAR:
1. BÃœYÃœK/kÃ¼Ã§Ã¼k harf farkÄ± gÃ¶zetme - "Sertifika" = "sertifika" = "SERTÄ°FÄ°KA"
2. Soru iÅŸareti olsun/olmasÄ±n aynÄ± anlama gelen sorularÄ± birleÅŸtir
3. Anahtar kelimeleri MUTLAKA koru (Ã¶rn: "katÄ±lÄ±m oranÄ±", "sertifika", "bootcamp sÃ¼resi")
4. EÅŸ anlamlÄ± kelimeleri ekle (Ã¶rn: "iÅŸtirak" = "katÄ±lÄ±m", "web semineri" = "canlÄ± yayÄ±n")
5. TÃ¼m kelimeler kÃ¼Ã§Ã¼k harfle yazÄ±lmalÄ±

SOHBET GEÃ‡MÄ°ÅÄ°:
{chat_history}

YENÄ° SORU:
{question}

ANAHTAR KELÄ°ME ZENGÄ°N SORGU (kÃ¼Ã§Ã¼k harfle):""")


# ============================================================================
# 2. YENÄ°: GÃœVENLÄ° SORU KATEGORÄ°ZASYONU
# ============================================================================

def categorize_question(question: str) -> str:
    """
    Soruyu kategorize eder ve gÃ¼venli LLM kullanÄ±mÄ±na karar verir
    
    Returns:
        "bootcamp_specific": Bootcamp hakkÄ±nda - HALÃœSÄ°NASYON RÄ°SKÄ°!
        "general_safe": Genel bilgi - LLM kullanÄ±labilir
        "greeting": Selamlama - Direkt cevap
    """
    q_lower = question.lower()
    
    # 1. SelamlaÅŸmalar
    greetings = ["merhaba", "selam", "hey", "hi", "gÃ¼naydÄ±n", "iyi gÃ¼nler"]
    if any(g in q_lower for g in greetings):
        return "greeting"
    
    # 2. Bootcamp-spesifik anahtar kelimeler (HALÃœSÄ°NASYON RÄ°SKÄ°!)
    bootcamp_keywords = [
        "bootcamp", "sertifika", "katÄ±lÄ±m", "mentor", "proje", "grup",
        "canlÄ± yayÄ±n", "webinar", "akbank", "eÄŸitim sÃ¼resi", "tarih",
        "toplantÄ±", "zulip", "github repo", "teslim", "dÃ¶kÃ¼man"
    ]
    if any(kw in q_lower for kw in bootcamp_keywords):
        return "bootcamp_specific"
    
    # 3. Genel gÃ¼venli sorular
    general_safe_patterns = [
        "nedir", "ne demek", "nasÄ±l", "kimdir", "matematik", "hesapla",
        "mentormate nedir", "sen kimsin", "ne yaparsÄ±n", "+", "-", "*", "/"
    ]
    if any(pattern in q_lower for pattern in general_safe_patterns):
        return "general_safe"
    
    # VarsayÄ±lan: Bootcamp-spesifik kabul et (gÃ¼venli taraf)
    return "bootcamp_specific"


# ============================================================================
# 3. RAGPipeline SINIFI (HÄ°BRÄ°T MOD)
# ============================================================================

class RAGPipeline:
    """RAG sistemi iÃ§in merkezi yÃ¶netim sÄ±nÄ±fÄ± - Hibrit Mod"""
    
    def __init__(
        self,
        google_api_key: str,
        db_path: str,
        collection_name: str = "mentormate_faq",
        embedding_model: str = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        llm_model: str = "gemini-2.0-flash",
        temperature: float = 0.01
    ):
        self.google_api_key = google_api_key
        self.db_path = db_path
        self.collection_name = collection_name
        self.embedding_model_name = embedding_model
        self.llm_model_name = llm_model
        self.temperature = temperature
        
        # BileÅŸenler
        self.llm = None
        self.llm_general = None  # YENÄ°: Genel sorular iÃ§in ayrÄ± LLM
        self.embeddings = None
        self.vectordb = None
        self.retriever = None
        self.memory = None
        self.chain = None
        
        self._initialize()
    
    def _initialize(self):
        """TÃ¼m bileÅŸenleri baÅŸlatÄ±r"""
        self._setup_llm()
        self._setup_embeddings()
        self._setup_vectordb()
        self._setup_retriever()
        self._setup_memory()
        self._setup_chain()
    
    def _setup_llm(self):
        """LLM modellerini yÃ¼kler"""
        # RAG iÃ§in katÄ± LLM
        self.llm = ChatGoogleGenerativeAI(
            model=self.llm_model_name,
            google_api_key=self.google_api_key,
            temperature=self.temperature
        )
        
        # YENÄ°: Genel sorular iÃ§in biraz daha esnek LLM
        self.llm_general = ChatGoogleGenerativeAI(
            model=self.llm_model_name,
            google_api_key=self.google_api_key,
            temperature=0.3  # Biraz daha yaratÄ±cÄ± ama kontrollÃ¼
        )
    
    def _setup_embeddings(self):
        """Embedding modelini yÃ¼kler"""
        self.embeddings = HuggingFaceEmbeddings(
            model_name=self.embedding_model_name,
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'batch_size': 32}
        )
    
    def _setup_vectordb(self):
        """Vector database'i yÃ¼kler"""
        self.vectordb = Chroma(
            persist_directory=self.db_path,
            embedding_function=self.embeddings,
            collection_name=self.collection_name
        )
    
    def _setup_retriever(self):
        """MultiQuery Retriever'Ä± kurar"""
        base_retriever = self.vectordb.as_retriever(
            search_type="mmr",
            search_kwargs={
                'k': 5,
                'fetch_k': 25,
                'lambda_mult': 0.6
            }
        )
        
        self.retriever = MultiQueryRetriever.from_llm(
            retriever=base_retriever,
            llm=self.llm,
            include_original=True
        )
    
    def _setup_memory(self):
        """Conversation memory'yi baÅŸlatÄ±r"""
        self.memory = ConversationBufferWindowMemory(
            memory_key="chat_history",
            k=5,
            return_messages=True,
            output_key='answer'
        )
    
    def _setup_chain(self):
        """KonuÅŸma zincirini oluÅŸturur"""
        prompt = PromptTemplate(
            template=EXPERT_PROMPT_TEMPLATE,
            input_variables=["context", "question"]
        )
        
        self.chain = ConversationalRetrievalChain.from_llm(
            llm=self.llm,
            retriever=self.retriever,
            memory=self.memory,
            condense_question_prompt=CONDENSE_QUESTION_PROMPT,
            combine_docs_chain_kwargs={"prompt": prompt},
            return_source_documents=True,
            verbose=False
        )
    
    def query(self, question: str) -> Dict:
        """
        YENÄ°: Hibrit sorgu iÅŸleme
        1. Ã–nce RAG'e sor
        2. Cevap gÃ¼vensizse ve soru gÃ¼venli kategorideyse â†’ LLM'e sor
        3. Bootcamp-spesifik sorularda â†’ "Bilgi yok" de
        """
        try:
            # 1. AÅAMA: Soru kategorisini belirle
            category = categorize_question(question)
            
            # Selamlama iÃ§in direkt cevap
            if category == "greeting":
                return {
                    "answer": "Merhaba! Ben MentorMate. Size nasÄ±l yardÄ±mcÄ± olabilirim? ğŸ˜Š",
                    "source_documents": []
                }
            
            # 2. AÅAMA: Ã–nce RAG'e sor
            result = self.chain.invoke({"question": question})
            answer = result.get("answer", "").strip()
            source_docs = result.get("source_documents", [])
            
            # 3. AÅAMA: Cevap gÃ¼venilir mi?
            is_confident = self._check_confidence(answer, source_docs)
            
            # 4. AÅAMA: GÃ¼vensizse ve gÃ¼venli kategorideyse â†’ LLM Fallback
            if not is_confident and category == "general_safe":
                return self._general_llm_fallback(question)
            
            # 5. AÅAMA: Bootcamp-spesifik + gÃ¼vensiz â†’ "Bilgi yok"
            if not is_confident and category == "bootcamp_specific":
                return {
                    "answer": "âš ï¸ Bu konuda veri setimde gÃ¼venilir bilgi bulunmuyor.",
                    "source_documents": source_docs
                }
            
            # Normal RAG cevabÄ±
            return result
            
        except Exception as e:
            raise Exception(f"Query iÅŸleme hatasÄ±: {str(e)}")
    
    def _check_confidence(self, answer: str, source_docs: List) -> bool:
        """
        CevabÄ±n gÃ¼venilir olup olmadÄ±ÄŸÄ±nÄ± kontrol eder
        """
        answer_lower = answer.lower()
        
        # "Bilgi yok" cevaplarÄ± gÃ¼vensiz
        no_info_keywords = ["veri setimde", "bilgi bulunmuyor", "bilgim yok"]
        if any(kw in answer_lower for kw in no_info_keywords):
            return False
        
        # Kaynak yoksa gÃ¼vensiz
        if not source_docs:
            return False
        
        # Kelime Ã¶rtÃ¼ÅŸme oranÄ± dÃ¼ÅŸÃ¼kse gÃ¼vensiz
        answer_words = set([w for w in answer_lower.split() if len(w) > 3])
        if not answer_words:
            return True
        
        source_text = " ".join([doc.page_content.lower() for doc in source_docs])
        matched_words = [w for w in answer_words if w in source_text]
        overlap_ratio = len(matched_words) / len(answer_words)
        
        return overlap_ratio >= 0.20
    
    def _general_llm_fallback(self, question: str) -> Dict:
        """
        YENÄ°: Genel sorular iÃ§in gÃ¼venli LLM fallback
        """
        prompt = PromptTemplate(
            template=GENERAL_LLM_PROMPT,
            input_variables=["question"]
        )
        
        try:
            formatted_prompt = prompt.format(question=question)
            response = self.llm_general.invoke(formatted_prompt)
            answer = response.content.strip()
            
            return {
                "answer": answer,
                "source_documents": []
            }
        except Exception as e:
            return {
                "answer": "âš ï¸ Bu konuda size yardÄ±mcÄ± olamÄ±yorum.",
                "source_documents": []
            }
    
    def clear_memory(self):
        """Sohbet geÃ§miÅŸini temizler"""
        self.memory.clear()
    
    def get_stats(self) -> Dict:
        """Pipeline istatistiklerini dÃ¶ner"""
        return {
            "llm_model": self.llm_model_name,
            "embedding_model": self.embedding_model_name,
            "temperature": self.temperature,
            "collection_name": self.collection_name,
            "db_path": self.db_path,
            "mode": "Hibrit (RAG + GÃ¼venli LLM Fallback)"
        }


# ============================================================================
# 4. YARDIMCI FONKSÄ°YONLAR
# ============================================================================

def validate_answer(answer: str, source_docs: List) -> str:
    """
    HalÃ¼sinasyon kontrolÃ¼ yapar (mevcut sistem ile uyumlu)
    """
    if not source_docs:
        return "âš ï¸ Bu konuda veri setimde gÃ¼venilir bilgi bulunmuyor."
    
    answer_lower = answer.lower()
    
    no_info_keywords = ["veri setimde", "bilgi bulunmuyor", "bilgim yok"]
    if any(keyword in answer_lower for keyword in no_info_keywords):
        return answer
    
    answer_words = set([w for w in answer_lower.split() if len(w) > 3])
    source_text = " ".join([doc.page_content.lower() for doc in source_docs])
    
    if not answer_words:
        return answer
    
    matched_words = [w for w in answer_words if w in source_text]
    overlap_ratio = len(matched_words) / len(answer_words)
    
    if overlap_ratio < 0.20:
        return "âš ï¸ Bu konuda veri setimde gÃ¼venilir bilgi bulunmuyor."
    
    return answer


def preprocess_query(query: str) -> str:
    """
    Sorguya anahtar kelime zenginleÅŸtirmesi ve normalizasyon yapar
    """
    query_normalized = query.lower()
    
    turkish_chars = {
        'Ä°': 'i', 'I': 'Ä±', 'Ä': 'ÄŸ', 'Ãœ': 'Ã¼',
        'Å': 'ÅŸ', 'Ã–': 'Ã¶', 'Ã‡': 'Ã§'
    }
    for upper, lower in turkish_chars.items():
        query_normalized = query_normalized.replace(upper, lower)
    
    keyword_map = {
        "katÄ±lÄ±m": ["iÅŸtirak", "katÄ±lÄ±m oranÄ±", "yoklama", "attendance", "devam"],
        "canlÄ± yayÄ±n": ["webinar", "web semineri", "youtube", "yayÄ±n", "live", "stream"],
        "sertifika": ["certificate", "belge", "sertifikadaki", "diploma", "sertifikasÄ±"],
        "bootcamp": ["eÄŸitim", "kurs", "program", "kampÄ±", "camp", "training"],
        "sÃ¼re": ["zaman", "gÃ¼n", "hafta", "ne kadar", "kaÃ§", "duration"],
        "mentor": ["danÄ±ÅŸman", "eÄŸitmen", "mentÃ¶r", "Ã¶ÄŸretmen"],
        "proje": ["Ã¶dev", "task", "gÃ¶rev", "assignment", "project", "tamamlama"],
        "github": ["git", "repo", "repository", "kod yÃ¼kleme", "arayÃ¼z"],
        "grup": ["ekip", "takÄ±m", "team", "bireysel", "tek kiÅŸi", "iki kiÅŸi"],
        "iÅŸ": ["staj", "kariyer", "fÄ±rsat", "employment", "job"],
        "arÅŸiv": ["kayÄ±t", "video", "recording", "kaydediliyor"],
        "duyuru": ["announcement", "bildirim", "haber", "kanal", "zulip"],
        "takvim": ["tarih", "gÃ¼n", "program", "schedule", "zamanlama"],
        "toplantÄ±": ["meeting", "buluÅŸma", "gÃ¶rÃ¼ÅŸme", "saat", "zaman"]
    }
    
    words = query_normalized.split()
    if len(words) <= 2:
        for word in words:
            for keyword, synonyms in keyword_map.items():
                if keyword in word or word in keyword:
                    query_normalized += " " + keyword + " " + " ".join(synonyms)
                    break
    
    enriched_query = query_normalized
    for keyword, synonyms in keyword_map.items():
        if keyword in query_normalized:
            enriched_query += " " + " ".join(synonyms)
    
    return enriched_query